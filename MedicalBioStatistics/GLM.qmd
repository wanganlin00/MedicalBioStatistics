# 广义线性模型

在统计学上，[广义线性模型](https://zh.wikipedia.org/zh-cn/%E5%BB%A3%E7%BE%A9%E7%B7%9A%E6%80%A7%E6%A8%A1%E5%9E%8B)（generalized linear model， GLM）是一种应用灵活的线性回归模型。该模型允许因变量的误差分布有除了正态分布之外的其它分布。此模型假设实验者所测量的随机变量的分布函数与实验中系统性效应（即非随机的效应）可经由一链接函数（link function）建立可解释其相关性的函数。

在广义线性模式中，假设每个资料的观测值 Y 来自某个指数族分布 f 。

## GLM 组件

广义线性模型是对线性模型的扩展，适用于非正态分布的数据，假设观测值之间是独立的，不能处理组内相关性。模型形式为：

$$
g(E(Y))=\mathbf{X} \beta
$$

1.  线性预测器（Linear Predictor）：

$$
\eta = \mathbf{X} \beta
$$

2.  因变量的期望值与线性预测函数的关系：

$$
E(y)=\mu
$$

3.  链接函数 `g(.)` ：

$$
\eta =g(\mu)=g(E(y))
$$

4.  反链接函数`g-1 (.)`：

$$
E(y)=g^{-1}(\eta)
$$

5.  y 的方差：

    $$
    Var(y)=f(\mu)=f(g^{-1}(\mathbf{X}\beta))
    $$

**典型链接函数**

+----------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| Y的分布                                                                                            | 名称                                                                                      | 链接函数                                                                                                                  | 均值函数                                                                                                                  |
+:==================================================================================================:+:=========================================================================================:+:=========================================================================================================================:+:=========================================================================================================================:+
| [正态](https://zh.wikipedia.org/wiki/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83 "正态分布")              | 恒等                                                                                      | ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/63238c06f9c1927aee60b40fec3adccd419cf32a){fig-align="center"} | ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/12c514082234f52d09595635789f474de0279b7d){fig-align="center"} |
+----------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| [指数](https://zh.wikipedia.org/wiki/%E6%8C%87%E6%95%B8%E5%88%86%E4%BD%88 "指数分布") / Gamma      | [倒数](https://zh.wikipedia.org/wiki/%E5%80%92%E6%95%B8 "倒数")                           | ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/35c753c466b330a78b576fc8727e188962cc604f)                     | ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/77e75642db84d5f96e6c2ceb8b6c1deec1b41037)                     |
+----------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| [泊松](https://zh.wikipedia.org/wiki/%E6%B3%8A%E6%9D%BE%E5%88%86%E4%BD%88 "泊松分布")              | [自然对数](https://zh.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E5%B0%8D%E6%95%B8 "自然对数") | ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/ef9f78b057c55a36d8b2516ba1f22a64f601fa1e)                     | ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/b8cdcc2a7f1ac3de2da641254ab17cd120d1ce5e)                     |
+----------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| [二项式](https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%A1%B9%E5%BC%8F%E5%88%86%E5%B8%83 "二项式分布") | [Logit](https://zh.wikipedia.org/wiki/Logit "Logit")                                      | ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/b1399fce891de947b987e2e8ae8abd942316a681)                     | ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/d6ffa52841bbde6699049034181cc032d5f14533)                     |
|                                                                                                    |                                                                                           |                                                                                                                           |                                                                                                                           |
| 多项式                                                                                             |                                                                                           |                                                                                                                           |                                                                                                                           |
+----------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+

## 数据来源

[数据下载网站](https://www.statlearning.com/resources-second-edition)

```{r}
library(tidyverse)
library(patchwork)
df <- read_csv("data/Default.csv")

df <- df %>% 
    mutate(across(1:2, ~ factor(.x,levels = c("No","Yes"),labels = c(0,1))
                  )
           )
str(df)

# 是否违约 是否学生 余额 收入
head(df)
table(df$default,df$student)
```

```{r}
ggplot(df,aes(balance,income))+
  geom_point(aes(shape=default,color=default),show.legend = F)|
ggplot(df,aes(default,balance,fill=default),)+
  geom_boxplot(show.legend = F)+
ggplot(df,aes(default,income,fill=default))+
  geom_boxplot()
```

## 恒等链接线性回归

线性回归是一种简单的线性回归模型，其中假设响应变量服从正态分布，并且使用恒等链接函数（identity link function），t-statistic

```{r}
library(tidymodels)
library(ggfortify)
# 使用 glm() 函数进行高斯线性回归
glm_gauss <- linear_reg() %>% 
  set_engine("glm", family = stats::gaussian(link = "identity")) %>% 
  fit(as.numeric(default)-1~balance,data=df)

# 查看模型的系数
tidy(glm_gauss)

# 查看模型性能的 AIC 和 Deviance
glance(glm_gauss) %>% dplyr::select(AIC, deviance)


# Change the theme and colour
autoplot(glm_gauss, which = 1:6, ncol = 2, label.size = 3,
         colour = "steelblue") + theme_bw()
```

```{r}
ggplot(df,aes(balance,as.numeric(default)-1))+
  geom_point(color="orange",size=1.25)+
  geom_smooth(method = "lm",se=FALSE)+
  geom_hline(yintercept = c(0,1),linetype=2)+
  ggtitle("linear regression")

```

## 逻辑回归

逻辑回归用于处理分类问题。其模型假设响应变量的对数优势（log odds）服从线性模型。

Sigmoid 激活函数：

$$
f(x)=\frac{1}{1+e^{-x}}=\frac{e^x}{1+e^x}
$$

```{r}
sigmoid <- tibble(
    x=seq(-6,6,length.out=1000),
    y=1/(1+exp(-x)),
)
ggplot(sigmoid,aes(x,y))+
    geom_line()
```

逻辑回归( logistic regression )的一般表达式：

$$
\pi(Y=k|X=(X_1,X_2,...,X_p)=\frac{e^{\beta_{k0}+\beta_{k1}X_1+\beta_{k2}X_2+...+\beta_{kp}X_p}}{1+\sum_{l=1}^{K-1} e^{\beta_{l0}+\beta_{l1}X_1+\beta_{l2}X_2+...+\beta_{lp}X_p}}
$$ 其中$\pi$ 是成功概率，$k=1,2,...,K-1$是因变量的第k个水平，共**K** 个水平，$p$ 是自变量个数。

logit link function

z-statistic

### 二分类Binary

-   当$K=2$时，$k=l=p=1$即二分类逻辑回归，一般需要引入虚拟变量（哑变量，dummy variable），通常取值为 0或1。

    极大似然法（maximum likelihood），*likelihood function*：

    $$
    \ell (\beta_0,\beta_1)=\prod_{i:y_i=1}\pi(x_i)\prod_{i':y_{i'}=0}(1-\pi(x_{i'}))
    $$

```{r}
logit_spec <- logistic_reg() %>%
  set_engine("glm",family= binomial(link = "logit")) 


logit_binary_y <- logit_spec %>% fit(default~balance,data=df)

logit_binary_y %>% glance()

tidy(logit_binary_y,  conf.int = TRUE) %>% 
    mutate(
        z_value = estimate/std.error,
        Wald_ChiSquare=z_value^2, #  Wald卡方值可以用来检验各个变量系数是否显著 不同于零。 它是通过系数估计的平方除以其标准误差的平方来计算的。即 z值的平方
        OR = exp(estimate),
        `OR 95% CI`= sprintf("%.3f ~ %3.f",exp(conf.low),exp(conf.high)),
    )


ggplot(df,aes(balance,as.numeric(default)-1))+
  geom_point(color="orange",size=1.25)+
  geom_smooth(method = "glm",
              method.args=list(family=binomial(link = "logit")),se=FALSE)+
  geom_hline(yintercept = c(0,1),linetype=2)+
  ggtitle("binary logistic regression with continuous x")
```

```{r}
logit_binary_x <- logit_spec %>%fit(default ~ student, data = df)

tidy(logit_binary_x)


ggplot(df,aes(student,as.numeric(default)-1))+
  geom_point(color="orange",size=1.25)+
  geom_smooth(method = "glm",
              method.args=list(family=binomial(link = "logit")),se=FALSE)+
  geom_hline(yintercept = c(0,1),linetype=2)+
    scale_y_continuous("default", breaks = c(0,1))+
  ggtitle("binary logistic regression with binary x")
```

### 二分类多元逻辑回归

-   当$K=2$时，$k=l=1,p>1$即多元逻辑回归（multiple logistic regression）。

    优势（odds）

    $$
    Odds=\frac{\pi(X)}{1-\pi(X)}=e^{\beta_0+\beta_1X_1+\beta_2X_2+...+\beta_pX_p}
    $$

    log odds (logit)

    $$
    logit(\pi(X))=\ln (\frac{\pi(X)}{1-\pi(X)})=\beta_0+\beta_1X_1+\beta_2X_2+...+\beta_pX_p
    $$

```{r}
logit_multiple<-logit_spec %>% fit(default~balance+income+student,data=df)

tidy(logit_multiple)

# confusion matrix 混淆矩阵
augment(logit_multiple, new_data = df) %>%
  conf_mat(truth = default, estimate = .pred_class) %>% 
    autoplot(type = "heatmap")

#准确性 
(9627+105)/(9627+105+40+228)
augment(logit_multiple, new_data = df) %>%
  accuracy(truth = default, estimate = .pred_class)
```

```{r}
df_new <- tibble(
  balance = c(1000, 2000), 
  income = c(14144,24141),
  student = factor(c(1, 0)),)
predict(logit_multiple, new_data = df_new,type="class")
predict(logit_multiple, new_data = df_new, type = "prob")
```

### 似然比检验

likelihood ratio tests (LRT)

比较两个嵌套模型，log-likelihood (logLL)

![](images/clipboard-317605604.png)

相应的p-value 源自具有 个自由度的 卡方 分布（即模型中测试的参数数量之差）。

```{r}
logit_binary_y
logit_multiple


LRT=2*(logLik(logit_multiple$fit)-logLik(logit_binary_y$fit))
LRT

pval=1-pchisq(LRT,2)
pval

out<-anova(logit_binary_y$fit, logit_multiple$fit)
out

1-pchisq(out$Deviance[2],2)
```

### K\>2 多分类逻辑回归

用于处理具有多于两个类别的响应变量的情况。例如，分类问题中的三个或更多类别。

-   当$K>2$时，$k,l,p>1$即多项逻辑回归（multinomial logistic regression）。

    $$
    \ln (\frac{P(Y=k|X=x)}{P(Y=K|X=x)})=\beta_{k0}+\beta_{k1}X_1+\beta_{k2}X_2+...+\beta_{kp}X_p
    $$

#### `nnet::multinom()`

```{r}
mn_spec <- multinom_reg(mode = "classification", engine = "nnet")

iris_mnlogit <- mn_spec %>% 
    fit(Species ~ ., data = iris)

iris_mnlogit %>% glance()
iris_mnlogit %>% tidy()


augment(iris_mnlogit, new_data = iris) %>%
    conf_mat(truth = Species, estimate = .pred_class) %>%
    autoplot(type = "heatmap")
```

#### `glmnet::glmnet()`

```{r}
library(glmnet) # 多项回归
iris_glmnet <- glmnet(x = iris[, -5], y = iris[, 5], family = "multinomial")
iris_glmnet
summary(iris_glmnet )
plot(iris_glmnet)
plot(iris_glmnet$lambda,
  ylab = expression(lambda), xlab = "迭代次数", main = "惩罚系数的迭代路径"
)

# 选择一个迭代趋于稳定时的 lambda，比如 iris_glmnet$lambda[80]
coef(iris_glmnet, s = 0.0002796185)

iris_pred_glmnet <- predict(
  object = iris_glmnet, newx = as.matrix(iris[, -5]),
  s = 0.0002796185, type = "class"
)

```

```{r}
mn_spec <- multinom_reg(mode = "classification", engine = "glmnet" ,
                        penalty = 0)

iris_mnlogit <- mn_spec %>% 
    fit(Species ~ ., data = iris)
iris_mnlogit %>% glance()
iris_mnlogit$fit %>% tidy() %>% DT::datatable()
```

### 有序逻辑回归

$$
    \ln \left(\frac{P(Y\le k|X=x)}{1-P(Y\le k|X=x)}\right)
$$

```{r}
# 数据集 icpsr
acl <- read_rds("data/advanced_acl_data.rds")
acl$PhysActCat_W1 <- factor(acl$PhysActCat_W1,ordered = T)
str(acl$PhysActCat_W1)

ordered_logit <- MASS::polr(PhysActCat_W1 ~ SelfEfficacy_W1, data = acl,
                            method = "logistic")
ordered_logit %>% summary()

predict(ordered_logit ,acl ,type = "prob") %>% 
    as_tibble() %>% 
    DT::datatable()

predict(ordered_logit ,acl ,type = "class") %>% 
    as_tibble() %>% 
    DT::datatable()
```

## 泊松回归

泊松回归用于计数数据，假设响应变量服从泊松分布，并使用对数链接函数（log link function），z-statistic

`family=poisson(link = "log")`

`family = quasipoisson(link = "log"))`

$$
P(X=x;\lambda)=\frac{e^{-\lambda}\lambda ^x}{x!}
$$

```{r}
ggplot(tibble(x=0:20,
              y1=dpois(x,lambda = 2),
              y2=dpois(x,lambda = 6),
              ),
       aes(x)
       )+
    geom_col(aes(y=y1),fill = "lightblue")+
    geom_col(aes(y=y2),fill = "yellow",alpha=.3)+
    ylab("Poisson Density")
```

```{r}
library(poissonreg)
df2 <- read_csv("data/Bikeshare.csv")
```

```{r}
# 泊松回归模型
pois_spec <- poisson_reg() %>% 
  set_mode("regression") %>% 
  set_engine("glm",family=poisson(link = "log"))

pois_rec_spec <- recipe(bikers ~ mnth + hr + workingday + temp + weathersit, data = df2) %>% 
    step_dummy(all_nominal_predictors()) # 虚拟变量

pois_wf <- workflow() %>% 
  add_recipe(pois_rec_spec) %>% 
  add_model(pois_spec)

pois_fit <- pois_wf %>% fit(data = df2)


tidy(pois_fit)


# 绘制实际值与预测值的关系图
augment(pois_fit, new_data = df2, type = "response") %>%
    ggplot(aes(bikers, .pred)) +
    geom_point(alpha = 0.1) +
    geom_abline(slope = 1,
                linewidth = 1,
                color = "grey40") +
    labs(title = "Predicting the number of bikers per hour using Poission Regression", x = "Actual", y = "Predicted")
```

```{r}
pois_fit_coef_mnths <- 
  tidy(pois_fit) %>% 
  dplyr::filter(grepl("^mnth", term)) %>% 
  mutate(
    term = stringr::str_replace(term, "mnth_", ""),
    term = forcats::fct_inorder(term)
  ) 

pois_fit_coef_mnths %>% 
  ggplot(aes(term, estimate)) +
  geom_line(group = 1,na.rm = TRUE) +
  geom_point(shape = 21, size = 3, stroke = 1.5, 
             fill = "black", color = "white",na.rm = TRUE) +
  labs(title = "Coefficient value from Poission Regression",
       x = "Month", y = "Coefficient")
```

```{r}
pois_acl <- pois_spec %>% 
    fit(NChronic12_W1 ~ SelfEfficacy_W1,data = acl)

pois_acl %>% glance()

pois_acl %>% tidy()

AIC(pois_acl$fit)
BIC(pois_acl$fit)
```

## 负二项回归

负二项回归用于处理计数数据且存在过度离散（overdispersion）的问题即当均值不等于方差。

log link function，z-statistic

probability mass function ：

$$
P(X=x;\lambda,\nu)=\binom{x+\nu - 1}{ x} \left ( \frac{\lambda}{\lambda +\nu} \right)^x \left ( \frac{\nu}{\nu + \lambda} \right)^{\nu}
$$

负二项分布的均值是 $\lambda$ ，

方差是 $\lambda + \frac{\lambda ^2}{\nu}$ 。

```{r}
library(MASS)
# 负二项回归模型
nb_spec <- linear_reg() %>% 
  set_engine("glm", family = MASS::negative.binomial(theta = 1, link = "log"))

nb_acl <- nb_spec %>% 
  fit(NChronic12_W1 ~ SelfEfficacy_W1, data = acl)

# 查看模型结果
nb_acl %>% glance()
nb_acl %>% tidy()


AIC(nb_acl$fit)
BIC(nb_acl$fit)

# MASS::glm.nb()
```

## 零膨胀模型（zero-inflated）

逻辑回归+以上之一

## 正则化广义线性模型

Ridge、Lasso

```{r}
library(glmnet)
data(QuickStartExample)
fit <- glmnet::glmnet(x = QuickStartExample$x, y = QuickStartExample$y)
autoplot(fit)

fit <- glmnet::cv.glmnet(x = QuickStartExample$x, y = QuickStartExample$y)
autoplot(fit, colour = 'blue')

```
