[
  {
    "objectID": "quantitative_data.html",
    "href": "quantitative_data.html",
    "title": "\n1  定量数据的统计描述\n",
    "section": "",
    "text": "1.1 频数分布\nShow the codelibrary(ggplot2)\nlibrary(tibble)\nlibrary(dplyr)\nggplot(data = mtcars, aes(x = mpg)) +\n    geom_histogram(color = \"black\", bins = 10)\n\n\n\n\n\n\nShow the code\nggplot(data = mtcars, aes(x = mpg)) +\n    geom_histogram(color = \"black\", binwidth = diff(range(mtcars$mpg)) / 9)",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#频数分布",
    "href": "quantitative_data.html#频数分布",
    "title": "\n1  定量数据的统计描述\n",
    "section": "",
    "text": "极差(Range) : \\(R=X_{max}-X_{min}\\)\n组数 (Number of Bins) \\(k\\) : 通常选择 \\(8\\) 到 \\(15\\) 之间的值。\n组距 (Bin Width) : \\(interval=\\frac{R}{k}\\)\n频数 (Frequency) : \\(Frequency = count\\)\n频率 (Relative Frequency)： \\(Relative\\ Frequency = \\frac{count}{n} \\times 100\\%\\)",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#集中趋势central-tendency",
    "href": "quantitative_data.html#集中趋势central-tendency",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.2 集中趋势（central tendency）",
    "text": "1.2 集中趋势（central tendency）\n总体方差除以 n\n样本方差除以（n-1），R 计算的是样本方差\n\nShow the codex &lt;- c(1,2:9,11)\n\n#算术均值\nmean(x)\n#&gt; [1] 5.6\nsum(x)/length(x)\n#&gt; [1] 5.6\n\n\n# 截尾均值   10%，则只有 80% 的中心数据将用于计算平均值。\nmean(x,trim = 0.1)\n#&gt; [1] 5.5\n\n\n\n# 加权平均值\nz &lt;- c(5, 7, 8)\n\n# 权重（和为1）\nwts &lt;- c(0.2, 0.2, 0.6)\n\nweighted.mean(z, w = wts) \n#&gt; [1] 7.2\n\nsum(z * wts)\n#&gt; [1] 7.2\n\n\n\n# 几何平均值\nw &lt;- c(10, 20, 15, 40)\n\n# Geometric mean\nexp(mean(log(w)))\n#&gt; [1] 18.6121\npsych::geometric.mean(w)\n#&gt; [1] 18.6121\n\n\n\nShow the code#中位数\ndata &lt;- c(126, 52, 133, 104, 115, 67, 57, 83, 53, 105, 100)\nmedian(data)\n#&gt; [1] 100\n\ndata2 &lt;- c(126, 52, 133, 104, 115, 67, 57, 83, 53, 105)\nmedian(data2)\n#&gt; [1] 93.5\n\n\n\nShow the code# install.packages(\"modeest\")\nlibrary(modeest)\n\nset.seed(1234)\nx2 &lt;- rnorm(1000)\nmlv(x2, method = \"meanshift\")\n#&gt; [1] -0.03912067\n#&gt; attr(,\"iterations\")\n#&gt; [1] 265\n\ny &lt;- c(3, 5, 3, 3, 5, 6, 5)\nrstatix::get_mode(y)\n#&gt; [1] 3 5\nmodeest::mlv(y, method = \"mfv\")\n#&gt; [1] 3 5\n\n\n注意：函数rstatix::get_mode() 可能返回多个众数，如果存在多个众数，请检查其处理方式。",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#离散趋势dispersion-tendency",
    "href": "quantitative_data.html#离散趋势dispersion-tendency",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.3 离散趋势（dispersion tendency）",
    "text": "1.3 离散趋势（dispersion tendency）\n\nShow the code# 值域\nrange(mtcars$mpg)  \n#&gt; [1] 10.4 33.9\n# 极差 or 全距\ndiff(range(mtcars$mpg) )  \n#&gt; [1] 23.5\n\n\n# 方差 variance\nvar(mtcars$mpg)       \n#&gt; [1] 36.3241\n\n# 标准差 standard deviation\nsd(mtcars$mpg)       \n#&gt; [1] 6.026948\n\n\n# 变异系数 Coefficient of Variation\nCV &lt;- function(x, na.rm = TRUE) {  \n    if (na.rm) x &lt;- x[!is.na(x)]\n    CV = sd(x) / abs(mean(x)) * 100\n    sprintf(\"%.8f%%\", CV)\n}\nCV(mtcars$mpg)\n#&gt; [1] \"29.99880816%\"\n\n\n# 绝对中位差 median absolute deviation\nmad(mtcars$mpg,constant = 1.4826)\n#&gt; [1] 5.41149\nmedian(abs(mtcars$mpg-median(mtcars$mpg)))\n#&gt; [1] 3.65\nmedian(abs(mtcars$mpg-median(mtcars$mpg)))*1.4826\n#&gt; [1] 5.41149\n\n\n说明：mad() 计算时乘以比例因子 constant = 1.4826 以实现渐进正态一致性。",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#位置度量",
    "href": "quantitative_data.html#位置度量",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.4 位置度量",
    "text": "1.4 位置度量\n\nShow the code# 分位数\nquantile(mtcars$mpg,probs = c(0,0.1,0.25,0.5,0.75,1))    \n#&gt;     0%    10%    25%    50%    75%   100% \n#&gt; 10.400 14.340 15.425 19.200 22.800 33.900\n\n# 四分位数间距\nIQR(mtcars$mpg)   \n#&gt; [1] 7.375",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#关联度量",
    "href": "quantitative_data.html#关联度量",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.5 关联度量",
    "text": "1.5 关联度量\n\nShow the code# 协方差系数\n\ncov(mpg %&gt;% select(displ,cty,hwy))\n#&gt;           displ      cty       hwy\n#&gt; displ  1.669158 -4.39069 -5.893111\n#&gt; cty   -4.390690 18.11307 24.225432\n#&gt; hwy   -5.893111 24.22543 35.457779\n\n\n\ncov(mpg %&gt;% select(displ,cty,hwy)) %&gt;% cov2cor()\n#&gt;           displ        cty        hwy\n#&gt; displ  1.000000 -0.7985240 -0.7660200\n#&gt; cty   -0.798524  1.0000000  0.9559159\n#&gt; hwy   -0.766020  0.9559159  1.0000000\n\n# Pearson 相关系数\ncor(mpg %&gt;% select(displ,cty,hwy))\n#&gt;           displ        cty        hwy\n#&gt; displ  1.000000 -0.7985240 -0.7660200\n#&gt; cty   -0.798524  1.0000000  0.9559159\n#&gt; hwy   -0.766020  0.9559159  1.0000000\n\n\n# Kendall 的 tau 相关系数 适用于有序数据或非正态分布数据，因为它基于值的排名或顺序，而不是实际值。\ncor(mpg %&gt;% select(displ,cty,hwy), method = \"kendall\")\n#&gt;            displ        cty        hwy\n#&gt; displ  1.0000000 -0.7210828 -0.6536974\n#&gt; cty   -0.7210828  1.0000000  0.8628045\n#&gt; hwy   -0.6536974  0.8628045  1.0000000\n\n\n#  Spearman 的 rho 相关系数   Pearson 系数的稳健非参数替代项,数据非正态或具有异常值\ncor(mpg %&gt;% select(displ,cty,hwy), method = \"spearman\")\n#&gt;            displ        cty        hwy\n#&gt; displ  1.0000000 -0.8809049 -0.8266576\n#&gt; cty   -0.8809049  1.0000000  0.9542104\n#&gt; hwy   -0.8266576  0.9542104  1.0000000",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#分布形态",
    "href": "quantitative_data.html#分布形态",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.6 分布形态",
    "text": "1.6 分布形态\n\n1.6.1 偏度系数\n\n1.6.1.1 总体偏度（Population Skewness）\n表示随机变量概率分布的不对称性。\nhttps://www.macroption.com/skewness-formula/\n三阶中心矩。二阶中心矩即方差。\n\\[\nPopulation\\ Skewness (X) =  \\frac{E(X_i-E(X))^3}{Var(X)^{\\frac{3}{2}}} =E  [(\\frac{X_i-\\mu}{\\sigma})^3]= \\frac{1}{n} \\sum_{i=1}^{n}  (\\frac{X_i-\\mu}{\\sigma} )^3\n\\]\n偏度的取值范围： \\((-\\infty,+\\infty)\\)\n\nSkew＞0，正偏态分布，右偏 = 尾部向右延伸。Mode &lt; Median &lt; Mean；\nSkew=0，数据相对均匀的分布在均值两侧；\nSkew＜0，负偏态分布，左偏 = 尾部向左延伸；Mode &gt; Median &gt; Mean。\n\n\nShow the codex &lt;- c(1,2,3,5,6,10)\n\nskewness &lt;- function(x,na.rm=TRUE){\n    if(na.rm) x &lt;- x[!is.na(x)]\n    n=length(x)\n    μ=mean(x)\n    SD=sd(x)\n    \n    return(c(population_sknewness = mean(((x-μ)/SD)^3),\n             sample_sknewness = sum(((x-μ)/SD)^3)*n/(n-1)/(n-2)))\n}\nskewness(x)\n#&gt; population_sknewness     sample_sknewness \n#&gt;            0.5142767            0.9256980\n\n\ne1071::skewness(x,type = 2)  # 样本偏度\n#&gt; [1] 0.925698\ne1071::skewness(x,type = 3)  # 总体偏度\n#&gt; [1] 0.5142767\n\ne1071::skewness(x,type = 1)   # 无偏偏度\n#&gt; [1] 0.6760343\nmoments::skewness(x)\n#&gt; [1] 0.6760343\n\n\n\n1.6.1.2 样本偏度（Sample Skewness）\n\\[\nSample\\ Skewness(X) =  \\frac{n}{(n-1)(n-2)} \\sum_{i=1}^{n}  \\left [\\frac{X_i-\\bar X}{S} \\right ]^3\n\\]\n\n\n\n\n\n1.6.2 峰度系数\n\n1.6.2.1 总体峰度（Population Kurtosis）\n表示随机变量概率分布的尖峭程度。四阶中心矩与方差平方的比值。\nhttps://www.macroption.com/kurtosis-formula/\n超额峰度 excess kurtosis ：四阶中心矩与方差平方的比值减3。\nhttps://www.macroption.com/excess-kurtosis/\n\\[\nPopulation\\ Kurtosis(X) =  \\frac{E(X_i-E(X))^4}{Var(X)^{2}}-3= E  [(\\frac{X_i-\\mu}{\\sigma})^4] - 3= \\frac{1}{n} \\sum_{i=1}^{n}  (\\frac{X_i-\\mu}{\\sigma} )^4-3\n\\]\n超额峰度的取值范围：\\([-2,+\\infty)\\)\n\n超额峰度＜0，数据分布与正态分布相比较为扁平；\n超额峰度=0，正态分布；\n超额峰度＞0，数据分布与正态分布相比较为高尖。\n\n\nShow the code\nkurtosis&lt;-function(x,na.rm=TRUE){\n    if(na.rm) x&lt;-x[!is.na(x)]\n    n=length(x)\n    μ=mean(x)\n    SD=sd(x)\n    return(c(population_kurtosis= mean(((x-μ)/SD)^4)-3,\n             sample_kurtosis = sum(((x-μ)/SD)^4)*n*(n+1)/(n-1)/(n-2)/(n-3)-3*(n-1)^2/(n-2)/(n-3)))\n}\nkurtosis(x)\n#&gt; population_kurtosis     sample_kurtosis \n#&gt;           -1.377770            0.563368\ne1071::kurtosis(x,type = 3)# 默认\n#&gt; [1] -1.37777\ne1071::kurtosis(x,type = 2)\n#&gt; [1] 0.563368\n\n\n\n1.6.2.2 样本峰度（Sample Kurtosis）\n\\[\nSample \\ Kurtosis(X) =   \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum_{i=1}^{n} \\left [\\frac{X_i-\\bar X}{S} \\right]^4-\\frac{3(n-1)^2}{(n-2)(n-3)}\n\\]",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#标准化变换",
    "href": "quantitative_data.html#标准化变换",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.7 标准化变换",
    "text": "1.7 标准化变换\n\nShow the codescale(mtcars$mpg,center = T,scale = T) %&gt;%  \n    tibble(normalization = .) %&gt;% \n    DT::datatable()",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#统计摘要",
    "href": "quantitative_data.html#统计摘要",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.8 统计摘要",
    "text": "1.8 统计摘要\n\nShow the codesummary(mtcars$mpg)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   10.40   15.43   19.20   20.09   22.80   33.90\nrstatix::get_summary_stats(mtcars,mpg,type = \"full\")\n#&gt; # A tibble: 1 × 13\n#&gt;   variable     n   min   max median    q1    q3   iqr   mad  mean    sd    se\n#&gt;   &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 mpg         32  10.4  33.9   19.2  15.4  22.8  7.38  5.41  20.1  6.03  1.06\n#&gt; # ℹ 1 more variable: ci &lt;dbl&gt;\n\n\npsych::describeBy(mtcars$mpg,group =NULL)\n#&gt;    vars  n  mean   sd median trimmed  mad  min  max range skew kurtosis   se\n#&gt; X1    1 32 20.09 6.03   19.2    19.7 5.41 10.4 33.9  23.5 0.61    -0.37 1.07",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "\n3  相关性\n",
    "section": "",
    "text": "3.1 连续变量\nhttps://corrr.tidymodels.org/articles/using-corrr.html\nhttps://easystats.github.io/correlation/\n相关性：判断两个变量之间的相关关系强度和方向，无论是否独立。\n如果两个连续变量不相互独立时，使用协方差（covariance）来描述两个变量的关系。\n协方差（或相关系数）为零，不相关，说明不存在线性关系，但可能存在非线性关系。\nShow the codedf &lt;- iris[1:4]\n\n# 协方差矩阵\ncov(df)    \n#&gt;              Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; Sepal.Length    0.6856935  -0.0424340    1.2743154   0.5162707\n#&gt; Sepal.Width    -0.0424340   0.1899794   -0.3296564  -0.1216394\n#&gt; Petal.Length    1.2743154  -0.3296564    3.1162779   1.2956094\n#&gt; Petal.Width     0.5162707  -0.1216394    1.2956094   0.5810063",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "correlation.html#连续变量",
    "href": "correlation.html#连续变量",
    "title": "\n3  相关性\n",
    "section": "",
    "text": "3.1.0.1 相关系数\n相关系数的取值范围： \\([-1,1]\\)\n\\[\nr(X,Y)=\\frac {\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y)}{\\sqrt{\\sum_{i=1}^n (x_i-\\bar x)^2 \\sum_{i=1}^n (y_i-\\bar y)^2}}\n\\]\n\nShow the code# Pearson's 积差相关系数 一般要求两个连续变量都服从正态分布\ncorrelation(df,method = \"pearson\",p_adjust = \"holm\")\n#&gt; # Correlation Matrix (pearson-method)\n#&gt; \n#&gt; Parameter1   |   Parameter2 |     r |         95% CI | t(148) |         p\n#&gt; -------------------------------------------------------------------------\n#&gt; Sepal.Length |  Sepal.Width | -0.12 | [-0.27,  0.04] |  -1.44 | 0.152    \n#&gt; Sepal.Length | Petal.Length |  0.87 | [ 0.83,  0.91] |  21.65 | &lt; .001***\n#&gt; Sepal.Length |  Petal.Width |  0.82 | [ 0.76,  0.86] |  17.30 | &lt; .001***\n#&gt; Sepal.Width  | Petal.Length | -0.43 | [-0.55, -0.29] |  -5.77 | &lt; .001***\n#&gt; Sepal.Width  |  Petal.Width | -0.37 | [-0.50, -0.22] |  -4.79 | &lt; .001***\n#&gt; Petal.Length |  Petal.Width |  0.96 | [ 0.95,  0.97] |  43.39 | &lt; .001***\n#&gt; \n#&gt; p-value adjustment method: Holm (1979)\n#&gt; Observations: 150\n\n# Spearman's rank rho相关系数  　　非参数\ncorrelation(df,method = \"spearman\",p_adjust = \"holm\")\n#&gt; # Correlation Matrix (spearman-method)\n#&gt; \n#&gt; Parameter1   |   Parameter2 |   rho |         95% CI |        S |         p\n#&gt; ---------------------------------------------------------------------------\n#&gt; Sepal.Length |  Sepal.Width | -0.17 | [-0.32,  0.00] | 6.56e+05 | 0.041*   \n#&gt; Sepal.Length | Petal.Length |  0.88 | [ 0.84,  0.91] | 66429.35 | &lt; .001***\n#&gt; Sepal.Length |  Petal.Width |  0.83 | [ 0.78,  0.88] | 93208.42 | &lt; .001***\n#&gt; Sepal.Width  | Petal.Length | -0.31 | [-0.45, -0.15] | 7.37e+05 | &lt; .001***\n#&gt; Sepal.Width  |  Petal.Width | -0.29 | [-0.43, -0.13] | 7.25e+05 | &lt; .001***\n#&gt; Petal.Length |  Petal.Width |  0.94 | [ 0.91,  0.95] | 35060.85 | &lt; .001***\n#&gt; \n#&gt; p-value adjustment method: Holm (1979)\n#&gt; Observations: 150\n\n# Kendall's rank tau相关系数  　　非参数\ncorrelation(df,method = \"kendall\",p_adjust = \"holm\")\n#&gt; # Correlation Matrix (kendall-method)\n#&gt; \n#&gt; Parameter1   |   Parameter2 |   tau |         95% CI |     z |         p\n#&gt; ------------------------------------------------------------------------\n#&gt; Sepal.Length |  Sepal.Width | -0.08 | [-0.18,  0.03] | -1.33 | 0.183    \n#&gt; Sepal.Length | Petal.Length |  0.72 | [ 0.66,  0.77] | 12.65 | &lt; .001***\n#&gt; Sepal.Length |  Petal.Width |  0.66 | [ 0.59,  0.71] | 11.34 | &lt; .001***\n#&gt; Sepal.Width  | Petal.Length | -0.19 | [-0.29, -0.08] | -3.22 | 0.004**  \n#&gt; Sepal.Width  |  Petal.Width | -0.16 | [-0.26, -0.05] | -2.67 | 0.015*   \n#&gt; Petal.Length |  Petal.Width |  0.81 | [ 0.77,  0.84] | 13.97 | &lt; .001***\n#&gt; \n#&gt; p-value adjustment method: Holm (1979)\n#&gt; Observations: 150\n\n\n\n3.1.0.2 相关图（correlogram）\n\nShow the codelibrary(see)\n\ncorrelation(df,method = \"pearson\",p_adjust = \"holm\") |&gt;\n  summary(redundant = TRUE) |&gt;  \n  plot()\n\n\n\n\n\n\n\n\n3.1.0.3 显著性检验\n　　零假设为变量之间不相关（即两个总体的相关系数为 0 ） 。函数 cor.test( ) 可用于对相关系数进行显著性检 验。\n统计量\n\\[\nt=\\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}}\n\\]\n\nShow the codecor_test(df, \"Sepal.Length\", \"Sepal.Width\")\n#&gt; Parameter1   |  Parameter2 |     r |        95% CI | t(148) |     p\n#&gt; -------------------------------------------------------------------\n#&gt; Sepal.Length | Sepal.Width | -0.12 | [-0.27, 0.04] |  -1.44 | 0.152\n#&gt; \n#&gt; Observations: 150\n\n\npsych包corr.test() 计算相关系数矩阵和显著性检验\n\nShow the codepsych::corr.test(df)\n#&gt; Call:psych::corr.test(x = df)\n#&gt; Correlation matrix \n#&gt;              Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; Sepal.Length         1.00       -0.12         0.87        0.82\n#&gt; Sepal.Width         -0.12        1.00        -0.43       -0.37\n#&gt; Petal.Length         0.87       -0.43         1.00        0.96\n#&gt; Petal.Width          0.82       -0.37         0.96        1.00\n#&gt; Sample Size \n#&gt; [1] 150\n#&gt; Probability values (Entries above the diagonal are adjusted for multiple tests.) \n#&gt;              Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; Sepal.Length         0.00        0.15            0           0\n#&gt; Sepal.Width          0.15        0.00            0           0\n#&gt; Petal.Length         0.00        0.00            0           0\n#&gt; Petal.Width          0.00        0.00            0           0\n#&gt; \n#&gt;  To see confidence intervals of the correlations, print with the short=FALSE option\n\nprint(psych::corr.test(df), short = FALSE)\n#&gt; Call:psych::corr.test(x = df)\n#&gt; Correlation matrix \n#&gt;              Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; Sepal.Length         1.00       -0.12         0.87        0.82\n#&gt; Sepal.Width         -0.12        1.00        -0.43       -0.37\n#&gt; Petal.Length         0.87       -0.43         1.00        0.96\n#&gt; Petal.Width          0.82       -0.37         0.96        1.00\n#&gt; Sample Size \n#&gt; [1] 150\n#&gt; Probability values (Entries above the diagonal are adjusted for multiple tests.) \n#&gt;              Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; Sepal.Length         0.00        0.15            0           0\n#&gt; Sepal.Width          0.15        0.00            0           0\n#&gt; Petal.Length         0.00        0.00            0           0\n#&gt; Petal.Width          0.00        0.00            0           0\n#&gt; \n#&gt;  Confidence intervals based upon normal theory.  To get bootstrapped values, try cor.ci\n#&gt;             raw.lower raw.r raw.upper raw.p lower.adj upper.adj\n#&gt; Spl.L-Spl.W     -0.27 -0.12      0.04  0.15     -0.27      0.04\n#&gt; Spl.L-Ptl.L      0.83  0.87      0.91  0.00      0.81      0.91\n#&gt; Spl.L-Ptl.W      0.76  0.82      0.86  0.00      0.74      0.88\n#&gt; Spl.W-Ptl.L     -0.55 -0.43     -0.29  0.00     -0.58     -0.25\n#&gt; Spl.W-Ptl.W     -0.50 -0.37     -0.22  0.00     -0.51     -0.20\n#&gt; Ptl.L-Ptl.W      0.95  0.96      0.97  0.00      0.94      0.98",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "correlation.html#分类变量",
    "href": "correlation.html#分类变量",
    "title": "\n3  相关性\n",
    "section": "\n3.2 分类变量",
    "text": "3.2 分类变量\n　　如果独立性检验的结果表明两个变量之间不独立，那么如何量化它们之间相关性的强弱?\n\n3.2.1 列联系数、Phi 系数和 Cramer’s V 系数\nvcd 包里的函数 assocstats( )可以用来计算列联表的 Phi 系数、列联系数和 Cramer’s V 系数。其中， Phi 系数只适用于四格表。 　　\n\nShow the codelibrary(vcd)\nmytable &lt;- table(Arthritis$Sex, Arthritis$Treatment)\nassocstats(mytable)\n#&gt;                      X^2 df P(&gt; X^2)\n#&gt; Likelihood Ratio 0.73748  1  0.39047\n#&gt; Pearson          0.73653  1  0.39078\n#&gt; \n#&gt; Phi-Coefficient   : 0.094 \n#&gt; Contingency Coeff.: 0.093 \n#&gt; Cramer's V        : 0.094\n\n\n\n3.2.2 Kappa 统计量\n对于配对列联表，可以计算一致性指标 Kappa 统计量。 epiDisplay 包里的函数 kap( )可以用于计算一致性的比例以及 Kappa 统计量的值 　　 　　\n\nShow the codemy.matrix &lt;- matrix(c(11, 2, 12, 33), nrow = 2)\nsum(my.matrix)\n#&gt; [1] 58\nvcd::Kappa(my.matrix)\n#&gt;            value    ASE     z Pr(&gt;|z|)\n#&gt; Unweighted 0.455 0.1153 3.945 7.97e-05\n#&gt; Weighted   0.455 0.1153 3.945 7.97e-05\nepiDisplay::kap(my.matrix)\n#&gt; \n#&gt;  Table for calculation of kappa\n#&gt;    A  B\n#&gt; A 11 12\n#&gt; B  2 33\n#&gt; \n#&gt; Observed agreement = 75.86 % \n#&gt; Expected agreement = 55.71 % \n#&gt; Kappa = 0.455 \n#&gt; Standard error = 0.121 , Z = 3.762 , P value = &lt; 0.001 \n#&gt; \n\n\n　　共 58 个对象，每一对象用两种检测方法检测，其中11 个对象的两种检测结果都为阳性， 33 个对象的两种检测结果都是阴性，所以总一致性为 (11 + 33)/58 ≈ 75.86% 。\n\nShow the codechisq.test(my.matrix)$expected\n#&gt;          [,1]     [,2]\n#&gt; [1,] 5.155172 17.84483\n#&gt; [2,] 7.844828 27.15517\n\n\n　为了解释期望一致性和 Kappa 值的含义，先计算各个单元格的期望频数。 对角线上的这两个单元格对应的期望频数分别约为5.155172 和27.15517 ，因此期望一致性为 (5.155172+27.15517)/58≈ 55.71% 。期望一致性是假定两种方法的检测结果都是完全随机的情况下的 一致性。也就是说，即使两种检测方法都毫无作用，平均也能达到 55.71% 的一致性。 Kappa 统计量是超出随机的一致性的部分占最大可能超出随机的一致性的比例。在本例中，前者为 75.86% − 55.71% ， 后者为 100% − 55.71% 。 因此， Kappa 值为 (75.86 - 55.71)/(100 - 55.71) ≈ 0.455\n\n3.2.3 马赛克图\n　　马赛克图中的矩形面积正比于多维列联表中单元格的频率 　　\n\nShow the codemosaicplot(mytable,main =\"马塞克图\" ,\n           xlab =\"Sex\",ylab =  \"Treatment\",las = 1)",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html",
    "href": "nonparametric_test.html",
    "title": "\n11  非参数检验\n",
    "section": "",
    "text": "11.1 秩\n\\[\nF(Median)=P(X\\le Median)=0.5\n\\]\nShow the codex &lt;- c(1,4,2,2,6,9,5)\nrank(x)\n#&gt; [1] 1.0 4.0 2.5 2.5 6.0 7.0 5.0",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#二项分布bn0.5",
    "href": "nonparametric_test.html#二项分布bn0.5",
    "title": "\n11  非参数检验\n",
    "section": "\n11.2 二项分布B(n，0.5)",
    "text": "11.2 二项分布B(n，0.5)\n\nShow the codelibrary(ggplot2)\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(readxl)\ntibble(\n    x = -5:15,\n    y_binom = dbinom(x, size = 10,prob = 0.5),\n) |&gt; \nggplot()+\n    geom_col(aes(x=x,y=y_binom,color=\"binomal Distribution\"),fill=NA)+\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 5, sd = 1),\n                   )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"binomal Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#单样本-wilcoxon-signed-rank-exact-test",
    "href": "nonparametric_test.html#单样本-wilcoxon-signed-rank-exact-test",
    "title": "\n11  非参数检验\n",
    "section": "\n11.3 单样本 Wilcoxon Signed-Rank exact test",
    "text": "11.3 单样本 Wilcoxon Signed-Rank exact test\n如果样本数据没有通过正态分布检验就要采用单样本wilcoxon符号秩检验进行计算。使用该检验需要满足的条件是样本值均匀地分布在均值两侧。\n\nShow the codeset.seed(123)\nx &lt;- runif(n = 100,min = 6,max = 8)\nhist(x)\n\n\n\n\n\n\nShow the codeshapiro.test(x)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x\n#&gt; W = 0.95237, p-value = 0.001192\nwilcox.test(x, mu=7) \n#&gt; \n#&gt;  Wilcoxon signed rank test with continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; V = 2518, p-value = 0.9822\n#&gt; alternative hypothesis: true location is not equal to 7",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#双样本",
    "href": "nonparametric_test.html#双样本",
    "title": "\n11  非参数检验\n",
    "section": "\n11.4 双样本",
    "text": "11.4 双样本\n\n11.4.1 配对 Wilcoxon’s signed-rank test\n\\[\nT_++T_-=\\frac{n(n+1)}{2},n为非零配对差值的数量\n\\]\n\\[\nT=min{(T_+,T_-)}\n\\]\n5 ≤ n ≤30，附表T0\nn＞16，正态近似法\n\nShow the code\ndf &lt;- tibble(\n    low=c(958.5,838.4,612.2,812.9,739.0,899.4,758.5,695.0,749.7,815.5),\n    high=c(958.5,866.5,788.9,815.2,783.2,910.9,760.8,870.8,862.3,799.9),\n)\n\nshapiro.test(df$high-df$low)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$high - df$low\n#&gt; W = 0.79689, p-value = 0.01329\n\n# 忽略  差异绝对值为“0”的数剔除；\nwilcox.test(df$low[-1],df$high[-1],exact = T,paired = T)\n#&gt; \n#&gt;  Wilcoxon signed rank exact test\n#&gt; \n#&gt; data:  df$low[-1] and df$high[-1]\n#&gt; V = 4, p-value = 0.02734\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n11.4.2 独立 Wilcoxon’s Rank-Sum 检验 (Mann-Whitney U 检验)\n当两个样本不满足正态分布时，使用Wilcoxon秩和检验进行非参数检验\n用于比较两个独立样本的中位数是否相等。\n\\[\nWilxoxon秩和\\ T=min\\{T_1,T_2\\}\n\\]\n\nShow the codeMVR = c(38, 29, 35, 33, 38, 41, 31)\nMVP = c(32, 43, 44, 81, 35, 46, 37, 45, 44)\nshapiro.test(c(MVR,MVP))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  c(MVR, MVP)\n#&gt; W = 0.70443, p-value = 0.0001889\n\ncombined_data &lt;- c(MVR, MVP)\nranked_data &lt;- rank(combined_data)\nranked_data \n#&gt;  [1]  8.5  1.0  5.5  4.0  8.5 10.0  2.0  3.0 11.0 12.5 16.0  5.5 15.0  7.0 14.0\n#&gt; [16] 12.5\n\nMVR_ranks &lt;- ranked_data[1:length(MVR)]\nMVP_ranks &lt;- ranked_data[(length(MVR)+1):length(combined_data)]\n\nT1 &lt;- sum(MVR_ranks)\nT2 &lt;- sum(MVP_ranks)\n\nT1-length(MVR)*(length(MVR)+1)/2\n#&gt; [1] 11.5\nwilcox.test(MVR,MVP,exact = F,correct = F)\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  MVR and MVP\n#&gt; W = 11.5, p-value = 0.03386\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n11.4.2.1 W统计量\nn1&lt;10,n2-n1&lt;10，附录\nn1&gt;10,n2&gt;10，正态近似法\n\nShow the codex &lt;- c(17, 12, 13, 16, 9, 19, 21, 12, 18, 17)\ny &lt;- c(10, 6, 15, 9, 8, 11, 8, 16, 13, 7, 5, 14)\nwilcox.test(x, y, correct = F)\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  x and y\n#&gt; W = 101.5, p-value = 0.006124\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\nrank(c(x,y))[1:10] |&gt; sum()\n#&gt; [1] 156.5\nrank(c(x,y))[11:22] |&gt; sum()\n#&gt; [1] 96.5\n\n156.5-10*11/2\n#&gt; [1] 101.5\n\na &lt;- wilcox.test(x,y,correct=FALSE)\nstr(a) \n#&gt; List of 7\n#&gt;  $ statistic  : Named num 102\n#&gt;   ..- attr(*, \"names\")= chr \"W\"\n#&gt;  $ parameter  : NULL\n#&gt;  $ p.value    : num 0.00612\n#&gt;  $ null.value : Named num 0\n#&gt;   ..- attr(*, \"names\")= chr \"location shift\"\n#&gt;  $ alternative: chr \"two.sided\"\n#&gt;  $ method     : chr \"Wilcoxon rank sum test\"\n#&gt;  $ data.name  : chr \"x and y\"\n#&gt;  - attr(*, \"class\")= chr \"htest\"\nn1 &lt;- length(x)\na$statistic &lt;- a$statistic + n1*(n1+1)/2\nnames(a$statistic) &lt;- \"T.W\"\na\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  x and y\n#&gt; T.W = 156.5, p-value = 0.006124\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n11.4.2.2 曼-惠特尼 U 统计量\n\\[\n曼-惠特尼U统计量= 威尔科克森W(较小秩和)-\\frac{n_{T_{min}}(n_{T_{min}}+1)}{2}\n\\]\n\n11.4.2.3 Z 统计量 coin::wilcox_test()\n\n\nShow the codelibrary(coin)\ndf &lt;- read_excel(\"data/coin-wilcox_test.xlsx\") |&gt; \n    mutate(group=as.factor(group))\ndf\n#&gt; # A tibble: 240 × 2\n#&gt;    HADS得分 group\n#&gt;       &lt;dbl&gt; &lt;fct&gt;\n#&gt;  1       14 1    \n#&gt;  2       14 1    \n#&gt;  3        7 1    \n#&gt;  4       22 1    \n#&gt;  5        7 1    \n#&gt;  6       12 1    \n#&gt;  7       15 1    \n#&gt;  8       17 1    \n#&gt;  9        8 1    \n#&gt; 10       14 1    \n#&gt; # ℹ 230 more rows\n\nrank &lt;- rank(df$HADS得分)\n\ng1rankSum &lt;- sum(rank[1:120])\ng2rankSum &lt;- sum(rank[121:240])\n\n\nSPSS_威尔科克森W &lt;- min(g1rankSum,g2rankSum)\nSPSS_威尔科克森W \n#&gt; [1] 13965.5\nSPSS_曼惠特尼U &lt;-  SPSS_威尔科克森W -120*121/2\nSPSS_曼惠特尼U\n#&gt; [1] 6705.5\n\nwilcox.test(HADS得分 ~ group,data=df,correct=F)\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  HADS得分 by group\n#&gt; W = 7694.5, p-value = 0.3572\n#&gt; alternative hypothesis: true location shift is not equal to 0\n# SPSS  z统计量\ncoin::wilcox_test( HADS得分 ~ group,data=df, distribution = \"asymptotic\") #   exact   asymptotic    approximate\n#&gt; \n#&gt;  Asymptotic Wilcoxon-Mann-Whitney Test\n#&gt; \n#&gt; data:  HADS得分 by group (1, 2)\n#&gt; Z = 0.92062, p-value = 0.3572\n#&gt; alternative hypothesis: true mu is not equal to 0\ncoin::wilcox_test( HADS得分 ~ group,data=df, distribution = \"approximate\")\n#&gt; \n#&gt;  Approximative Wilcoxon-Mann-Whitney Test\n#&gt; \n#&gt; data:  HADS得分 by group (1, 2)\n#&gt; Z = 0.92062, p-value = 0.3589\n#&gt; alternative hypothesis: true mu is not equal to 0\n\n\nSPSS 用较小秩和减去对应 n(n+1)/2\nR有时用较小秩和减去对应 n(n+1)/2，有时用较大秩和减去对应 n(n+1)/2\n\nShow the codewilcox.test(HADS得分 ~ group,data=df,exact = F,correct = F)\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  HADS得分 by group\n#&gt; W = 7694.5, p-value = 0.3572\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n# SPSS_曼惠特尼U\ng2rankSum-120*121/2\n#&gt; [1] 6705.5\n\n\n# R中W\ng1rankSum-120*121/2\n#&gt; [1] 7694.5\n\n\n\nn1&gt;20\n\n11.4.3 Wilcoxon Distribution\n\nShow the code\ntibble(\n    x = 0:100,\n    y =dwilcox(x,m = 7,n = 9)\n) |&gt; \n    ggplot() +\n    geom_col(aes(x,y),fill=\"lightblue\",color=\"black\")+\n    ggtitle(\"Wilcoxon Distribution\")",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#多样本",
    "href": "nonparametric_test.html#多样本",
    "title": "\n11  非参数检验\n",
    "section": "\n11.5 多样本",
    "text": "11.5 多样本\n\n11.5.1 独立 Kruskal-Wallis 检验\n用于比较三个或更多独立样本的中位数是否相等。\n假设：\n\n随机，独立\n每个样本至少5个观测\n能够计算秩次\n\n\nShow the codekruskal.test(weight~group,data = PlantGrowth)\n#&gt; \n#&gt;  Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data:  weight by group\n#&gt; Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.01842\n\n\n\n11.5.1.1 事后多重比较\n\nShow the codepairwise.wilcox.test(PlantGrowth$weight,PlantGrowth$group,p.adjust.method = \"fdr\",exact=F)\n#&gt; \n#&gt;  Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n#&gt; \n#&gt; data:  PlantGrowth$weight and PlantGrowth$group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.199 -    \n#&gt; trt2 0.096 0.034\n#&gt; \n#&gt; P value adjustment method: fdr",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#相关-friedman-检验",
    "href": "nonparametric_test.html#相关-friedman-检验",
    "title": "\n11  非参数检验\n",
    "section": "\n11.6 相关 Friedman 检验",
    "text": "11.6 相关 Friedman 检验\n用于比较三个或更多相关样本的中位数是否相等。\n\nShow the code# 假设有三个相关样本 x, y, z\nx &lt;- c(14, 17, 20, 23, 25)\ny &lt;- c(15, 18, 21, 24, 26)\nz &lt;- c(16, 19, 22, 25, 27)\n\n# 将样本合并成一个数据框，并指定组别和受试者\ndata &lt;- data.frame(\n  value = c(x, y, z),\n  group = factor(rep(c(\"x\", \"y\", \"z\"), each = 5)),\n  subject = factor(rep(1:5, 3))\n)\n\n# 使用 friedman.test() 函数进行检验\nresult &lt;- friedman.test(value ~ group | subject, data = data)\n\n# 输出检验结果\nprint(result)\n#&gt; \n#&gt;  Friedman rank sum test\n#&gt; \n#&gt; data:  value and group and subject\n#&gt; Friedman chi-squared = 10, df = 2, p-value = 0.006738",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#kendalls-tau-检验",
    "href": "nonparametric_test.html#kendalls-tau-检验",
    "title": "\n11  非参数检验\n",
    "section": "\n11.7 Kendall’s Tau 检验",
    "text": "11.7 Kendall’s Tau 检验\n用途：用于检验两个变量之间的相关性。\n\nShow the code# 假设有两个变量 x 和 y\nx &lt;- c(14, 17, 20, 23, 25)\ny &lt;- c(15, 18, 21, 24, 26)\n\n# 使用 cor.test() 函数进行 Kendall's Tau 检验\nresult &lt;- cor.test(x, y, method = \"kendall\")\n\n# 输出检验结果\nprint(result)\n#&gt; \n#&gt;  Kendall's rank correlation tau\n#&gt; \n#&gt; data:  x and y\n#&gt; T = 10, p-value = 0.01667\n#&gt; alternative hypothesis: true tau is not equal to 0\n#&gt; sample estimates:\n#&gt; tau \n#&gt;   1",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#spearmans-rank-correlation-检验",
    "href": "nonparametric_test.html#spearmans-rank-correlation-检验",
    "title": "\n11  非参数检验\n",
    "section": "\n11.8 Spearman’s Rank Correlation 检验",
    "text": "11.8 Spearman’s Rank Correlation 检验\n用途：用于检验两个变量之间的相关性，适用于数据非线性关系。\n\nShow the code# 假设有两个变量 x 和 y\nx &lt;- c(14, 17, 20, 23, 25)\ny &lt;- c(15, 18, 21, 24, 26)\n\n# 使用 cor.test() 函数进行 Spearman's Rank Correlation 检验\nresult &lt;- cor.test(x, y, method = \"spearman\")\n\n# 输出检验结果\nprint(result)\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  x and y\n#&gt; S = 4.4409e-15, p-value = 0.01667\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt; rho \n#&gt;   1",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html",
    "href": "SurvivalAnalysis.html",
    "title": "\n17  生存分析\n",
    "section": "",
    "text": "17.1 生存函数\n医学研究中的生存数据建模\n\\[\nS(t)=P(T&gt;t)=1-F(t)=\\int_{t}^{+\\infty}f(x)dx\n\\]\n其中S(t)是累计生存概率或生存率，量化了生存时间大于t的概率。f(x)是密度函数，呈右偏态分布，反映了任意时间点 t 终点事件的瞬时发生率。F(t)=P(T&lt;t)是f(t)在区间[0,t]的累计形式，也称为分布函数或累积函数。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#乘积极限法kaplan-meier",
    "href": "SurvivalAnalysis.html#乘积极限法kaplan-meier",
    "title": "\n17  生存分析\n",
    "section": "\n17.2 乘积极限法(Kaplan-Meier)",
    "text": "17.2 乘积极限法(Kaplan-Meier)\nproduct limit method 也称为Kaplan-Meier 法。\n\\(t_1&lt;t_2&lt;t_3&lt;...&lt;t_n\\)，样本量大小n，ti 代表个体i发生终点事件或右删失的时间。由于一些个体有相同的生存时间，它们被称为 tied 观测时间，生存时间的个数小于样本量n。\n\n17.2.1 点估计S(t)\n\\(n_1&gt;n_2&gt;n_3&gt;...&gt;n_n\\) ,ni d代表在时间点ti 暴露于特定事件风险的幸存者数量。\n\\(d_i\\) 代表在时间点ti 发生终点事件的数量。（如果没有 tie，di=1或0）\n生存率的KM方法估计公式：\n\\[\n\\hat S(t)=\\prod_{t_i\\le t}\\frac{n_i-d_i}{n_i}\n\\tag{17.1}\\]\nEquation 17.1 包括了删失情况，如果从ti-1 到ti 发生了删失，但没有终点事件，di =0，条件概率等于1。\n\n17.2.2 区间估计S(t)\n(1-α)×100% CI \\([\\hat S(t)-z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]},\\hat S(t)+z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]}]\\)\n其中\\(Var\\left [\\hat S(t)  \\right]=\\hat S(t)^2\\sum_{t_i\\le t}\\frac{d_i}{n_i(n_i-d_i)}\\) (Greenwood method )\n\n17.2.3 示例\nhttps://biostatsquid.com/easy-survival-analysis-r-tutorial/\n\nShow the codelibrary(survminer)\nlibrary(survival)\nlibrary(readr)\nlibrary(ggsurvfit)\ndf &lt;- read_csv(\"data/log-rank-survival.csv\")\n\n\nsurv_obj &lt;- with(df, Surv(Days,status))\n\nsurv_fit1 &lt;-survfit(surv_obj ~1,data=df)\n# t_i  =  surv_fit1$time\n# n_i = surv_fit1$n.risk\n\n# d_i = surv_fit1$n.event\n\n# cnesored\nsurv_fit1$n.censor\n#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17\n\n# 生存率survival\nsurv_fit1$surv\n#&gt;  [1] 0.9821429 0.9285714 0.8928571 0.8571429 0.8392857 0.7857143 0.7678571\n#&gt;  [8] 0.7321429 0.6250000 0.5892857 0.5714286 0.5535714 0.5178571 0.4642857\n#&gt; [15] 0.4464286 0.3928571 0.3750000 0.3571429 0.3392857 0.3214286 0.3035714\n#&gt; [22] 0.3035714\n\nsummary(surv_fit1)\n#&gt; Call: survfit(formula = surv_obj ~ 1, data = df)\n#&gt; \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    11     56       1    0.982  0.0177        0.948        1.000\n#&gt;    13     55       3    0.929  0.0344        0.864        0.999\n#&gt;    14     52       2    0.893  0.0413        0.815        0.978\n#&gt;    15     50       2    0.857  0.0468        0.770        0.954\n#&gt;    16     48       1    0.839  0.0491        0.748        0.941\n#&gt;    17     47       3    0.786  0.0548        0.685        0.901\n#&gt;    18     44       1    0.768  0.0564        0.665        0.887\n#&gt;    19     43       2    0.732  0.0592        0.625        0.858\n#&gt;    20     41       6    0.625  0.0647        0.510        0.766\n#&gt;    21     35       2    0.589  0.0657        0.474        0.733\n#&gt;    23     33       1    0.571  0.0661        0.455        0.717\n#&gt;    24     32       1    0.554  0.0664        0.438        0.700\n#&gt;    25     31       2    0.518  0.0668        0.402        0.667\n#&gt;    27     29       3    0.464  0.0666        0.350        0.615\n#&gt;    28     26       1    0.446  0.0664        0.333        0.598\n#&gt;    30     25       3    0.393  0.0653        0.284        0.544\n#&gt;    32     22       1    0.375  0.0647        0.267        0.526\n#&gt;    38     21       1    0.357  0.0640        0.251        0.508\n#&gt;    39     20       1    0.339  0.0633        0.235        0.489\n#&gt;    40     19       1    0.321  0.0624        0.220        0.470\n#&gt;    45     18       1    0.304  0.0614        0.204        0.451\n\nggsurvfit(surv_fit1, linewidth =1)+\n    add_confidence_interval()+\n    scale_ggsurvfit()+\n    add_risktable() +\n    labs(x = \"Days\")\n\n\n\n\n\n\n\n\nShow the code# 估计 x-天 的生存率\n\nsummary( surv_fit1, times = c(0,30,50))$surv\n#&gt; [1] 1.0000000 0.3928571 0.3035714\n\n# 中位生存率 median\nsurv_fit1\n#&gt; Call: survfit(formula = surv_obj ~ 1, data = df)\n#&gt; \n#&gt;       n events median 0.95LCL 0.95UCL\n#&gt; [1,] 56     39     27      21      39",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#单因素生存曲线的比较",
    "href": "SurvivalAnalysis.html#单因素生存曲线的比较",
    "title": "\n17  生存分析\n",
    "section": "\n17.3 单因素生存曲线的比较",
    "text": "17.3 单因素生存曲线的比较\n\n\n检验方法\n权重\n\n\n\nlog-rank test\n1\n\n\nWilcoxon test\nnj\n\n\n\nTarone-Ware test\n\\(\\sqrt{n_j}\\)\n\n\nPeto test\n\\(\\hat S(t_j)\\)\n\n\n\n\\[\n\\chi^2=\\frac{\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)^2}{\\hat {Var}\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)}\n\\]",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#log-rank-test",
    "href": "SurvivalAnalysis.html#log-rank-test",
    "title": "\n17  生存分析\n",
    "section": "\n17.4 log-rank test",
    "text": "17.4 log-rank test\n\nH0 :两总体的生存曲线是相同的。\n\n计算当第j次发生终点事件各组终点事件的期望值（e1j ,e2j ）\n\\(e_{1j}=\\left ( \\frac{n_{1j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n\\(e_{2j}=\\left ( \\frac{n_{2j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n其中mij 表示在第 j 个时间点第 i 组终点事件的数量，nij 表示在第 j 个时间点第 i 组初始观测的数量\n\n\n对所有时间点对终点事件的观测值和期望值的差异求和\n\\(O_i-Ei=\\sum_j(m_{ij}-e_{ij})\\ \\ \\ (i=1,2)\\)\n计算其方差估计值\n\\(\\hat{Var}=\\sum_j\\frac{n_{1j}n_{2j}(m_{1j}+m_{2j})(n_{1j}+n_{2j}-m_{1j}-m_{2j})}{(n_{1j}+n_{2j})^2(n_{1j}+n_{2j}-1)}\\ \\ \\ (i=1,2)\\)\n\n\n计算log-rank test 的检验统计量\n\\[\n\\chi^2=\\frac{(O_1-E_1)^2}{\\hat{Var}(O_1-E_1)} \\ 或者 \\ \\chi^2=\\frac{(O_2-E_2)^2}{\\hat{Var}(O_2-E_2)}\n\\]\n也可以近似估计为\n\\[\n\\chi^2=\\sum_{i=1}^2\\frac{(O_i-E_i)^2}{E_i} \\sim \\chi^2(\\nu=1)\n\\]\n\n\n\nShow the code\nsurv_fit2&lt;-survfit(surv_obj ~ treatment,data=df)\nggsurvplot(surv_fit2, linewidth =1,\n          data = df,\n          censor.shape = \"|\", censor.size = 4,\n          pval = T,conf.int = T,risk.table = T,risk.table.col = \"strata\",\n          legend.labs = c(\"CON\",\"DPVB\",\"LDRT\",\"LR-DPVB\"),\n          risk.table.height = .25,\n          ggtheme = theme_bw()\n            )+\n    labs(x = \"Days\")\n#&gt; NULL\n\n\n\nShow the code# 执行Log-rank检验\nlogrank_test &lt;- survdiff( Surv(Days,status) ~ treatment,data = df)\nlogrank_test\n#&gt; Call:\n#&gt; survdiff(formula = Surv(Days, status) ~ treatment, data = df)\n#&gt; \n#&gt;                    N Observed Expected (O-E)^2/E (O-E)^2/V\n#&gt; treatment=CON     14       14     4.46     20.40     26.03\n#&gt; treatment=DPVB    14        9    13.26      1.37      2.19\n#&gt; treatment=LDRT    14       14     5.53     12.99     16.92\n#&gt; treatment=LR_DPVB 14        2    15.76     12.01     22.67\n#&gt; \n#&gt;  Chisq= 58.4  on 3 degrees of freedom, p= 1e-12\nlogrank_test$chisq\n#&gt; [1] 58.43627\nlogrank_test$pvalue\n#&gt; [1] 1.268397e-12\n\n\n\nShow the code\n\nsurvdiff( Surv(Days,status) ~ treatment,\n          data = df |&gt; dplyr::filter(treatment %in% c(\"CON\", \"DPVB\")))\n#&gt; Call:\n#&gt; survdiff(formula = Surv(Days, status) ~ treatment, data = dplyr::filter(df, \n#&gt;     treatment %in% c(\"CON\", \"DPVB\")))\n#&gt; \n#&gt;                 N Observed Expected (O-E)^2/E (O-E)^2/V\n#&gt; treatment=CON  14       14      5.3     14.31      24.1\n#&gt; treatment=DPVB 14        9     17.7      4.28      24.1\n#&gt; \n#&gt;  Chisq= 24.1  on 1 degrees of freedom, p= 9e-07\n\nsurvdiff( Surv(Days,status) ~ treatment,\n          data = df |&gt; dplyr::filter(treatment %in% c(\"CON\", \"LDRT\")))\n#&gt; Call:\n#&gt; survdiff(formula = Surv(Days, status) ~ treatment, data = dplyr::filter(df, \n#&gt;     treatment %in% c(\"CON\", \"LDRT\")))\n#&gt; \n#&gt;                 N Observed Expected (O-E)^2/E (O-E)^2/V\n#&gt; treatment=CON  14       14       12     0.331     0.716\n#&gt; treatment=LDRT 14       14       16     0.248     0.716\n#&gt; \n#&gt;  Chisq= 0.7  on 1 degrees of freedom, p= 0.4\n\nsurvdiff( Surv(Days,status) ~ treatment,\n          data = df |&gt; dplyr::filter(treatment %in% c(\"CON\", \"LR_DPVB\")))\n#&gt; Call:\n#&gt; survdiff(formula = Surv(Days, status) ~ treatment, data = dplyr::filter(df, \n#&gt;     treatment %in% c(\"CON\", \"LR_DPVB\")))\n#&gt; \n#&gt;                    N Observed Expected (O-E)^2/E (O-E)^2/V\n#&gt; treatment=CON     14       14     4.73     18.16      31.1\n#&gt; treatment=LR_DPVB 14        2    11.27      7.62      31.1\n#&gt; \n#&gt;  Chisq= 31.1  on 1 degrees of freedom, p= 2e-08",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html",
    "href": "simple_linear_regression.html",
    "title": "\n12  线性回归\n",
    "section": "",
    "text": "12.1 一元线性回归\n线性模型用于解释一个连续因变量和一个或多个自变量之间的线性关系。模型形式一般为：\n\\[\nY=X\\beta + \\epsilon\n\\]\n其中， Y 是因变量，X 是自变量矩阵，β 是回归系数，ϵ 是误差项。\n数据下载网站\nlinear regression model：\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+\\epsilon_i,其中\\epsilon_i\\sim N(0,\\sigma^2)\n\\]\nShow the code#linear model specification 线性模型规范\nlm_spec &lt;-linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;%\n  set_engine(\"lm\")  \nlm_spec\n#&gt; Linear Regression Model Specification (regression)\n#&gt; \n#&gt; Computational engine: lm\nShow the codelm_tv &lt;- lm_spec %&gt;%  fit(sales ~ TV, data = advertising)\n# 模型摘要\nsummary(lm_tv$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.3860 -1.9545 -0.1913  2.0671  7.2124 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***\n#&gt; TV          0.047537   0.002691   17.67   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.259 on 198 degrees of freedom\n#&gt; Multiple R-squared:  0.6119, Adjusted R-squared:  0.6099 \n#&gt; F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16\n\n# 参数估计值、标准误、统计量、p值\nbroom::tidy(lm_tv, conf.int=T)\n#&gt; # A tibble: 2 × 7\n#&gt;   term        estimate std.error statistic  p.value conf.low conf.high\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)   7.03     0.458        15.4 1.41e-35   6.13      7.94  \n#&gt; 2 TV            0.0475   0.00269      17.7 1.47e-42   0.0422    0.0528\n# 模型统计信息\nbroom::glance(lm_tv) \n#&gt; # A tibble: 1 × 12\n#&gt;   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n#&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     0.612         0.610  3.26      312. 1.47e-42     1  -519. 1044. 1054.\n#&gt; # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html#一元线性回归",
    "href": "simple_linear_regression.html#一元线性回归",
    "title": "\n12  线性回归\n",
    "section": "",
    "text": "12.1.1 点须图\n\nShow the code\n# 整理回归模型结果\ntidy_lm &lt;- tidy(lm_tv, conf.int=T) %&gt;% dplyr::filter(term !='(Intercept)' )\n# 绘制点须图\nggplot(tidy_lm, aes(x = estimate, y = term)) +\n  geom_point(size = 2, color = \"black\") + # 绘制点\n  geom_errorbarh(aes(xmin = conf.low, \n                     xmax = conf.high), \n                 height = 0, color = \"black\") + # 绘制误差线\n  geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2) + # 绘制参考线\n  labs(x = NULL, y = NULL) \n\n\n\n\n\n\n\n\n12.1.2 预测\n\nShow the code# 预测\nstats::predict(lm_tv, new_data = advertising) %&gt;% \n    head(n = 10)\n#&gt; # A tibble: 10 × 1\n#&gt;    .pred\n#&gt;    &lt;dbl&gt;\n#&gt;  1 18.0 \n#&gt;  2  9.15\n#&gt;  3  7.85\n#&gt;  4 14.2 \n#&gt;  5 15.6 \n#&gt;  6  7.45\n#&gt;  7  9.77\n#&gt;  8 12.7 \n#&gt;  9  7.44\n#&gt; 10 16.5\n\n# 置信区间 平均响应值       取决于方差和样本量     随样本量增加收缩\npredict(lm_tv, new_data = advertising, type = \"conf_int\") %&gt;% \n    head(n = 10)\n#&gt; # A tibble: 10 × 2\n#&gt;    .pred_lower .pred_upper\n#&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n#&gt;  1       17.3        18.6 \n#&gt;  2        8.44        9.86\n#&gt;  3        7.02        8.68\n#&gt;  4       13.8        14.7 \n#&gt;  5       15.1        16.1 \n#&gt;  6        6.58        8.31\n#&gt;  7        9.11       10.4 \n#&gt;  8       12.3        13.2 \n#&gt;  9        6.58        8.31\n#&gt; 10       16.0        17.1\n\n# 单个新观测值         主要取决于方差\npredict(lm_tv, new_data = advertising, type = \"pred_int\") %&gt;% \n    head(n = 10)\n#&gt; # A tibble: 10 × 2\n#&gt;    .pred_lower .pred_upper\n#&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n#&gt;  1      11.5          24.4\n#&gt;  2       2.68         15.6\n#&gt;  3       1.37         14.3\n#&gt;  4       7.79         20.7\n#&gt;  5       9.18         22.1\n#&gt;  6       0.962        13.9\n#&gt;  7       3.31         16.2\n#&gt;  8       6.30         19.2\n#&gt;  9       0.957        13.9\n#&gt; 10      10.1          23.0\n\n\n# 比较观测值与预测值\naugment(lm_tv, new_data = advertising) %&gt;%\n    select(sales, .pred) %&gt;%\n    head(n = 10)\n#&gt; # A tibble: 10 × 2\n#&gt;    sales .pred\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1  22.1 18.0 \n#&gt;  2  10.4  9.15\n#&gt;  3   9.3  7.85\n#&gt;  4  18.5 14.2 \n#&gt;  5  12.9 15.6 \n#&gt;  6   7.2  7.45\n#&gt;  7  11.8  9.77\n#&gt;  8  13.2 12.7 \n#&gt;  9   4.8  7.44\n#&gt; 10  10.6 16.5\n\n\npredict(lm_tv$fit, new_data = advertising, interval = \"confidence\") %&gt;% \n    head(n = 10)\npredict(lm_tv$fit, new_data = advertising, interval = \"prediction\") %&gt;% \n    head(n = 10)",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html#模型假设",
    "href": "simple_linear_regression.html#模型假设",
    "title": "\n12  线性回归\n",
    "section": "\n12.2 模型假设",
    "text": "12.2 模型假设\n一般线性模型中，其自变量全部为固定效应自变量，4点假设：\n\n因变量 Y 为连续型数值变量\n线性\n\n保证各实测点到回归直线的纵向距离的平方和最小，即使得残差平方和最小。\n\\[\nQ=\\sum (Y-\\hat Y)^2\n\\]\n\nShow the code# 可视化\naugment(lm_tv, new_data = advertising) %&gt;%\n    ggplot(aes(x = TV)) +\n    geom_linerange(aes(ymin = sales, ymax = .pred)) +\n    geom_point(aes(y = sales), color = \"red\") +\n    geom_abline(\n        intercept = coef(lm_tv$fit)[1],\n        slope = coef(lm_tv$fit)[2],\n        color = \"blue\",\n        linewidth = 1\n    )\n\n\n\n\n\n\n\n\n残差的正态性 \\(\\epsilon\\sim N(0,\\sigma^2)\\)\n方差齐性 \\(Var(ε_i ​ )=σ^2\\)\n残差的独立性",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html#模型诊断",
    "href": "simple_linear_regression.html#模型诊断",
    "title": "\n12  线性回归\n",
    "section": "\n12.3 模型诊断",
    "text": "12.3 模型诊断\n\nShow the codeautoplot(lm_tv, which = 1:6, ncol = 2, label.size = 3)\n\n\n\n\n\n\n\n\n12.3.1 残差图\n预测值与残差的关系，线性度，同方差\n\nShow the code# 检查线性回归模型的残差是否与预测值无关，即残差的分布是否随机。\n# 残差应该随机分布在0附近\ntibble(\n    `Fitted values`=fitted(lm_tv$fit),\n    Residuals = residuals(lm_tv$fit)\n) %&gt;% ggplot(aes(x = `Fitted values` , y = Residuals)) +\n  geom_point(pch=21) +\n    geom_smooth(formula = \"y~x\",color=\"red\",lwd=0.5)+\n  geom_hline(yintercept = 0,lty=2) +\n  labs(x = \"Fitted Values\", y = \"Residuals\")\n\n\n\n\n\n\n\n\n12.3.2 Q-Q图\n标准化残差正态性\n\nShow the codetibble(\n       StandardizedResiduals =rstandard(lm_tv$fit) ) %&gt;% \n    ggplot(aes(sample=StandardizedResiduals)) +\n    stat_qq(pch=21)+\n    stat_qq_line(color=\"red\",lty=2)+\n    labs(x = \"Theoretical Quantiles\", y = \"Sample quantiles\")\n\n\n\n\n\n\n\n\n12.3.3 Scale-Location 图\n检查同方差性，如果看到漏斗形（残差随着拟合值增大而增大），则可能存在异方差性问题。\n标准化残差平方根图\n检查残差的正态性，如果看到残差的分布围绕 0 随机散布，没有明显的模式，模型拟合是理想的。\n\nShow the codeplot(lm_tv$fit, which = 3)\n\n\n\n\n\n\n\n\nShow the code# 绘制 Scale-Location 图\ntibble(\n    fitted_values=fitted(lm_tv$fit),\n    StandardizedResiduals = rstudent(lm_tv$fit) ,\n) %&gt;%\n    ggplot(aes(x = fitted_values, y = sqrt(abs(StandardizedResiduals)))) +\n    geom_point(pch=21) +\n    geom_smooth(color=\"red\",lwd=0.5)+\n    labs(title = \"Scale-Location Plot\",x = \"Fitted Values\", y = \"√|Standardized residuals|\")\n\n\n\n\n\n\n\n\n12.3.4 Cook’s距离\n\n\nShow the codeset.seed(1011)\nx&lt;-rnorm(9)               #random 9 values\nx[10]&lt;-5                  #value far from the others\ny&lt;-rnorm(10,0.5+2*x,1)   #generate y\n\n#plot the data\nlmodel&lt;-lm(y~x)           #fit the model\nplot(x,y)                 #plot the data\nabline(line(x,y))        # add the regression line\n\n\n\n\n\n\nShow the codeinfluence.measures(lmodel)   \n#&gt; Influence measures of\n#&gt;   lm(formula = y ~ x) :\n#&gt; \n#&gt;     dfb.1_   dfb.x   dffit cov.r  cook.d   hat inf\n#&gt; 1  -0.0724 -0.0137 -0.0837 1.431 0.00397 0.103    \n#&gt; 2  -0.2607  0.1637 -0.2717 1.388 0.03993 0.157    \n#&gt; 3   0.0822 -0.0555  0.0869 1.554 0.00430 0.169    \n#&gt; 4   0.2679  0.0174  0.2935 1.178 0.04433 0.100    \n#&gt; 5   0.1102  0.0548  0.1490 1.408 0.01238 0.116    \n#&gt; 6  -0.5785  0.1207 -0.5854 0.724 0.13792 0.104    \n#&gt; 7   0.4851 -0.1676  0.4851 0.925 0.10651 0.114    \n#&gt; 8  -0.6059  0.3277 -0.6179 0.848 0.16313 0.139    \n#&gt; 9   0.4957 -0.2572  0.5034 0.996 0.11760 0.135    \n#&gt; 10  0.0157 -1.0428 -1.1090 9.033 0.68380 0.863   *\n\n\n\nShow the codeplot(lm_tv$fit,4)  \n\n\n\n\n\n\n\n\nShow the codethreshold &lt;- 4 / (nrow(advertising)-length(lm_tv$fit$coefficients)-2)\n                  \n                 \ntibble(\n    x = 1:nrow(advertising),\n    cooks_distance = cooks.distance(lm_tv$fit),\n    label = factor(if_else(cooks_distance&gt;threshold,x,NA))\n) %&gt;% \n    ggplot() +\n    geom_segment(aes(\n        x = x,\n        xend = x,\n        y = 0,\n        yend = cooks_distance ,\n    )) +\n    geom_text(aes(\n        x = x,\n        y =cooks_distance ,\n        label =label,\n    ), vjust = -0.2) +\n    labs(x = \"Observation Index\", y = \"Cook's Distance\")\n\n\n\n\n\n\n\n\n12.3.5 残差-杠杆值图\n\n\nShow the code\ninfluence(lmodel)$hat     #leverage\n#&gt;         1         2         3         4         5         6         7         8 \n#&gt; 0.1027407 0.1570337 0.1686229 0.1003533 0.1156210 0.1044403 0.1135604 0.1391403 \n#&gt;         9        10 \n#&gt; 0.1353478 0.8631394\n\n\n1/10 + (x-mean(x))^2/(var(x)*9)  #leverage manually computed \n#&gt;  [1] 0.1027407 0.1570337 0.1686229 0.1003533 0.1156210 0.1044403 0.1135604\n#&gt;  [8] 0.1391403 0.1353478 0.8631394\n\n\n\n\nShow the codeinfluence(lmodel)$coefficients     #DFBETA\n#&gt;     (Intercept)            x\n#&gt; 1  -0.015131790 -0.001678535\n#&gt; 2  -0.053246101  0.019647712\n#&gt; 3   0.017216660 -0.006821716\n#&gt; 4   0.053369207  0.002038393\n#&gt; 5   0.022861311  0.006672433\n#&gt; 6  -0.101915091  0.012493753\n#&gt; 7   0.090627673 -0.018400391\n#&gt; 8  -0.109982670  0.034951829\n#&gt; 9   0.093779788 -0.028593745\n#&gt; 10  0.003248704 -0.126864091\n\ndfbeta(lmodel)  \n#&gt;     (Intercept)            x\n#&gt; 1  -0.015131790 -0.001678535\n#&gt; 2  -0.053246101  0.019647712\n#&gt; 3   0.017216660 -0.006821716\n#&gt; 4   0.053369207  0.002038393\n#&gt; 5   0.022861311  0.006672433\n#&gt; 6  -0.101915091  0.012493753\n#&gt; 7   0.090627673 -0.018400391\n#&gt; 8  -0.109982670  0.034951829\n#&gt; 9   0.093779788 -0.028593745\n#&gt; 10  0.003248704 -0.126864091\n#computing the DFBETA manually for the 10th observation\ncoef(lm(y~x)) - coef(lm(y[-10]~x[-10]))\n#&gt;  (Intercept)            x \n#&gt;  0.003248704 -0.126864091\n\n\n\nShow the codeplot(lm_tv$fit,5)  \n\n\n\n\n\n\n\nhat 统计量\n\nShow the codetibble(\n    x = 1:nrow(advertising),\n    leverage = hatvalues(lm_tv$fit),\n    StandardizedResiduals = rstandard(lm_tv$fit) ,\n    cooks_distance = cooks.distance(lm_tv$fit),\n    label = factor(if_else(cooks_distance&gt;threshold,x,NA))\n) %&gt;%\n    ggplot(aes(x = leverage, y = StandardizedResiduals)) +\n    geom_point(pch=21) +\n    geom_smooth(color=\"red\",lwd=0.5)+\n    scale_x_continuous(limits = c(0, NA)) +\n    geom_vline(xintercept = 0, lty = 2) +\n    geom_hline(yintercept = 0, lty = 2) +\n    ggrepel::geom_text_repel(mapping = aes(label = label))+\n    labs(x = \"Leverage Values\", y = \"Standardized residuals\")\n\n\n\n\n\n\n\n\n12.3.6 Cook‘s距离和杠杆值\n\nShow the codeplot(lm_tv$fit,6)",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html",
    "href": "multiple_linear_regression.html",
    "title": "\n13  多重线性回归\n",
    "section": "",
    "text": "13.1 多重线性模型\n\\[\nY_i=\\beta_0+\\sum_{i=1}^p \\beta_p X_{pi}+\\epsilon_i,其中\\epsilon_i\\sim N(0,\\sigma^2)\n\\]\nY=Xβ+ε\n在矩阵表示法中，因变量是一个向量 Y，每个样本都有一行。自变量组合成一个矩阵X，其中每个特征有一列，另外还有一列 1值用于截距。每列每个示例都有一行。回归系数β和残差ε也是向量。\n向量β的最佳估计值计算为：\n\\[\n\\hat{\\mathbf{\\beta}}=  (X^TX)^{-1}X^TY\n\\]\nShow the codelibrary(tidymodels)\nlibrary(patchwork)\nlibrary(ggfortify)\nlibrary(rms)\n\n# 检测变量相关关系\nad &lt;- advertising %&gt;% select(-1)\ncor(ad)\n#&gt;                   TV      radio  newspaper     sales\n#&gt; TV        1.00000000 0.05480866 0.05664787 0.7822244\n#&gt; radio     0.05480866 1.00000000 0.35410375 0.5762226\n#&gt; newspaper 0.05664787 0.35410375 1.00000000 0.2282990\n#&gt; sales     0.78222442 0.57622257 0.22829903 1.0000000",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多重线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#多重线性模型",
    "href": "multiple_linear_regression.html#多重线性模型",
    "title": "\n13  多重线性回归\n",
    "section": "",
    "text": "13.1.1 rms::ols()\n\n\nShow the code\nmlm_ols &lt;- rms::ols(sales~ TV+radio+newspaper,data = advertising)\nmlm_ols \n#&gt; Linear Regression Model\n#&gt; \n#&gt; rms::ols(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt;                 Model Likelihood    Discrimination    \n#&gt;                       Ratio Test           Indexes    \n#&gt; Obs     200    LR chi2    455.01    R2       0.897    \n#&gt; sigma1.6855    d.f.            3    R2 adj   0.896    \n#&gt; d.f.    196    Pr(&gt; chi2) 0.0000    g        5.685    \n#&gt; \n#&gt; Residuals\n#&gt; \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.8277 -0.8908  0.2418  1.1893  2.8292 \n#&gt; \n#&gt; \n#&gt;           Coef    S.E.   t     Pr(&gt;|t|)\n#&gt; Intercept  2.9389 0.3119  9.42 &lt;0.0001 \n#&gt; TV         0.0458 0.0014 32.81 &lt;0.0001 \n#&gt; radio      0.1885 0.0086 21.89 &lt;0.0001 \n#&gt; newspaper -0.0010 0.0059 -0.18 0.8599\n# texreg::texreg(mlm_ols)\n\ncar::vif(mlm_ols)\n#&gt;        TV     radio newspaper \n#&gt;  3.966283  3.970266  3.410504\nanova(mlm_ols)\n#&gt;                 Analysis of Variance          Response: sales \n#&gt; \n#&gt;  Factor     d.f. Partial SS   MS           F       P     \n#&gt;  TV           1  3.058010e+03 3.058010e+03 1076.41 &lt;.0001\n#&gt;  radio        1  1.361737e+03 1.361737e+03  479.33 &lt;.0001\n#&gt;  newspaper    1  8.871717e-02 8.871717e-02    0.03 0.8599\n#&gt;  REGRESSION   3  4.860323e+03 1.620108e+03  570.27 &lt;.0001\n#&gt;  ERROR      196  5.568253e+02 2.840945e+00\n\n\n\n13.1.2 lm()\n\n\nShow the codemlm_lm&lt;- lm(sales~TV+radio+newspaper,data = advertising)\nsummary(mlm_lm)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.8277 -0.8908  0.2418  1.1893  2.8292 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***\n#&gt; TV           0.045765   0.001395  32.809   &lt;2e-16 ***\n#&gt; radio        0.188530   0.008611  21.893   &lt;2e-16 ***\n#&gt; newspaper   -0.001037   0.005871  -0.177     0.86    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.686 on 196 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8956 \n#&gt; F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\nbroom::tidy(mlm_lm)\n#&gt; # A tibble: 4 × 5\n#&gt;   term        estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)  2.94      0.312       9.42  1.27e-17\n#&gt; 2 TV           0.0458    0.00139    32.8   1.51e-81\n#&gt; 3 radio        0.189     0.00861    21.9   1.51e-54\n#&gt; 4 newspaper   -0.00104   0.00587    -0.177 8.60e- 1\nbroom::glance(mlm_lm)\n#&gt; # A tibble: 1 × 12\n#&gt;   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n#&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     0.897         0.896  1.69      570. 1.58e-96     3  -386.  782.  799.\n#&gt; # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nlogLik(mlm_lm)\n#&gt; 'log Lik.' -386.1811 (df=5)\ncar::vif(mlm_lm)\n#&gt;        TV     radio newspaper \n#&gt;  1.004611  1.144952  1.145187",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多重线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#变换",
    "href": "multiple_linear_regression.html#变换",
    "title": "\n13  多重线性回归\n",
    "section": "\n13.2 变换",
    "text": "13.2 变换\n\n13.2.1 线性组合\n我们经常希望对回归系数的线性组合进行推断，特别是对于多个类别的分类变量。例如，对于分类变量，回归系数表示其中一个组与参考类别之间的平均差异\n\nShow the codelibrary(multcomp, quietly = T)\nconfint(mlm_lm)\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept)  2.32376228 3.55401646\n#&gt; TV           0.04301371 0.04851558\n#&gt; radio        0.17154745 0.20551259\n#&gt; newspaper   -0.01261595 0.01054097\n# 在 R 中，我们通过首先指定一个矩阵来执行此计算，该矩阵指定要进行的比较。此处的矩阵必须具有与回归方程中的回归系数相同的列数\ncomparison &lt;- matrix(c(0,3,1,1), nrow=1)\n\nlincom &lt;- glht(mlm_lm, linfct = comparison)\nsummary(lincom)\n#&gt; \n#&gt;   Simultaneous Tests for General Linear Hypotheses\n#&gt; \n#&gt; Fit: lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; 1 == 0 0.324786   0.009268   35.05   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; (Adjusted p values reported -- single-step method)\nconfint(lincom)\n#&gt; \n#&gt;   Simultaneous Confidence Intervals\n#&gt; \n#&gt; Fit: lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Quantile = 1.9721\n#&gt; 95% family-wise confidence level\n#&gt;  \n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;        Estimate lwr    upr   \n#&gt; 1 == 0 0.3248   0.3065 0.3431\n\n\n\n13.2.2 交互项\n\nShow the codelm_interact&lt;- lm(sales ~ .+ TV:radio, data = advertising)\n\nlm_interact\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ . + TV:radio, data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           id           TV        radio    newspaper     TV:radio  \n#&gt;   6.7912439   -0.0005502    0.0190783    0.0278567    0.0012488    0.0010873\n\n\n\n13.2.3 多项式\n\nShow the codelm(sales ~ TV+ I(TV^2),data = advertising)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + I(TV^2), data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV      I(TV^2)  \n#&gt;   6.114e+00    6.727e-02   -6.847e-05\n\n\n\n13.2.4 对数变换\n\nShow the codelm(sales ~ log(TV),data = advertising)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ log(TV), data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      log(TV)  \n#&gt;      -4.203        3.901",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多重线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#模型假设",
    "href": "multiple_linear_regression.html#模型假设",
    "title": "\n13  多重线性回归\n",
    "section": "\n13.3 模型假设",
    "text": "13.3 模型假设\nhttps://www.statmethods.net/stats/rdiagnostics.html\n\nShow the codelibrary(car)\ncar::scatterplotMatrix(ad)  # 多重共线性\n\n\n\n\n\n\nShow the codeconfint(mlm_lm)  # 95%置信区间\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept)  2.32376228 3.55401646\n#&gt; TV           0.04301371 0.04851558\n#&gt; radio        0.17154745 0.20551259\n#&gt; newspaper   -0.01261595 0.01054097\nplot(mlm_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the codeautoplot(mlm_lm) #回归诊断图\n\n\n\n\n\n\n\n\n13.3.1 线性假设\n残差图， 成分残差图\n\nShow the codeplot(mlm_lm,1)  \n\n\n\n\n\n\nShow the codecrPlots(mlm_lm)\n\n\n\n\n\n\n\n\n13.3.2 正态性假设Q-Q图\nStandardized Residuals\n\nShow the codeplot(mlm_lm,2) \n\n\n\n\n\n\nShow the codesummary(powerTransform(mlm_lm))  \n#&gt; bcPower Transformation to Normality \n#&gt;    Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\n#&gt; Y1    0.9074           1       0.7569       1.0578\n#&gt; \n#&gt; Likelihood ratio test that transformation parameter is equal to 0\n#&gt;  (log transformation)\n#&gt;                            LRT df       pval\n#&gt; LR test, lambda = (0) 147.1578  1 &lt; 2.22e-16\n#&gt; \n#&gt; Likelihood ratio test that no transformation is needed\n#&gt;                           LRT df    pval\n#&gt; LR test, lambda = (1) 1.41991  1 0.23342\n\n\n\nShow the codeplot(mlm_lm,3)\n\n\n\n\n\n\n\n\n13.3.3 误差相关性\n\nShow the codedurbinWatsonTest(mlm_lm)      #结果表明rho=0\n#&gt;  lag Autocorrelation D-W Statistic p-value\n#&gt;    1     -0.04687792      2.083648   0.606\n#&gt;  Alternative hypothesis: rho != 0\n\n\n\n13.3.4 误差项的方差齐性\n\nShow the codencvTest(mlm_lm)\n#&gt; Non-constant Variance Score Test \n#&gt; Variance formula: ~ fitted.values \n#&gt; Chisquare = 5.355982, Df = 1, p = 0.020651\nspreadLevelPlot(mlm_lm)\n\n\n\n\n\n\n#&gt; \n#&gt; Suggested power transformation:  1.499852\n\n\nShow the codetibble(\n    abs_studentized_residuals=abs(rstudent(mlm_lm)),\n    fitted_values=mlm_lm$model$sales\n) %&gt;% ggplot(aes(fitted_values,abs_studentized_residuals))+\n    geom_point(pch=21)+\n    geom_smooth()\n\n\n\n\n\n\n\n\n13.3.5 异常观测点\n\nShow the code# studentized residual Plot\nresidplot&lt;-function(fit,nbreaks=10){\n  z&lt;-rstudent(fit)\n  hist(z,breaks=nbreaks,freq=FALSE)     #密度直方图\n  title(xlab=\"Studentized Residual\")\n  rug(z,col=\"brown\")                    #轴须图\n  curve(dnorm(x,mean=mean(z),sd=sd(z)),add=TRUE,col=\"blue\",lwd=2) #正态密度曲线\n  lines(density(z)$x,density(z)$y,col=\"red\",lwd=2)       #样本密度曲线\n  legend(\"topright\",c(\"Normal Curve\",\"Kernel Density Curve\"),#图例\n  lty = c(3,2),pch = c(21,22),col=c(\"blue\",\"red\"),cex=.7)\n}\nresidplot(mlm_lm)\n\n\n\n\n\n\n\n\nShow the code#######################################################################\nlibrary(car)\noutlierTest(mlm_lm)            #离群点\n#高杠杆值点\nhat.plot&lt;-function(fit){\n  p&lt;-length(coefficients(fit)) #模型估计的参数数目（包含截距项）\n  n&lt;-length(fitted(fit))       #样本量\n  plot(hatvalues(fit),main=\"Index Plot of Hat Values\")#帽子值\n  abline(h=c(2,3)*p/n,col=\"red\",lty=2)  #大于帽子均值p/n的2或3倍被认为是高杠杆值\n  identity(1:n,hatvalues(fit),names(hatvalues(fit)))\n}\nhat.plot(mlm_lm)\n####强影响点\n#Cook's D图形    大于4/(n-k-1)  k为预测变量数目\ncutoff&lt;-4/(nrow(advertising)-length(mlm_lm$coefficients)-2)\n{plot(mlm_lm,which=4,cook.levels=cutoff)\nabline(h=cutoff,lty=2,col=\"red\")}\n#变量添加图\navPlots(mlm_lm,ask=FALSE,id.method=\"identity\")\n\n###\ninfluencePlot(mlm_lm,id.method=\"identity\",main=\"Influence Plot\")\n\n\n\n13.3.6 多重共线性\n\nShow the codecar::vif(mlm_lm)\n#&gt;        TV     radio newspaper \n#&gt;  1.004611  1.144952  1.145187\n\nsqrt(car::vif(mlm_lm))&gt;=2       #vif平方根 ≥2 存在\n#&gt;        TV     radio newspaper \n#&gt;     FALSE     FALSE     FALSE",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多重线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#逐步回归",
    "href": "multiple_linear_regression.html#逐步回归",
    "title": "\n13  多重线性回归\n",
    "section": "\n13.4 逐步回归",
    "text": "13.4 逐步回归\n逐步回归是筛选变量，有向前、向后和两个方向同时进行三个方法。\n\ndirection = \"both\"双向\ndirection = \"backward\"向后\ndirection = \"forward\"向前\n\n\nShow the codestep_full &lt;- lm(sales~ . ,data = advertising[-1])\nstep_lm_0 &lt;- lm(sales~ 1 ,data = advertising[-1])\n\nstep_forward &lt;- stats::step(step_lm_0,scope =formula(step_full),  \n                            direction = \"forward\")\n#&gt; Start:  AIC=661.8\n#&gt; sales ~ 1\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + TV         1    3314.6 2102.5 474.52\n#&gt; + radio      1    1798.7 3618.5 583.10\n#&gt; + newspaper  1     282.3 5134.8 653.10\n#&gt; &lt;none&gt;                   5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=474.52\n#&gt; sales ~ TV\n#&gt; \n#&gt;             Df Sum of Sq     RSS    AIC\n#&gt; + radio      1   1545.62  556.91 210.82\n#&gt; + newspaper  1    183.97 1918.56 458.20\n#&gt; &lt;none&gt;                   2102.53 474.52\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                   556.91 210.82\n#&gt; + newspaper  1  0.088717 556.83 212.79\nsummary(step_forward)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n\n\nstep_backward &lt;- stats::step(object = step_full,#scope = formula(step_lm_0) ,\n                         direction = \"backward\")\n#&gt; Start:  AIC=212.79\n#&gt; sales ~ TV + radio + newspaper\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; - newspaper  1      0.09  556.9 210.82\n#&gt; &lt;none&gt;                    556.8 212.79\n#&gt; - radio      1   1361.74 1918.6 458.20\n#&gt; - TV         1   3058.01 3614.8 584.90\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;         Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                556.9 210.82\n#&gt; - radio  1    1545.6 2102.5 474.52\n#&gt; - TV     1    3061.6 3618.5 583.10\nsummary(step_backward )\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\nstep_both&lt;- stats::step(object = step_lm_0, scope = formula(step_full) ,\n                         direction = \"both\")\n#&gt; Start:  AIC=661.8\n#&gt; sales ~ 1\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + TV         1    3314.6 2102.5 474.52\n#&gt; + radio      1    1798.7 3618.5 583.10\n#&gt; + newspaper  1     282.3 5134.8 653.10\n#&gt; &lt;none&gt;                   5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=474.52\n#&gt; sales ~ TV\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + radio      1    1545.6  556.9 210.82\n#&gt; + newspaper  1     184.0 1918.6 458.20\n#&gt; &lt;none&gt;                   2102.5 474.52\n#&gt; - TV         1    3314.6 5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                    556.9 210.82\n#&gt; + newspaper  1      0.09  556.8 212.79\n#&gt; - radio      1   1545.62 2102.5 474.52\n#&gt; - TV         1   3061.57 3618.5 583.10\nsummary(step_both)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多重线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#模型选择和优化",
    "href": "multiple_linear_regression.html#模型选择和优化",
    "title": "\n13  多重线性回归\n",
    "section": "\n13.5 模型选择和优化",
    "text": "13.5 模型选择和优化\n\n\nn是观测值的数量，p是模型的参数数（等于回归系数的数量）\n\n\n\\(\\mathcal{L}\\)是模型拟合的最大似然值\n\nShow the code########################两模型比较\nlm1 &lt;- lm(sales~TV+radio+newspaper,data = advertising)\nlm2 &lt;- lm(sales~TV*radio*newspaper,data = advertising)\n\nanova(lm2,lm1) #anova() 嵌套模型\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Model 1: sales ~ TV * radio * newspaper\n#&gt; Model 2: sales ~ TV + radio + newspaper\n#&gt;   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n#&gt; 1    192 169.86                                  \n#&gt; 2    196 556.83 -4   -386.97 109.35 &lt; 2.2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n##########################################            AIC \nAIC(lm2,lm1)  # 赤池信息准则  AIC值小的优先选择\n#&gt;     df      AIC\n#&gt; lm2  9 552.9065\n#&gt; lm1  5 782.3622\n#BIC\n\n\n####################################相对重要性##################################\nad &lt;- scale(advertising[-1])\nad\n#&gt;                 TV        radio    newspaper        sales\n#&gt;   [1,]  0.96742460  0.979065591  1.774492530  1.548168135\n#&gt;   [2,] -1.19437904  1.080097401  0.667902716 -0.694303815\n#&gt;   [3,] -1.51235985  1.524637364  1.779084189 -0.905134512\n#&gt;   [4,]  0.05191939  1.214806480  1.283185019  0.858176766\n#&gt;   [5,]  0.39319551 -0.839506984  1.278593360 -0.215143142\n#&gt;   [6,] -1.61136487  1.726700983  2.040808751 -1.307629477\n#&gt;   [7,] -1.04295960  0.642292892 -0.323895625 -0.425973838\n#&gt;   [8,] -0.31265202 -0.246787034 -0.870303044 -0.157643861\n#&gt;   [9,] -1.61252963 -1.425491481 -1.357018896 -1.767623723\n#&gt;  [10,]  0.61450084 -1.391814211 -0.429503781 -0.655970962\n#&gt;  [11,] -0.94278982 -1.176279684 -0.291754012 -1.039299500\n#&gt;  [12,]  0.78805080  0.049572941 -1.219269126  0.647346069\n#&gt;  [13,] -1.43548537  0.797208333  1.622967784 -0.924300938\n#&gt;  [14,] -0.57705364 -1.055041512 -1.072336039 -0.828468804\n#&gt;  [15,]  0.66458573  0.649028346  0.709227646  0.954008900\n#&gt;  [16,]  0.56325118  1.645875535  1.026052116  1.605667416\n#&gt;  [17,] -0.92298882  0.898240143  3.831555755 -0.291808850\n#&gt;  [18,]  1.56494899  1.100303763  1.159210227  1.988995954\n#&gt;  [19,] -0.90668211 -0.186167948 -0.562661892 -0.521805973\n#&gt;  [20,]  0.00299927  0.042837487 -0.525928620  0.110686115\n#&gt;  [21,]  0.83114711  0.298784739  1.049010411  0.762344631\n#&gt;  [22,]  1.05245243 -1.223427861 -0.323895625 -0.291808850\n#&gt;  [23,] -1.55895045 -0.495998831  0.874527370 -1.614292308\n#&gt;  [24,]  0.94645883 -0.428644291 -0.199920832  0.283183958\n#&gt;  [25,] -0.98705089 -0.718268813 -0.562661892 -0.828468804\n#&gt;  [26,]  1.34946748 -1.331195125 -0.507561984 -0.387640985\n#&gt;  [27,] -0.04825039  0.406552002 -0.824386454  0.187351823\n#&gt;  [28,]  1.08390109 -0.442115199 -0.351445579  0.359849666\n#&gt;  [29,]  1.18523563  0.258372015 -0.351445579  0.934842473\n#&gt;  [30,] -0.89037540 -0.489263377  0.470461379 -0.675137388\n#&gt;  [31,]  1.69889695  0.339197463  0.580661195  1.414003146\n#&gt;  [32,] -0.39767985 -0.394967022  0.369444882 -0.406807411\n#&gt;  [33,] -0.58054794 -1.465904205 -0.025437791 -0.847635231\n#&gt;  [34,]  1.38091613 -0.219845218 -1.389160509  0.647346069\n#&gt;  [35,] -0.59801941 -1.472639659 -1.063152721 -0.866801658\n#&gt;  [36,]  1.67327212 -1.290782401 -1.012644472 -0.234309569\n#&gt;  [37,]  1.39605808  1.383192830 -1.173352536  2.180660223\n#&gt;  [38,] -0.84262004  1.760378253  0.695452669  0.129852542\n#&gt;  [39,] -1.21068574  0.231430199  0.208736817 -0.751803096\n#&gt;  [40,]  0.94296453  0.972330137  0.066395389  1.433169573\n#&gt;  [41,]  0.64594949 -0.064929776  0.048028753  0.494014654\n#&gt;  [42,]  0.34893444  0.682705616  0.374036541  0.589846789\n#&gt;  [43,]  1.70705030  0.298784739 -1.320285624  1.279838158\n#&gt;  [44,]  0.69719914 -1.001157880 -0.190737514 -0.215143142\n#&gt;  [45,] -1.42034342  0.164075659  0.585252854 -1.058465927\n#&gt;  [46,]  0.32680391 -0.051458868  0.043437094  0.168185396\n#&gt;  [47,] -0.66790531 -0.900126070  0.236286771 -0.655970962\n#&gt;  [48,]  1.08157156  1.228277388 -0.553478574  1.758998831\n#&gt;  [49,]  0.93364642 -0.502734285  0.888302347  0.149018969\n#&gt;  [50,] -0.93347170 -0.778887899  0.286795020 -0.828468804\n#&gt;  [51,]  0.61450084 -1.358136941  0.185778522 -0.502639546\n#&gt;  [52,] -0.54327546 -0.920332432 -1.237635762 -0.636804535\n#&gt;  [53,]  0.80785181  1.241748296  0.415361472  1.644000269\n#&gt;  [54,]  0.41416128  1.544843726  1.292368337  1.375670293\n#&gt;  [55,]  1.34713795  0.372874732 -0.672861707  1.184006023\n#&gt;  [56,]  0.60401795  1.760378253  1.352059904  1.854830966\n#&gt;  [57,] -1.62767157  0.325726555  0.498011333 -1.633458735\n#&gt;  [58,] -0.12628963 -0.273728850 -0.640720094 -0.157643861\n#&gt;  [59,]  0.74262497  1.773849161  0.328119951  1.873997393\n#&gt;  [60,]  0.74146021  0.420022910 -0.975911200  0.839010339\n#&gt;  [61,] -1.08955020 -1.432226935 -0.420320463 -1.135131635\n#&gt;  [62,]  1.33083124  1.309102836  1.108701978  1.950663100\n#&gt;  [63,]  1.07458297 -0.522940647 -0.149412583  0.321516812\n#&gt;  [64,] -0.51648587  0.426758364 -1.017236131 -0.004312446\n#&gt;  [65,] -0.18569264  1.315838290 -0.075946040  0.762344631\n#&gt;  [66,] -0.90901164 -0.940538794 -1.361610555 -0.905134512\n#&gt;  [67,] -1.34579847  0.089985665 -1.301918988 -0.866801658\n#&gt;  [68,] -0.09018192 -0.590295187 -0.934586269 -0.119311008\n#&gt;  [69,]  1.05245243  0.285313831 -0.897852997  0.934842473\n#&gt;  [70,]  0.81251087  1.389928284 -0.154004242  1.586500989\n#&gt;  [71,]  0.60634748  0.494112904  0.374036541  0.819843912\n#&gt;  [72,] -0.43378756 -0.603766095  0.052620412 -0.310975277\n#&gt;  [73,] -1.40054242  0.655763800 -0.516745302 -1.000966646\n#&gt;  [74,] -0.20549365 -1.183015138  0.034253776 -0.579305254\n#&gt;  [75,]  0.77290886  0.089985665 -0.801428159  0.570680362\n#&gt;  [76,] -1.51585415  1.376457376  2.702007645 -1.020133073\n#&gt;  [77,] -1.39238907 -1.459168751 -0.452462076 -1.365128758\n#&gt;  [78,] -0.30915772  0.352668371 -0.750919910  0.034020408\n#&gt;  [79,] -1.64980211  0.446964726 -0.971319541 -1.671791589\n#&gt;  [80,] -0.36157214 -1.048306058 -0.342262261 -0.579305254\n#&gt;  [81,] -0.82281904  0.231430199 -0.378995532 -0.425973838\n#&gt;  [82,]  1.08040679 -1.290782401  0.291386679 -0.330141704\n#&gt;  [83,] -0.83563145 -0.199638856  0.089353684 -0.521805973\n#&gt;  [84,] -0.91600023  1.430341008  0.231695112 -0.080978154\n#&gt;  [85,]  0.77407363  1.329309198  0.149045251  1.471502427\n#&gt;  [86,]  0.53762635 -0.327612482  1.613784466  0.225684677\n#&gt;  [87,] -0.82398380  0.285313831 -0.668270048 -0.387640985\n#&gt;  [88,] -0.42330468  1.167658302  1.498992991  0.379016092\n#&gt;  [89,] -0.68421201  0.150604751  1.967342208 -0.215143142\n#&gt;  [90,] -0.43378756  1.652610989  0.957177231  0.513181081\n#&gt;  [91,] -0.14842017 -1.236898769 -0.975911200 -0.540972400\n#&gt;  [92,] -1.37957665 -1.465904205  0.112311979 -1.288463050\n#&gt;  [93,]  0.82299375  0.689441070  1.306143314  1.030674608\n#&gt;  [94,]  1.20969569  0.891504689  1.916833959  1.567334562\n#&gt;  [95,] -0.46174192 -0.623972457 -0.902444656 -0.483473119\n#&gt;  [96,]  0.18936165  0.561467444  1.026052116  0.551513935\n#&gt;  [97,]  0.58887601 -1.331195125 -1.132027606 -0.445140265\n#&gt;  [98,]  0.44095087 -0.152490678 -0.392770509  0.283183958\n#&gt;  [99,]  1.66162447  1.282161020  0.947993914  2.180660223\n#&gt; [100,] -0.13793728  1.241748296  0.704635987  0.609013216\n#&gt; [101,]  0.87773770 -1.277311493  0.883710688 -0.445140265\n#&gt; [102,]  1.73966372  0.878033781  3.230048428  1.873997393\n#&gt; [103,]  1.55097181 -0.886655162 -0.420320463  0.149018969\n#&gt; [104,]  0.47589381 -0.408437930 -0.581028528  0.129852542\n#&gt; [105,]  1.06177055  0.743324702 -1.159577559  1.279838158\n#&gt; [106,] -0.10648863  1.558314633  1.306143314  0.992341754\n#&gt; [107,] -1.42150819 -0.826036076 -0.039212768 -1.307629477\n#&gt; [108,] -0.65975195 -1.546729653 -0.337670602 -1.020133073\n#&gt; [109,] -1.56011521 -1.539994199 -0.227470786 -1.671791589\n#&gt; [110,]  1.26211011  0.244901107 -1.150394241  1.107340316\n#&gt; [111,]  0.91733971 -1.014628788  1.191351840 -0.119311008\n#&gt; [112,]  1.10253732  0.992536499 -0.337670602  1.490668854\n#&gt; [113,]  0.33379250 -0.529676101 -1.292735670  0.014853981\n#&gt; [114,]  0.72864780 -0.179432494 -0.911627974  0.359849666\n#&gt; [115,] -0.80185327  1.585256449  0.181186863  0.110686115\n#&gt; [116,] -0.83796098  0.790472879  1.016868798 -0.272642423\n#&gt; [117,] -0.09134669 -0.603766095 -0.227470786 -0.349308131\n#&gt; [118,] -0.82281904 -1.513052383 -0.723369956 -0.885968085\n#&gt; [119,] -0.24858995  0.918446505  2.233658429  0.359849666\n#&gt; [120,] -1.48673502 -0.489263377 -0.378995532 -1.422628038\n#&gt; [121,] -0.06688662  0.238165653  0.718410964  0.283183958\n#&gt; [122,] -1.49372361 -0.105342500  0.911260642 -1.345962331\n#&gt; [123,]  0.89637394 -1.405285119 -0.686636684 -0.464306692\n#&gt; [124,] -0.27887383  0.763531064 -0.833569772  0.225684677\n#&gt; [125,]  0.96043601  0.608615622  2.004075480  1.088173889\n#&gt; [126,] -0.69702443 -0.772152445 -0.213695809 -0.655970962\n#&gt; [127,] -1.62184775  1.053155585  0.920443960 -1.422628038\n#&gt; [128,] -0.77855797 -1.566936015 -0.980502859 -1.000966646\n#&gt; [129,]  0.85327764  1.733436437 -1.256002398  2.046495235\n#&gt; [130,] -1.01849954 -0.758681537  0.576069536 -0.828468804\n#&gt; [131,] -1.70454606  1.100303763 -1.003461154 -2.380949385\n#&gt; [132,]  1.37625707 -1.371607849  0.571477877 -0.253475996\n#&gt; [133,] -1.61485916  0.265107469 -1.306510647 -1.595125881\n#&gt; [134,]  0.84745381  0.689441070  0.667902716  1.069007462\n#&gt; [135,] -1.28290117  1.032949223  1.609192807 -0.617638108\n#&gt; [136,] -1.15011797  1.598727357 -1.012644472 -0.464306692\n#&gt; [137,] -1.41451960  1.059891039 -0.975911200 -0.866801658\n#&gt; [138,]  1.47526209  0.379610186  1.338284927  1.299004585\n#&gt; [139,] -1.21185051  0.177546567 -0.461645394 -0.847635231\n#&gt; [140,]  0.44095087  1.389928284 -1.324877283  1.279838158\n#&gt; [141,] -0.85776198 -0.421908837 -0.810611477 -0.598471681\n#&gt; [142,]  0.54345018  0.817414695  2.068358705  0.992341754\n#&gt; [143,]  0.85560717  0.669234708  0.337303269  1.164839596\n#&gt; [144,] -0.49435534 -1.183015138  0.176595204 -0.694303815\n#&gt; [145,] -0.59219559 -0.570088825  0.383219859 -0.502639546\n#&gt; [146,] -0.07853427 -1.438962389 -0.989686177 -0.713470242\n#&gt; [147,]  1.08390109 -1.075247874 -1.003461154 -0.157643861\n#&gt; [148,]  1.12000880  1.733436437  0.631169444  2.180660223\n#&gt; [149,] -1.27008875  1.147451941 -0.856528067 -0.598471681\n#&gt; [150,] -1.19204951  0.170811113 -0.457053735 -0.751803096\n#&gt; [151,]  1.55679563 -0.630707911  0.295978338  0.398182519\n#&gt; [152,] -0.30333390 -1.001157880  0.833202439 -0.464306692\n#&gt; [153,]  0.58887601  0.002424763 -0.750919910  0.494014654\n#&gt; [154,]  0.28254284  1.107039217  0.328119951  0.954008900\n#&gt; [155,]  0.47472905 -0.145755224 -0.966727882  0.302350385\n#&gt; [156,] -1.66494405 -0.785623353 -1.141210924 -2.074286554\n#&gt; [157,] -0.61898518  1.362986468  0.915852301  0.244851104\n#&gt; [158,]  0.03211839 -1.479375113 -0.287162353 -0.751803096\n#&gt; [159,] -1.57642192  0.918446505  0.672494375 -1.288463050\n#&gt; [160,] -0.17870405 -0.327612482  0.185778522 -0.215143142\n#&gt; [161,]  0.29652002 -0.347818844  0.006703822  0.072353262\n#&gt; [162,] -0.71449590  0.844356511  0.860752393 -0.138477435\n#&gt; [163,]  0.48171764 -0.347818844 -0.227470786  0.168185396\n#&gt; [164,]  0.19169118  0.911711051 -1.063152721  0.762344631\n#&gt; [165,] -0.34759496 -0.576824279 -1.154985900 -0.406807411\n#&gt; [166,]  1.01867425 -1.337930579  2.490791332 -0.406807411\n#&gt; [167,] -1.50420650  0.965594683 -0.411137145 -1.154298062\n#&gt; [168,]  0.69603438 -1.216692407 -0.512153643 -0.349308131\n#&gt; [169,]  0.79620416  0.022631125  1.241860088  0.589846789\n#&gt; [170,]  1.59872717 -0.852977892 -1.109069311  0.187351823\n#&gt; [171,] -1.13031697 -0.785623353 -0.558070233 -1.077632354\n#&gt; [172,]  0.20333883 -0.159226132  0.773510872  0.091519689\n#&gt; [173,] -1.48440549 -0.213109764 -0.622353458 -1.230963769\n#&gt; [174,]  0.24876466 -1.088718782 -0.815203136 -0.445140265\n#&gt; [175,]  0.87773770 -1.337930579 -0.801428159 -0.483473119\n#&gt; [176,]  1.51253457  1.726700983  0.516377969  2.487323054\n#&gt; [177,]  1.18057657  0.467171088 -0.470828712  1.184006023\n#&gt; [178,]  0.26973043 -1.041570604  0.213328476 -0.445140265\n#&gt; [179,]  1.51020504 -1.412020573 -0.314712307 -0.425973838\n#&gt; [180,]  0.21615124 -0.893390616 -0.594803505 -0.272642423\n#&gt; [181,]  0.11132240 -1.391814211 -1.021827790 -0.675137388\n#&gt; [182,]  0.83231187 -1.203221500 -0.144820924 -0.349308131\n#&gt; [183,] -1.05810154 -1.183015138 -0.039212768 -1.020133073\n#&gt; [184,]  1.63716441  1.329309198  1.893875664  2.333991639\n#&gt; [185,]  1.24347388 -0.132284316 -0.025437791  0.685678923\n#&gt; [186,]  0.67506861  1.470753732 -0.502970325  1.644000269\n#&gt; [187,] -0.08785239 -1.425491481 -0.181554196 -0.713470242\n#&gt; [188,]  0.51316629  0.366139279 -0.567253551  0.628179642\n#&gt; [189,]  1.61852817 -0.630707911 -1.233044103  0.359849666\n#&gt; [190,] -1.49488838 -0.751946083 -0.328487284 -1.403461612\n#&gt; [191,] -1.25261728  1.201335572 -1.136619265 -0.617638108\n#&gt; [192,] -0.83330192 -0.839506984 -1.127435947 -0.790135950\n#&gt; [193,] -1.51235985 -1.290782401  0.048028753 -1.556793027\n#&gt; [194,]  0.23012842  1.261954658 -1.237635762  1.069007462\n#&gt; [195,]  0.03095363  0.830885603 -1.127435947  0.628179642\n#&gt; [196,] -1.26775922 -1.317724217 -0.769286546 -1.230963769\n#&gt; [197,] -0.61549089 -1.236898769 -1.031011108 -0.828468804\n#&gt; [198,]  0.34893444 -0.940538794 -1.109069311 -0.234309569\n#&gt; [199,]  1.59057381  1.261954658  1.636742761  2.199826650\n#&gt; [200,]  0.99071990 -0.987686972 -1.003461154 -0.119311008\n#&gt; attr(,\"scaled:center\")\n#&gt;        TV     radio newspaper     sales \n#&gt;  147.0425   23.2640   30.5540   14.0225 \n#&gt; attr(,\"scaled:scale\")\n#&gt;        TV     radio newspaper     sales \n#&gt; 85.854236 14.846809 21.778621  5.217457\n#R平方贡献率  #相对权重 \nrelweights&lt;-function(fit,...){\n  R&lt;-cor(fit$model)\n  nvar&lt;-ncol(R)\n  rxx&lt;-R[2:nvar,2:nvar]\n  rxy&lt;-R[2:nvar,1]\n  svd&lt;-eigen(rxx)\n  evec&lt;-svd$vectors\n  ev&lt;-svd$values\n  delta&lt;-diag(sqrt(ev))\n  lambda&lt;-evec %*%delta %*% t(evec)\n  lambdaasq&lt;-lambda^2\n  beta&lt;-solve(lambda) %*% rxy\n  r2&lt;-colSums(beta^2)\n  rawwgt&lt;-lambdaasq%*%beta^2\n  import&lt;-(rawwgt/r2)*100            #计算相对权重\n  import&lt;-data.frame(Weights=import)  #数据框化\n  row.names(import)&lt;-names(fit$model[2:nvar])\n  import&lt;-import[order(import$Weights),1,drop=FALSE] #升序排序\n  dotchart(import$Weights,labels=row.names(import),   #点图\n           xlab = \"% of R-Square\",pch=19,\n           main=\"Relative Importiance of Predictor Variables \",\n           sub=paste(\"Total R-Square =\",round(r2,digits = 3)),\n  ...)\nreturn(import)\n}\nrelweights(lm1,col=\"blue\")\n\n\n\n\n\n\n#&gt;             Weights\n#&gt; newspaper  2.468097\n#&gt; radio     32.198236\n#&gt; TV        65.333667",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多重线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#线性可加模型",
    "href": "multiple_linear_regression.html#线性可加模型",
    "title": "\n13  多重线性回归\n",
    "section": "\n13.6 线性可加模型",
    "text": "13.6 线性可加模型\nadditive model\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+  \\beta_2 X_i^2+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\log(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1 (X_i\\times W_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\exp(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\sin(X_i)+\\epsilon_i\n\\]",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多重线性回归</span>"
    ]
  },
  {
    "objectID": "LMM.html",
    "href": "LMM.html",
    "title": "\n14  线性混合效应模型\n",
    "section": "",
    "text": "14.1 模型假设Cov(γ,X)=0\n线性混合效应模型 （Linear Mixed-effect Model，LMM）用于分析具有固定效应和随机效应的数据结构。 它能够处理数据中的个体异质性和组内相关性。如果数据满足正态分布但有组内相关性，使用线性混合效应模型。\n线性混合模型的一般表达形式：\n\\[ Y = \\mathbf{X} \\beta + \\mathbf{Z} \\gamma + \\epsilon \\]\n其中：\n固定效应是感兴趣的自变量，表示所有个体都相同的效应\n随机效应：随机截距表示不同个体的基线差异，随机斜率表示不同个体对自变量的响应差异。\n随机效应假设\n随机效应的方差-协方差矩阵\\(Σ_γ\\) ​，残差的方差矩阵 \\(σ^2I\\)的结构相关性特征：\n对于连续数据，mixed model repeated measures（MMRM）\n对于分类数据或计数数据，generalized linear mixed-effects model(GLMM)\nMixed Effects Models and Extensions in Ecology with R 第5章",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合效应模型</span>"
    ]
  },
  {
    "objectID": "LMM.html#模型假设covγx0",
    "href": "LMM.html#模型假设covγx0",
    "title": "\n14  线性混合效应模型\n",
    "section": "",
    "text": "因变量 Y 为连续型数值变量\n线性\n残差的正态性 \\(\\epsilon\\sim N(0,\\sigma^2 I)\\)\n方差齐性 \\(Var(ε_i ​ )=σ^2\\)\n\n\n\n随机效应与「所有固定效应自变量」之间相互独立 \\(Cov(γ,X)=0\\)\n随机效应 ( γ ) 服从均值为 0 的多元正态分布 \\(γ∼N(0,Σ_γ ​ )\\)\n随机效应 ( γ ) 与残差 ( ε ) 之间相互独立 \\(Cov(γ,ε)=0\\)\n\n\n\nunstructured\ncompound symmetry\nauto-regression AR(1)\nhomogeneous toeplitz\nhomogeneous auto-regression ARH(1)\nhomogeneous compound symmetry",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合效应模型</span>"
    ]
  },
  {
    "objectID": "LMM.html#lme4lmer",
    "href": "LMM.html#lme4lmer",
    "title": "\n14  线性混合效应模型\n",
    "section": "\n14.2 lme4::lmer()\n",
    "text": "14.2 lme4::lmer()\n\nlmer() 的表达式如下：\n\\[\nlmer (data,formual= DV \\sim Fixed\\_Factor + \\\\ (Random\\_intercept + Random\\_slope | Random\\_Factor)+\\\\(Random\\_intercept + Random\\_slope | Random\\_Factor)+...\n\\\\)\n\\]\n截距中，1表示随机截距，0表示固定截距，默认截距为1。\n\n\nLME\n表达式\n简写\n\n\n\n随机截距+随机斜率\ny~x+( 1+x | id )\ny~x+( x | id )\n\n\n随机截距+固定斜率\ny~x+( 1+1 | id )\ny~x+( 1 | id )\n\n\n固定截距+随机斜率\ny~x+( 0+x | id )\nNA\n\n\n线性模型：固定截距+固定斜率\ny~x\nNA\n\n\n\n\nShow the codelibrary(readr)\nlibrary(dplyr)\n\nrikz &lt;- read_tsv(\"data/AED/RIKZ.txt\")\nrikz &lt;- rikz |&gt; \n    mutate(\n        Beach = factor(Beach),\n        Exposure = factor(Exposure)\n    )\nhead(rikz)\n#&gt; # A tibble: 6 × 5\n#&gt;   Sample Richness Exposure    NAP Beach\n#&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;\n#&gt; 1      1       11 10        0.045 1    \n#&gt; 2      2       10 10       -1.04  1    \n#&gt; 3      3       13 10       -1.34  1    \n#&gt; 4      4       11 10        0.616 1    \n#&gt; 5      5       10 10       -0.684 1    \n#&gt; 6      6        8 8         1.19  2",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合效应模型</span>"
    ]
  },
  {
    "objectID": "LMM.html#随机截距随机斜率",
    "href": "LMM.html#随机截距随机斜率",
    "title": "\n14  线性混合效应模型\n",
    "section": "\n14.3 随机截距+随机斜率",
    "text": "14.3 随机截距+随机斜率\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times 2n_{subjects}} \\mathbf{\\gamma}_{2n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ有两倍于受试者数量的列，每个受试者的随机截距和随机斜率\n\nShow the codelibrary(lmerTest)\nconflicted::conflicts_prefer(lmerTest::lmer)\nlme1 &lt;- lmer(Richness ~ 1 + NAP + Exposure+ NAP:Exposure + (1 + NAP |Beach) ,data = rikz)\nsummary(lme1)\n#&gt; Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n#&gt; lmerModLmerTest]\n#&gt; Formula: Richness ~ 1 + NAP + Exposure + NAP:Exposure + (1 + NAP | Beach)\n#&gt;    Data: rikz\n#&gt; \n#&gt; REML criterion at convergence: 207.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.92384 -0.36066 -0.13343  0.09819  2.84228 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  Beach    (Intercept) 3.758    1.938         \n#&gt;           NAP         2.837    1.684    -1.00\n#&gt;  Residual             6.535    2.556         \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;                Estimate Std. Error      df t value Pr(&gt;|t|)   \n#&gt; (Intercept)     13.3457     2.2784  5.0864   5.858  0.00194 **\n#&gt; NAP             -4.1753     2.1243  5.7080  -1.965  0.09942 . \n#&gt; Exposure10      -5.3273     2.5556  5.1415  -2.085  0.09000 . \n#&gt; Exposure11      -9.7660     2.5653  5.1903  -3.807  0.01169 * \n#&gt; NAP:Exposure10   0.1646     2.3621  5.5602   0.070  0.94688   \n#&gt; NAP:Exposure11   2.7273     2.3715  5.6329   1.150  0.29661   \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;             (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP         -0.770                             \n#&gt; Exposure10  -0.892  0.686                      \n#&gt; Exposure11  -0.888  0.683  0.792               \n#&gt; NAP:Expsr10  0.692 -0.899 -0.775 -0.615        \n#&gt; NAP:Expsr11  0.689 -0.896 -0.615 -0.779  0.806 \n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\n\n\n\nplot(lme1)\n\n\n\n\n\n\nShow the code\nAIC(lme1)\n#&gt; [1] 227.1558\nBIC(lme1)\n#&gt; [1] 245.2224\nlogLik(lme1)\n#&gt; 'log Lik.' -103.5779 (df=10)\n\n# library(broom.mixed)\n# tidy(lme1)\n\n\nlibrary(nlme)\nlme(Richness ~ 1 + NAP * Exposure,\n             random = ~ 1 + NAP | Beach ,\n             data = rikz,\n             control = lmeControl(opt = \"optim\", \n                                  msMaxIter = 1000, \n                                  msMaxEval = 5000)\n    ) |&gt; \n    summary()\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: rikz \n#&gt;        AIC      BIC    logLik\n#&gt;   227.2046 243.8402 -103.6023\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 + NAP | Beach\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev   Corr  \n#&gt; (Intercept) 1.939709 (Intr)\n#&gt; NAP         1.689580 -0.996\n#&gt; Residual    2.554676       \n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  2.278989 33  5.855970  0.0000\n#&gt; NAP            -4.175271  2.128084 33 -1.961986  0.0582\n#&gt; Exposure10     -5.323695  2.556406  6 -2.082492  0.0825\n#&gt; Exposure11     -9.765613  2.566035  6 -3.805720  0.0089\n#&gt; NAP:Exposure10  0.167146  2.366467 33  0.070631  0.9441\n#&gt; NAP:Exposure11  2.726865  2.375786 33  1.147774  0.2593\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.767                             \n#&gt; Exposure10     -0.891  0.684                      \n#&gt; Exposure11     -0.888  0.682  0.792               \n#&gt; NAP:Exposure10  0.690 -0.899 -0.772 -0.613        \n#&gt; NAP:Exposure11  0.687 -0.896 -0.613 -0.777  0.806 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.9251786 -0.3608959 -0.1327685  0.0992999  2.8420571 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9\n\n\n这个模型的公式可以分解为：\n\nREML 限制性最大似然准则 207.2，评估模型的拟合优度\nScaled residuals\n随机效应部分：Beach 作为随机效应的分组变量，包含随机截距和随机斜率（NAP），相关性为 -1，说明随机截距和随机斜率之间呈现完全负相关关系。\n固定效应部分：Richness 的预测由截距、NAP（数值变量）和 Exposure（分类变量，包含 Exposure10 和 Exposure11）及其交互项构成。\n固定效应的相关性矩阵\n\n\nShow the code# 标准化模型残差分布\nquantile(residuals(lme1,type=\"pearson\",scaled=T))\n#&gt;         0%        25%        50%        75%       100% \n#&gt; -1.9238372 -0.3606612 -0.1334336  0.0981939  2.8422803\n# 查看固定效应和显著性检验\nfixef(lme1)   \n#&gt;    (Intercept)            NAP     Exposure10     Exposure11 NAP:Exposure10 \n#&gt;     13.3456944     -4.1752712     -5.3272654     -9.7660482      0.1646123 \n#&gt; NAP:Exposure11 \n#&gt;      2.7273068\nanova(lme1)\n#&gt; Type III Analysis of Variance Table with Satterthwaite's method\n#&gt;               Sum Sq Mean Sq NumDF  DenDF F value  Pr(&gt;F)  \n#&gt; NAP           90.646  90.646     1 5.5230 13.8711 0.01139 *\n#&gt; Exposure     109.852  54.926     2 5.2975  8.4051 0.02273 *\n#&gt; NAP:Exposure  22.308  11.154     2 5.3880  1.7068 0.26657  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n# 随机效应：随机截距和随机斜率  # 每个组的随机截距表示该组的平均值与模型整体平均值（截距）的差异\nranef(lme1) \n#&gt; $Beach\n#&gt;     (Intercept)           NAP\n#&gt; 1 -4.274356e-02  3.713708e-02\n#&gt; 2 -2.709479e-14  2.354089e-14\n#&gt; 3  3.819348e-03 -3.318381e-03\n#&gt; 4 -2.741786e-01  2.382158e-01\n#&gt; 5  3.269522e+00 -2.840673e+00\n#&gt; 6  2.736093e-01 -2.377212e-01\n#&gt; 7 -3.250033e-03  2.823741e-03\n#&gt; 8 -2.148947e+00  1.867079e+00\n#&gt; 9 -1.077831e+00  9.364564e-01\n#&gt; \n#&gt; with conditional variances for \"Beach\"\n# 随机效应的显著性检验\nlmerTest::ranova(lme1)\n#&gt; ANOVA-like table for random-effects: Single term deletions\n#&gt; \n#&gt; Model:\n#&gt; Richness ~ NAP + Exposure + (1 + NAP | Beach) + NAP:Exposure\n#&gt;                          npar  logLik    AIC    LRT Df Pr(&gt;Chisq)\n#&gt; &lt;none&gt;                     10 -103.58 227.16                     \n#&gt; NAP in (1 + NAP | Beach)    8 -105.67 227.35 4.1935  2     0.1229\n\ncor(ranef(lme1)$Beach)\n#&gt;             (Intercept) NAP\n#&gt; (Intercept)           1  -1\n#&gt; NAP                  -1   1\n\n\n\nShow the codee &lt;- glmm.hp::glmm.hp(lme1)\nsave(e,file = \"data/glmm.hp.Rdata\")\n\n# $r.squaredGLMM\n#            R2m       R2c\n# [1,] 0.6279508 0.7811086\n# \n# $hierarchical.partitioning\n#              Unique Average.share Individual I.perc(%)\n# 1            0.0000        0.0657     0.0657     10.46\n# NAP          0.0000        0.0867     0.0867     13.81\n# Exposure     0.2987        0.0135     0.3122     49.71\n# NAP:Exposure 0.0884        0.0750     0.1634     26.02\n# \n# $variables\n# [1] \"1\"            \"NAP\"          \"Exposure\"     \"NAP:Exposure\"\n# \n# $type\n# [1] \"hierarchical.partitioning\"\n# \n# attr(,\"class\")\n# [1] \"glmmhp\"\n\n\n\nShow the codeload(\"data/glmm.hp.Rdata\")\ne\n#&gt; $r.squaredGLMM\n#&gt;            R2m       R2c\n#&gt; [1,] 0.6279508 0.7811086\n#&gt; \n#&gt; $hierarchical.partitioning\n#&gt;              Unique Average.share Individual I.perc(%)\n#&gt; 1            0.0000        0.0657     0.0657     10.46\n#&gt; NAP          0.0000        0.0867     0.0867     13.81\n#&gt; Exposure     0.2987        0.0135     0.3122     49.71\n#&gt; NAP:Exposure 0.0884        0.0750     0.1634     26.02\n#&gt; \n#&gt; $variables\n#&gt; [1] \"1\"            \"NAP\"          \"Exposure\"     \"NAP:Exposure\"\n#&gt; \n#&gt; $type\n#&gt; [1] \"hierarchical.partitioning\"\n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"glmmhp\"\n\n\n$r.squaredGLMM\n\n\n这里呈现了两个衡量模型拟合优度的指标，R2m 和 R2c，分别对应不同的广义决定系数计算方式。\n\nR2m 的值为 0.6279508，表示固定效应变量解释了大约62.80%的响应变量的方差\nR2c 的值为 0.7811086，表示固定效应和随机效应共同解释了大约78.11%的响应变量的方差\n\n\n\n$hierarchical.partitioning\n\n“Unique” 列：展示了各变量独自解释的方差比例\n“Average.share” 列：变量与其他变量所有组合的方差解释比例\n“Individual” 列：“Unique”和“Average.share”的和，即变量的总贡献\n“I.perc (%)” 列：每个变量的相对重要性程度。\n\n$variables\n\n简单列出了模型中涉及的变量名称，这里有 \"1\"（代表整体截距）、\"NAP\"、\"Exposure\" 以及它们的交互项 \"NAP:Exposure\"，明确了模型在分析中考虑的因素构成。\n\n$type\n\n指出了当前分析结果呈现的类型是 \"hierarchical.partitioning\"，说明后续如果进一步拓展分析或者对比不同模型等操作时，可以清楚知道这部分结果对应的分析类别。\n\n\nShow the codeplot(e)",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合效应模型</span>"
    ]
  },
  {
    "objectID": "LMM.html#随机截距固定斜率",
    "href": "LMM.html#随机截距固定斜率",
    "title": "\n14  线性混合效应模型\n",
    "section": "\n14.4 随机截距+固定斜率",
    "text": "14.4 随机截距+固定斜率\n\\[\n\\eta_{(nrow \\ \\times 1)}=\\mathbf{X_{nrow×1}}\\beta_{1\\times1} +Z_{nrow\\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects}\\times 1}+\\epsilon_i\n\\]\nZ有一倍于受试者数量的列，每个受试者的随机截距。\n\nShow the codelme2 &lt;- lmer(Richness ~ 1 + NAP * Exposure+ (1+1 |Beach) ,data = rikz)\nsummary(lme2)\n#&gt; Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n#&gt; lmerModLmerTest]\n#&gt; Formula: Richness ~ 1 + NAP * Exposure + (1 + 1 | Beach)\n#&gt;    Data: rikz\n#&gt; \n#&gt; REML criterion at convergence: 211.3\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.5653 -0.4387 -0.1165  0.1783  4.1098 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 0.2641   0.5139  \n#&gt;  Residual             8.8316   2.9718  \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;                Estimate Std. Error      df t value Pr(&gt;|t|)    \n#&gt; (Intercept)     13.3457     1.4836  6.5050   8.996 6.63e-05 ***\n#&gt; NAP             -4.1753     1.5051 33.0857  -2.774 0.009030 ** \n#&gt; Exposure10      -5.5450     1.6577  6.4545  -3.345 0.013909 *  \n#&gt; Exposure11      -9.7306     1.6705  6.6476  -5.825 0.000781 ***\n#&gt; NAP:Exposure10   0.6717     1.6439 34.9341   0.409 0.685306    \n#&gt; NAP:Exposure11   2.6888     1.6567 34.2669   1.623 0.113766    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;             (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP         -0.278                             \n#&gt; Exposure10  -0.895  0.249                      \n#&gt; Exposure11  -0.888  0.247  0.795               \n#&gt; NAP:Expsr10  0.255 -0.916 -0.276 -0.226        \n#&gt; NAP:Expsr11  0.253 -0.908 -0.226 -0.296  0.832\nAIC(lme2)\n#&gt; [1] 227.3493\nBIC(lme2)\n#&gt; [1] 241.8026\nlogLik(lme2)\n#&gt; 'log Lik.' -105.6747 (df=8)\n\n2*(1-pt(6.007,35,lower.tail = T))\n#&gt; [1] 7.558855e-07\n\n\n\nlme(Richness ~ 1 + NAP * Exposure,random= ~ 1+1 |Beach ,data = rikz) |&gt; \n    summary()\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: rikz \n#&gt;        AIC      BIC    logLik\n#&gt;   227.3493 240.6578 -105.6747\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 + 1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:   0.5138683 2.971793\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  1.483557 33  8.995739  0.0000\n#&gt; NAP            -4.175271  1.505110 33 -2.774063  0.0090\n#&gt; Exposure10     -5.544983  1.657659  6 -3.345069  0.0155\n#&gt; Exposure11     -9.730595  1.670518  6 -5.824898  0.0011\n#&gt; NAP:Exposure10  0.671731  1.643864 33  0.408629  0.6855\n#&gt; NAP:Exposure11  2.688806  1.656743 33  1.622947  0.1141\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.278                             \n#&gt; Exposure10     -0.895  0.249                      \n#&gt; Exposure11     -0.888  0.247  0.795               \n#&gt; NAP:Exposure10  0.255 -0.916 -0.276 -0.226        \n#&gt; NAP:Exposure11  0.253 -0.908 -0.226 -0.296  0.832 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.5652904 -0.4386841 -0.1164805  0.1783113  4.1098230 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合效应模型</span>"
    ]
  },
  {
    "objectID": "LMM.html#固定截距随机斜率",
    "href": "LMM.html#固定截距随机斜率",
    "title": "\n14  线性混合效应模型\n",
    "section": "\n14.5 固定截距+随机斜率",
    "text": "14.5 固定截距+随机斜率\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ 有一倍于受试者数量的列，每个受试者的随机斜率。\n\nShow the codelme3 &lt;- lmer(Richness ~ 1 +  NAP * Exposure + (0 + NAP |Beach) ,data = rikz)\nsummary(lme3)\n#&gt; Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n#&gt; lmerModLmerTest]\n#&gt; Formula: Richness ~ 1 + NAP * Exposure + (0 + NAP | Beach)\n#&gt;    Data: rikz\n#&gt; \n#&gt; REML criterion at convergence: 211.4\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.6048 -0.4448 -0.1226  0.2322  4.1284 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name Variance Std.Dev.\n#&gt;  Beach    NAP  0.000    0.000   \n#&gt;  Residual      9.024    3.004   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;                Estimate Std. Error      df t value Pr(&gt;|t|)    \n#&gt; (Intercept)     13.3457     1.4068 39.0000   9.486 1.11e-11 ***\n#&gt; NAP             -4.1753     1.5214 39.0000  -2.744  0.00912 ** \n#&gt; Exposure10      -5.5318     1.5715 39.0000  -3.520  0.00111 ** \n#&gt; Exposure11      -9.7284     1.5852 39.0000  -6.137 3.34e-07 ***\n#&gt; NAP:Exposure10   0.6278     1.6583 39.0000   0.379  0.70703    \n#&gt; NAP:Exposure11   2.6835     1.6725 39.0000   1.604  0.11668    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;             (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP         -0.297                             \n#&gt; Exposure10  -0.895  0.266                      \n#&gt; Exposure11  -0.887  0.263  0.794               \n#&gt; NAP:Expsr10  0.272 -0.917 -0.294 -0.242        \n#&gt; NAP:Expsr11  0.270 -0.910 -0.242 -0.315  0.835 \n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\n\n\nlme(Richness ~ 1 + NAP * Exposure,random= ~ 0+NAP |Beach ,data = rikz) |&gt; \n    summary()\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: rikz \n#&gt;        AIC      BIC    logLik\n#&gt;   227.3962 240.7047 -105.6981\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~0 + NAP | Beach\n#&gt;                  NAP Residual\n#&gt; StdDev: 0.0001223769 3.004042\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  1.406821 33  9.486418  0.0000\n#&gt; NAP            -4.175271  1.521443 33 -2.744283  0.0097\n#&gt; Exposure10     -5.531822  1.571461  6 -3.520178  0.0125\n#&gt; Exposure11     -9.728394  1.585241  6 -6.136854  0.0009\n#&gt; NAP:Exposure10  0.627847  1.658269 33  0.378616  0.7074\n#&gt; NAP:Exposure11  2.683487  1.672531 33  1.604447  0.1181\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.297                             \n#&gt; Exposure10     -0.895  0.266                      \n#&gt; Exposure11     -0.887  0.263  0.794               \n#&gt; NAP:Exposure10  0.272 -0.917 -0.294 -0.242        \n#&gt; NAP:Exposure11  0.270 -0.910 -0.242 -0.315  0.835 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.6048271 -0.4448474 -0.1225590  0.2321686  4.1283628 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合效应模型</span>"
    ]
  },
  {
    "objectID": "LMM.html#随机效应模型",
    "href": "LMM.html#随机效应模型",
    "title": "\n14  线性混合效应模型\n",
    "section": "\n14.6 随机效应模型",
    "text": "14.6 随机效应模型\n\nShow the code\nlme4 &lt;- lmer(Richness ~ 1 + (1+NAP|Beach) ,data = rikz)\nsummary(lme4)\n#&gt; Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n#&gt; lmerModLmerTest]\n#&gt; Formula: Richness ~ 1 + (1 + NAP | Beach)\n#&gt;    Data: rikz\n#&gt; \n#&gt; REML criterion at convergence: 242.9\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.1607 -0.4415 -0.1999  0.2065  2.6133 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  Beach    (Intercept) 28.173   5.308         \n#&gt;           NAP         11.292   3.360    -0.95\n#&gt;  Residual              6.697   2.588         \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error     df t value Pr(&gt;|t|)  \n#&gt; (Intercept)   2.8023     0.8218 3.7478    3.41   0.0299 *\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nranef(lme4)\n#&gt; $Beach\n#&gt;   (Intercept)        NAP\n#&gt; 1   6.0112287 -2.8605659\n#&gt; 2   9.7420133 -5.0379262\n#&gt; 3   0.8792316 -0.9838634\n#&gt; 4   0.3721784 -0.7548668\n#&gt; 5   9.1546337 -6.7668418\n#&gt; 6   1.5719076 -1.1861532\n#&gt; 7   0.4484228 -0.7999673\n#&gt; 8   2.1690889 -1.6492031\n#&gt; 9   3.3610981 -2.4639704\n#&gt; \n#&gt; with conditional variances for \"Beach\"\n\nlme(Richness ~ 1 ,random= ~ 1+NAP |Beach ,data = rikz) |&gt; \n    summary()\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: rikz \n#&gt;       AIC      BIC    logLik\n#&gt;   252.935 261.8559 -121.4675\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 + NAP | Beach\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev   Corr  \n#&gt; (Intercept) 5.307778 (Intr)\n#&gt; NAP         3.360427 -0.948\n#&gt; Residual    2.587870       \n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 \n#&gt;                Value Std.Error DF  t-value p-value\n#&gt; (Intercept) 2.802324 0.8217849 36 3.410046  0.0016\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -2.1606764 -0.4415215 -0.1998751  0.2064870  2.6133376 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合效应模型</span>"
    ]
  },
  {
    "objectID": "LMM.html#线性模型固定截距-固定斜率",
    "href": "LMM.html#线性模型固定截距-固定斜率",
    "title": "\n14  线性混合效应模型\n",
    "section": "\n14.7 线性模型：固定截距+ 固定斜率",
    "text": "14.7 线性模型：固定截距+ 固定斜率\n\nShow the codelm &lt;- lm(Richness ~ 1 + NAP * Exposure ,data = rikz)\nlm\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Richness ~ 1 + NAP * Exposure, data = rikz)\n#&gt; \n#&gt; Coefficients:\n#&gt;    (Intercept)             NAP      Exposure10      Exposure11  NAP:Exposure10  \n#&gt;        13.3457         -4.1753         -5.5318         -9.7284          0.6278  \n#&gt; NAP:Exposure11  \n#&gt;         2.6835",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合效应模型</span>"
    ]
  },
  {
    "objectID": "LMM.html#模型选择",
    "href": "LMM.html#模型选择",
    "title": "\n14  线性混合效应模型\n",
    "section": "\n14.8 模型选择",
    "text": "14.8 模型选择\n限制最大似然法REML\n\n\n赤池信息准则（AIC）\n\\[ kIC=−2log(\\mathcal{L})+2k\\]\n其中：\n\n\\(\\mathcal{L}\\) 是似然函数。\n\\(k\\) 是模型参数的数量。\n\n\n\n贝叶斯信息准则（BIC）\n\\[ BIC=−2log(\\mathcal{L})+klog(n) \\]\n其中：\n\n\n\\(n\\) 是样本量。\n\n\n\n\nShow the code\nplot_lme &lt;- function(model, title) {\n    ggplot(rikz, aes(NAP, Richness, group = Beach, color = Beach)) +\n        geom_point() +\n        geom_line(\n            data =  bind_cols(rikz, .pred = predict(model, rikz)),\n            mapping = aes(y = .pred),\n            linewidth = 1\n        ) +\n        labs(title = title)+\n        scale_x_continuous(expand = (mult=c(0,.1)))+\n        scale_y_continuous(expand = (mult=c(0,.1)))+\n    ggsci::scale_color_jco() +\n        ggpubr::theme_pubr() +\n        theme(legend.position = \"right\",\n              plot.title = element_text(hjust = .5))\n}\n\nlibrary(purrr)\nlibrary(ggplot2)\nlme_plot &lt;- map2(list(lme1,lme2,lme3, lme4,lm),list(\"随机截距+随机斜率\",\"随机截距+固定斜率\",\"固定截距+随机斜率\",\"随机效应\",\"固定效应\"),plot_lme)\n\n\nlme_plot\n#&gt; [[1]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[2]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[3]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[4]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[5]]\n\n\n\n\n\n\n\n\nShow the codeanova(lme1,lme2,lme3,lme4,lm)\n#&gt; Data: rikz\n#&gt; Models:\n#&gt; lme4: Richness ~ 1 + (1 + NAP | Beach)\n#&gt; lm: Richness ~ 1 + NAP * Exposure\n#&gt; lme2: Richness ~ 1 + NAP * Exposure + (1 + 1 | Beach)\n#&gt; lme3: Richness ~ 1 + NAP * Exposure + (0 + NAP | Beach)\n#&gt; lme1: Richness ~ 1 + NAP + Exposure + NAP:Exposure + (1 + NAP | Beach)\n#&gt;      npar    AIC    BIC  logLik -2*log(L)   Chisq Df Pr(&gt;Chisq)    \n#&gt; lme4    5 254.24 263.27 -122.12    244.24                          \n#&gt; lm      7 234.26 246.91 -110.13    220.26 23.9789  2  6.209e-06 ***\n#&gt; lme2    8 236.26 250.71 -110.13    220.26  0.0000  1     1.0000    \n#&gt; lme3    8 236.26 250.71 -110.13    220.26  0.0000  0               \n#&gt; lme1   10 238.20 256.27 -109.10    218.20  2.0619  2     0.3567    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# p小于0.05,说明全模型与简化后模型存在差异，最终采用lme1,AIC",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合效应模型</span>"
    ]
  },
  {
    "objectID": "LMM.html#模型诊断",
    "href": "LMM.html#模型诊断",
    "title": "\n14  线性混合效应模型\n",
    "section": "\n14.9 模型诊断",
    "text": "14.9 模型诊断\nsleepstudy\n\nShow the code# 拟合线性混合模型\nmodel &lt;- lme1\n# 1. 残差图\nresiduals &lt;- resid(model)\nfitted &lt;- fitted(model)\nggplot(data.frame(fitted, residuals), aes(fitted, residuals)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(title = \"Residuals vs Fitted\", x = \"Fitted values\", y = \"Residuals\")\n\n\n\n\n\n\nShow the code\n# 2. QQ图\nqqnorm(residuals)\nqqline(residuals)\n\n\n\n\n\n\nShow the code\n# 3. Cook's 距离\ncooksd &lt;- cooks.distance(model)\nplot(cooksd, type = \"h\", main = \"Cook's Distance\")\n\n\n\n\n\n\nShow the code\n# 4. 随机效应的分布\nrand_dist &lt;- ranef(model)\n\nqqnorm(rand_dist$Beach$NAP)\nqqline(rand_dist$Beach$NAP)",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合效应模型</span>"
    ]
  },
  {
    "objectID": "GLM.html",
    "href": "GLM.html",
    "title": "\n15  广义线性模型\n",
    "section": "",
    "text": "15.1 GLM 组件\n在统计学上，广义线性模型（generalized linear model， GLM）是一种应用灵活的线性回归模型。该模型允许因变量的误差分布有除了正态分布之外的其它分布。此模型假设实验者所测量的随机变量的分布函数与实验中系统性效应（即非随机的效应）可经由一链接函数（link function）建立可解释其相关性的函数。\n在广义线性模式中，假设每个资料的观测值 Y 来自某个指数族分布 f 。\n广义线性模型是对线性模型的扩展，适用于非正态分布的数据，假设观测值之间是独立的，不能处理组内相关性。模型形式为：\n\\[\ng(E(Y))=\\mathbf{X} \\beta\n\\]\n\\[\n\\eta = \\mathbf{X} \\beta\n\\]\n\\[\nE(y)=\\mu\n\\]\n\\[\n\\eta =g(\\mu)=g(E(y))\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\n典型链接函数",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#glm-组件",
    "href": "GLM.html#glm-组件",
    "title": "\n15  广义线性模型\n",
    "section": "",
    "text": "线性预测器（Linear Predictor）：\n\n\n\n因变量的期望值与线性预测函数的关系：\n\n\n\n链接函数 g(.) ：\n\n\n\n反链接函数g-1 (.)：\n\n\n\n\ny 的方差：\n\\[\nVar(y)=f(\\mu)=f(g^{-1}(\\mathbf{X}\\beta))\n\\]\n\n\n\n\n\nY的分布\n名称\n链接函数\n均值函数\n\n\n\n正态\n恒等\n\n\n\n\n\n指数 / Gamma\n倒数\n\n\n\n\n泊松\n自然对数\n\n\n\n\n\n二项式\n多项式\n\nLogit",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#数据来源",
    "href": "GLM.html#数据来源",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.2 数据来源",
    "text": "15.2 数据来源\n数据下载网站\n\nShow the codelibrary(tidyverse)\nlibrary(patchwork)\ndf &lt;- read_csv(\"data/Default.csv\")\n\ndf &lt;- df %&gt;% \n    mutate(across(1:2, ~ factor(.x,levels = c(\"No\",\"Yes\"),labels = c(0,1))\n                  )\n           )\nstr(df)\n#&gt; tibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ default: Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ student: Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 1 2 1 2 1 1 ...\n#&gt;  $ balance: num [1:10000] 730 817 1074 529 786 ...\n#&gt;  $ income : num [1:10000] 44362 12106 31767 35704 38463 ...\n\n# 是否违约 是否学生 余额 收入\nhead(df)\n#&gt; # A tibble: 6 × 4\n#&gt;   default student balance income\n#&gt;   &lt;fct&gt;   &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 0       0          730. 44362.\n#&gt; 2 0       1          817. 12106.\n#&gt; 3 0       0         1074. 31767.\n#&gt; 4 0       0          529. 35704.\n#&gt; 5 0       0          786. 38463.\n#&gt; 6 0       1          920.  7492.\ntable(df$default,df$student)\n#&gt;    \n#&gt;        0    1\n#&gt;   0 6850 2817\n#&gt;   1  206  127\n\n\n\nShow the codeggplot(df,aes(balance,income))+\n  geom_point(aes(shape=default,color=default),show.legend = F)|\nggplot(df,aes(default,balance,fill=default),)+\n  geom_boxplot(show.legend = F)+\nggplot(df,aes(default,income,fill=default))+\n  geom_boxplot()",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#恒等链接线性回归",
    "href": "GLM.html#恒等链接线性回归",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.3 恒等链接线性回归",
    "text": "15.3 恒等链接线性回归\n线性回归是一种简单的线性回归模型，其中假设响应变量服从正态分布，并且使用恒等链接函数（identity link function），t-statistic\n\nShow the codelibrary(tidymodels)\nlibrary(ggfortify)\n# 使用 glm() 函数进行高斯线性回归\nglm_gauss &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = stats::gaussian(link = \"identity\")) %&gt;% \n  fit(as.numeric(default)-1~balance,data=df)\n\n# 查看模型的系数\ntidy(glm_gauss)\n#&gt; # A tibble: 2 × 5\n#&gt;   term         estimate  std.error statistic   p.value\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept) -0.0752   0.00335        -22.4 1.26e-108\n#&gt; 2 balance      0.000130 0.00000347      37.4 2.77e-286\n\n# 查看模型性能的 AIC 和 Deviance\nglance(glm_gauss) %&gt;% dplyr::select(AIC, deviance)\n#&gt; # A tibble: 1 × 2\n#&gt;      AIC deviance\n#&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 -7284.     282.\n\n\n# Change the theme and colour\nautoplot(glm_gauss, which = 1:6, ncol = 2, label.size = 3,\n         colour = \"steelblue\") + theme_bw()\n\n\n\n\n\n\n\n\nShow the codeggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"lm\",se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"linear regression\")",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#逻辑回归",
    "href": "GLM.html#逻辑回归",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.4 逻辑回归",
    "text": "15.4 逻辑回归\n逻辑回归用于处理分类问题。其模型假设响应变量的对数优势（log odds）服从线性模型。\nSigmoid 激活函数：\n\\[\nf(x)=\\frac{1}{1+e^{-x}}=\\frac{e^x}{1+e^x}\n\\]\n\nShow the codesigmoid &lt;- tibble(\n    x=seq(-6,6,length.out=1000),\n    y=1/(1+exp(-x)),\n)\nggplot(sigmoid,aes(x,y))+\n    geom_line()\n\n\n\n\n\n\n\n逻辑回归( logistic regression )的一般表达式：\n\\[\n\\pi(Y=k|X=(X_1,X_2,...,X_p)=\\frac{e^{\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p}}{1+\\sum_{l=1}^{K-1} e^{\\beta_{l0}+\\beta_{l1}X_1+\\beta_{l2}X_2+...+\\beta_{lp}X_p}}\n\\] 其中\\(\\pi\\) 是成功概率，\\(k=1,2,...,K-1\\)是因变量的第k个水平，共K 个水平，\\(p\\) 是自变量个数。\nlogit link function\nz-statistic\n\n15.4.1 二分类Binary\n\n\n当\\(K=2\\)时，\\(k=l=p=1\\)即二分类逻辑回归，一般需要引入虚拟变量（哑变量，dummy variable），通常取值为 0或1。\n极大似然法（maximum likelihood），likelihood function：\n\\[\n\\ell (\\beta_0,\\beta_1)=\\prod_{i:y_i=1}\\pi(x_i)\\prod_{i':y_{i'}=0}(1-\\pi(x_{i'}))\n\\]\n\n\n\nShow the codelogit_spec &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\",family= binomial(link = \"logit\")) \n\n\nlogit_binary_y &lt;- logit_spec %&gt;% fit(default~balance,data=df)\n\nlogit_binary_y %&gt;% glance()\n#&gt; # A tibble: 1 × 8\n#&gt;   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         2921.    9999  -798. 1600. 1615.    1596.        9998 10000\n\ntidy(logit_binary_y,  conf.int = TRUE) %&gt;% \n    mutate(\n        z_value = estimate/std.error,\n        Wald_ChiSquare=z_value^2, #  Wald卡方值可以用来检验各个变量系数是否显著 不同于零。 它是通过系数估计的平方除以其标准误差的平方来计算的。即 z值的平方\n        OR = exp(estimate),\n        `OR 95% CI`= sprintf(\"%.3f ~ %3.f\",exp(conf.low),exp(conf.high)),\n    )\n#&gt; # A tibble: 2 × 11\n#&gt;   term         estimate std.error statistic   p.value conf.low conf.high z_value\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 (Intercept) -10.7      0.361        -29.5 3.62e-191 -1.14e+1  -9.97      -29.5\n#&gt; 2 balance       0.00550  0.000220      25.0 1.98e-137  5.08e-3   0.00594    25.0\n#&gt; # ℹ 3 more variables: Wald_ChiSquare &lt;dbl&gt;, OR &lt;dbl&gt;, `OR 95% CI` &lt;chr&gt;\n\n\nggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"glm\",\n              method.args=list(family=binomial(link = \"logit\")),se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"binary logistic regression with continuous x\")\n\n\n\n\n\n\n\n\nShow the codelogit_binary_x &lt;- logit_spec %&gt;%fit(default ~ student, data = df)\n\ntidy(logit_binary_x)\n#&gt; # A tibble: 2 × 5\n#&gt;   term        estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)   -3.50     0.0707    -49.6  0       \n#&gt; 2 student1       0.405    0.115       3.52 0.000431\n\n\nggplot(df,aes(student,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"glm\",\n              method.args=list(family=binomial(link = \"logit\")),se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n    scale_y_continuous(\"default\", breaks = c(0,1))+\n  ggtitle(\"binary logistic regression with binary x\")\n\n\n\n\n\n\n\n\n15.4.2 二分类多元逻辑回归\n\n\n当\\(K=2\\)时，\\(k=l=1,p&gt;1\\)即多元逻辑回归（multiple logistic regression）。\n优势（odds）\n\\[\nOdds=\\frac{\\pi(X)}{1-\\pi(X)}=e^{\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p}\n\\]\nlog odds (logit)\n\\[\nlogit(\\pi(X))=\\ln (\\frac{\\pi(X)}{1-\\pi(X)})=\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p\n\\]\n\n\n\nShow the codelogit_multiple&lt;-logit_spec %&gt;% fit(default~balance+income+student,data=df)\n\ntidy(logit_multiple)\n#&gt; # A tibble: 4 × 5\n#&gt;   term            estimate  std.error statistic   p.value\n#&gt;   &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept) -10.9        0.492        -22.1   4.91e-108\n#&gt; 2 balance       0.00574    0.000232      24.7   4.22e-135\n#&gt; 3 income        0.00000303 0.00000820     0.370 7.12e-  1\n#&gt; 4 student1     -0.647      0.236         -2.74  6.19e-  3\n\n# confusion matrix 混淆矩阵\naugment(logit_multiple, new_data = df) %&gt;%\n  conf_mat(truth = default, estimate = .pred_class) %&gt;% \n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\nShow the code\n#准确性 \n(9627+105)/(9627+105+40+228)\n#&gt; [1] 0.9732\naugment(logit_multiple, new_data = df) %&gt;%\n  accuracy(truth = default, estimate = .pred_class)\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.973\n\n\n\nShow the codedf_new &lt;- tibble(\n  balance = c(1000, 2000), \n  income = c(14144,24141),\n  student = factor(c(1, 0)),)\npredict(logit_multiple, new_data = df_new,type=\"class\")\n#&gt; # A tibble: 2 × 1\n#&gt;   .pred_class\n#&gt;   &lt;fct&gt;      \n#&gt; 1 0          \n#&gt; 2 1\npredict(logit_multiple, new_data = df_new, type = \"prob\")\n#&gt; # A tibble: 2 × 2\n#&gt;   .pred_0 .pred_1\n#&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   0.997 0.00322\n#&gt; 2   0.337 0.663\n\n\n\n15.4.3 似然比检验\nlikelihood ratio tests (LRT)\n比较两个嵌套模型，log-likelihood (logLL)\n\n相应的p-value 源自具有 个自由度的 卡方 分布（即模型中测试的参数数量之差）。\n\nShow the codelogit_binary_y\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:  stats::glm(formula = default ~ balance, family = ~binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance  \n#&gt;  -10.651331     0.005499  \n#&gt; \n#&gt; Degrees of Freedom: 9999 Total (i.e. Null);  9998 Residual\n#&gt; Null Deviance:       2921 \n#&gt; Residual Deviance: 1596  AIC: 1600\nlogit_multiple\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:  stats::glm(formula = default ~ balance + income + student, family = ~binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance       income     student1  \n#&gt;  -1.087e+01    5.737e-03    3.033e-06   -6.468e-01  \n#&gt; \n#&gt; Degrees of Freedom: 9999 Total (i.e. Null);  9996 Residual\n#&gt; Null Deviance:       2921 \n#&gt; Residual Deviance: 1572  AIC: 1580\n\n\nLRT=2*(logLik(logit_multiple$fit)-logLik(logit_binary_y$fit))\nLRT\n#&gt; 'log Lik.' 24.90686 (df=4)\n\npval=1-pchisq(LRT,2)\npval\n#&gt; 'log Lik.' 3.904316e-06 (df=4)\n\nout&lt;-anova(logit_binary_y$fit, logit_multiple$fit)\nout\n#&gt; Analysis of Deviance Table\n#&gt; \n#&gt; Model 1: default ~ balance\n#&gt; Model 2: default ~ balance + income + student\n#&gt;   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n#&gt; 1      9998     1596.5                          \n#&gt; 2      9996     1571.5  2   24.907 3.904e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n1-pchisq(out$Deviance[2],2)\n#&gt; [1] 3.904316e-06\n\n\n\n15.4.4 K&gt;2 多分类逻辑回归\n用于处理具有多于两个类别的响应变量的情况。例如，分类问题中的三个或更多类别。\n\n\n当\\(K&gt;2\\)时，\\(k,l,p&gt;1\\)即多项逻辑回归（multinomial logistic regression）。\n\\[\n\\ln (\\frac{P(Y=k|X=x)}{P(Y=K|X=x)})=\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p\n\\]\n\n\n\n15.4.4.1 nnet::multinom()\n\n\nShow the codemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"nnet\")\n\niris_mnlogit &lt;- mn_spec %&gt;% \n    fit(Species ~ ., data = iris)\n\niris_mnlogit %&gt;% glance()\n#&gt; # A tibble: 1 × 4\n#&gt;     edf deviance   AIC  nobs\n#&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    10     11.9  31.9   150\niris_mnlogit %&gt;% tidy()\n#&gt; # A tibble: 10 × 6\n#&gt;    y.level    term         estimate std.error statistic p.value\n#&gt;    &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1 versicolor (Intercept)     18.7       35.0    0.534    0.593\n#&gt;  2 versicolor Sepal.Length    -5.46      89.9   -0.0607   0.952\n#&gt;  3 versicolor Sepal.Width     -8.71     157.    -0.0554   0.956\n#&gt;  4 versicolor Petal.Length    14.2       60.2    0.237    0.813\n#&gt;  5 versicolor Petal.Width     -3.10      45.5   -0.0681   0.946\n#&gt;  6 virginica  (Intercept)    -23.8       35.8   -0.666    0.505\n#&gt;  7 virginica  Sepal.Length    -7.92      89.9   -0.0881   0.930\n#&gt;  8 virginica  Sepal.Width    -15.4      157.    -0.0978   0.922\n#&gt;  9 virginica  Petal.Length    23.7       60.5    0.391    0.696\n#&gt; 10 virginica  Petal.Width     15.1       45.9    0.330    0.742\n\n\naugment(iris_mnlogit, new_data = iris) %&gt;%\n    conf_mat(truth = Species, estimate = .pred_class) %&gt;%\n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\n15.4.4.2 glmnet::glmnet()\n\n\nShow the codelibrary(glmnet) # 多项回归\niris_glmnet &lt;- glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\")\niris_glmnet\n#&gt; \n#&gt; Call:  glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\") \n#&gt; \n#&gt;     Df  %Dev  Lambda\n#&gt; 1    0  0.00 0.43500\n#&gt; 2    1  6.56 0.39640\n#&gt; 3    1 12.05 0.36110\n#&gt; 4    1 16.73 0.32910\n#&gt; 5    1 20.78 0.29980\n#&gt; 6    2 25.37 0.27320\n#&gt; 7    2 29.66 0.24890\n#&gt; 8    2 33.54 0.22680\n#&gt; 9    2 37.10 0.20670\n#&gt; 10   2 40.40 0.18830\n#&gt; 11   2 43.47 0.17160\n#&gt; 12   3 46.47 0.15630\n#&gt; 13   3 49.57 0.14240\n#&gt; 14   3 52.38 0.12980\n#&gt; 15   3 54.97 0.11830\n#&gt; 16   3 57.36 0.10780\n#&gt; 17   3 59.60 0.09818\n#&gt; 18   3 61.71 0.08946\n#&gt; 19   3 63.72 0.08151\n#&gt; 20   3 65.70 0.07427\n#&gt; 21   3 67.65 0.06767\n#&gt; 22   3 69.54 0.06166\n#&gt; 23   3 71.38 0.05618\n#&gt; 24   3 73.12 0.05119\n#&gt; 25   3 74.71 0.04664\n#&gt; 26   3 76.24 0.04250\n#&gt; 27   3 77.67 0.03872\n#&gt; 28   3 78.99 0.03528\n#&gt; 29   3 80.21 0.03215\n#&gt; 30   3 81.33 0.02929\n#&gt; 31   3 82.36 0.02669\n#&gt; 32   3 83.31 0.02432\n#&gt; 33   3 84.18 0.02216\n#&gt; 34   3 84.99 0.02019\n#&gt; 35   3 85.73 0.01840\n#&gt; 36   3 86.53 0.01676\n#&gt; 37   3 87.34 0.01527\n#&gt; 38   3 88.06 0.01392\n#&gt; 39   3 88.73 0.01268\n#&gt; 40   3 89.34 0.01155\n#&gt; 41   3 89.89 0.01053\n#&gt; 42   3 90.40 0.00959\n#&gt; 43   4 90.87 0.00874\n#&gt; 44   4 91.34 0.00796\n#&gt; 45   4 91.77 0.00726\n#&gt; 46   4 92.16 0.00661\n#&gt; 47   4 92.52 0.00602\n#&gt; 48   4 92.85 0.00549\n#&gt; 49   4 93.16 0.00500\n#&gt; 50   4 93.44 0.00456\n#&gt; 51   4 93.69 0.00415\n#&gt; 52   4 93.92 0.00378\n#&gt; 53   4 94.14 0.00345\n#&gt; 54   4 94.34 0.00314\n#&gt; 55   4 94.52 0.00286\n#&gt; 56   4 94.68 0.00261\n#&gt; 57   4 94.83 0.00238\n#&gt; 58   4 94.97 0.00216\n#&gt; 59   4 95.10 0.00197\n#&gt; 60   4 95.22 0.00180\n#&gt; 61   4 95.33 0.00164\n#&gt; 62   4 95.43 0.00149\n#&gt; 63   4 95.52 0.00136\n#&gt; 64   4 95.60 0.00124\n#&gt; 65   4 95.68 0.00113\n#&gt; 66   4 95.75 0.00103\n#&gt; 67   4 95.81 0.00094\n#&gt; 68   4 95.87 0.00085\n#&gt; 69   4 95.92 0.00078\n#&gt; 70   4 95.97 0.00071\n#&gt; 71   4 96.01 0.00065\n#&gt; 72   4 96.05 0.00059\n#&gt; 73   4 96.09 0.00054\n#&gt; 74   4 96.12 0.00049\n#&gt; 75   4 96.15 0.00045\n#&gt; 76   4 96.18 0.00041\n#&gt; 77   4 96.20 0.00037\n#&gt; 78   4 96.22 0.00034\n#&gt; 79   4 96.24 0.00031\n#&gt; 80   4 96.26 0.00028\n#&gt; 81   4 96.27 0.00025\n#&gt; 82   4 96.29 0.00023\n#&gt; 83   4 96.30 0.00021\n#&gt; 84   4 96.31 0.00019\n#&gt; 85   4 96.32 0.00018\n#&gt; 86   4 96.33 0.00016\n#&gt; 87   4 96.33 0.00015\n#&gt; 88   4 96.34 0.00013\n#&gt; 89   4 96.35 0.00012\n#&gt; 90   4 96.35 0.00011\n#&gt; 91   4 96.35 0.00010\n#&gt; 92   4 96.36 0.00009\n#&gt; 93   4 96.36 0.00008\n#&gt; 94   4 96.36 0.00008\n#&gt; 95   4 96.37 0.00007\n#&gt; 96   4 96.37 0.00006\n#&gt; 97   4 96.37 0.00006\n#&gt; 98   4 96.37 0.00005\n#&gt; 99   4 96.38 0.00005\n#&gt; 100  4 96.38 0.00004\nsummary(iris_glmnet )\n#&gt;            Length Class  Mode     \n#&gt; a0         300    -none- numeric  \n#&gt; beta         3    -none- list     \n#&gt; dfmat      300    -none- numeric  \n#&gt; df         100    -none- numeric  \n#&gt; dim          2    -none- numeric  \n#&gt; lambda     100    -none- numeric  \n#&gt; dev.ratio  100    -none- numeric  \n#&gt; nulldev      1    -none- numeric  \n#&gt; npasses      1    -none- numeric  \n#&gt; jerr         1    -none- numeric  \n#&gt; offset       1    -none- logical  \n#&gt; classnames   3    -none- character\n#&gt; grouped      1    -none- logical  \n#&gt; call         4    -none- call     \n#&gt; nobs         1    -none- numeric\nplot(iris_glmnet)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the codeplot(iris_glmnet$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\", main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\nShow the code\n# 选择一个迭代趋于稳定时的 lambda，比如 iris_glmnet$lambda[80]\ncoef(iris_glmnet, s = 0.0002796185)\n#&gt; $setosa\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;              s=0.0002796185\n#&gt; (Intercept)       17.015429\n#&gt; Sepal.Length       .       \n#&gt; Sepal.Width        4.486992\n#&gt; Petal.Length      -3.250342\n#&gt; Petal.Width       -3.315393\n#&gt; \n#&gt; $versicolor\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;              s=0.0002796185\n#&gt; (Intercept)        8.132656\n#&gt; Sepal.Length       2.123980\n#&gt; Sepal.Width        .       \n#&gt; Petal.Length       .       \n#&gt; Petal.Width        .       \n#&gt; \n#&gt; $virginica\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;              s=0.0002796185\n#&gt; (Intercept)      -25.148085\n#&gt; Sepal.Length       .       \n#&gt; Sepal.Width       -5.176029\n#&gt; Petal.Length       7.536940\n#&gt; Petal.Width       14.481524\n\niris_pred_glmnet &lt;- predict(\n  object = iris_glmnet, newx = as.matrix(iris[, -5]),\n  s = 0.0002796185, type = \"class\"\n)\n\n\n\nShow the codemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"glmnet\" ,\n                        penalty = 0)\n\niris_mnlogit &lt;- mn_spec %&gt;% \n    fit(Species ~ ., data = iris)\niris_mnlogit %&gt;% glance()\n#&gt; # A tibble: 1 × 3\n#&gt;   nulldev npasses  nobs\n#&gt;     &lt;dbl&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1    330.    6546   150\niris_mnlogit$fit %&gt;% tidy() %&gt;% DT::datatable()\n\n\n\n\n\n\n15.4.5 有序逻辑回归\n\\[\n    \\ln \\left(\\frac{P(Y\\le k|X=x)}{1-P(Y\\le k|X=x)}\\right)\n\\]\n\nShow the code# 数据集 icpsr\nacl &lt;- read_rds(\"data/advanced_acl_data.rds\")\nacl$PhysActCat_W1 &lt;- factor(acl$PhysActCat_W1,ordered = T)\nstr(acl$PhysActCat_W1)\n#&gt;  Ord.factor w/ 5 levels \"(1) Low_5th\"&lt;..: 1 3 5 3 2 2 3 1 4 5 ...\n\nordered_logit &lt;- MASS::polr(PhysActCat_W1 ~ SelfEfficacy_W1, data = acl,\n                            method = \"logistic\")\nordered_logit %&gt;% summary()\n#&gt; Call:\n#&gt; MASS::polr(formula = PhysActCat_W1 ~ SelfEfficacy_W1, data = acl, \n#&gt;     method = \"logistic\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                  Value Std. Error t value\n#&gt; SelfEfficacy_W1 0.2431    0.02893   8.404\n#&gt; \n#&gt; Intercepts:\n#&gt;                           Value    Std. Error t value \n#&gt; (1) Low_5th|(2) 2Low_5th   -0.9332   0.0371   -25.1533\n#&gt; (2) 2Low_5th|(3) 3Low_5th  -0.2688   0.0338    -7.9606\n#&gt; (3) 3Low_5th|(4) 4Low_5th   0.8470   0.0364    23.2527\n#&gt; (4) 4Low_5th|(5) Hi_5th     1.5298   0.0435    35.1647\n#&gt; \n#&gt; Residual Deviance: 11196.86 \n#&gt; AIC: 11206.86\n\npredict(ordered_logit ,acl ,type = \"prob\") %&gt;% \n    as_tibble() %&gt;% \n    DT::datatable()\n\n\n\n\nShow the code\npredict(ordered_logit ,acl ,type = \"class\") %&gt;% \n    as_tibble() %&gt;% \n    DT::datatable()",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#泊松回归",
    "href": "GLM.html#泊松回归",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.5 泊松回归",
    "text": "15.5 泊松回归\n泊松回归用于计数数据，假设响应变量服从泊松分布，并使用对数链接函数（log link function），z-statistic\nfamily=poisson(link = \"log\")\nfamily = quasipoisson(link = \"log\"))\n\\[\nP(X=x;\\lambda)=\\frac{e^{-\\lambda}\\lambda ^x}{x!}\n\\]\n\nShow the codeggplot(tibble(x=0:20,\n              y1=dpois(x,lambda = 2),\n              y2=dpois(x,lambda = 6),\n              ),\n       aes(x)\n       )+\n    geom_col(aes(y=y1),fill = \"lightblue\")+\n    geom_col(aes(y=y2),fill = \"yellow\",alpha=.3)+\n    ylab(\"Poisson Density\")\n\n\n\n\n\n\n\n\nShow the codelibrary(poissonreg)\ndf2 &lt;- read_csv(\"data/Bikeshare.csv\")\n\n\n\nShow the code# 泊松回归模型\npois_spec &lt;- poisson_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"glm\",family=poisson(link = \"log\"))\n\npois_rec_spec &lt;- recipe(bikers ~ mnth + hr + workingday + temp + weathersit, data = df2) %&gt;% \n    step_dummy(all_nominal_predictors()) # 虚拟变量\n\npois_wf &lt;- workflow() %&gt;% \n  add_recipe(pois_rec_spec) %&gt;% \n  add_model(pois_spec)\n\npois_fit &lt;- pois_wf %&gt;% fit(data = df2)\n\n\ntidy(pois_fit)\n#&gt; # A tibble: 18 × 5\n#&gt;    term                       estimate std.error statistic   p.value\n#&gt;    &lt;chr&gt;                         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1 (Intercept)                 3.01     0.00632     477.   0        \n#&gt;  2 hr                          0.0507   0.000144    352.   0        \n#&gt;  3 workingday                 -0.0128   0.00195      -6.57 4.91e- 11\n#&gt;  4 temp                        2.56     0.00995     258.   0        \n#&gt;  5 mnth_Aug                   -0.229    0.00470     -48.7  0        \n#&gt;  6 mnth_Dec                    0.298    0.00501      59.5  0        \n#&gt;  7 mnth_Feb                   -0.102    0.00592     -17.2  5.28e- 66\n#&gt;  8 mnth_Jan                   -0.145    0.00678     -21.4  1.74e-101\n#&gt;  9 mnth_July                  -0.378    0.00496     -76.2  0        \n#&gt; 10 mnth_June                  -0.150    0.00462     -32.5  1.32e-231\n#&gt; 11 mnth_March                 -0.0312   0.00534      -5.83 5.44e-  9\n#&gt; 12 mnth_May                    0.0508   0.00434      11.7  1.43e- 31\n#&gt; 13 mnth_Nov                    0.285    0.00461      61.8  0        \n#&gt; 14 mnth_Oct                    0.267    0.00432      61.7  0        \n#&gt; 15 mnth_Sept                  -0.00653  0.00443      -1.47 1.41e-  1\n#&gt; 16 weathersit_cloudy.misty    -0.0308   0.00216     -14.2  5.70e- 46\n#&gt; 17 weathersit_heavy.rain.snow -0.646    0.167        -3.87 1.08e-  4\n#&gt; 18 weathersit_light.rain.snow -0.473    0.00404    -117.   0\n\n\n# 绘制实际值与预测值的关系图\naugment(pois_fit, new_data = df2, type = \"response\") %&gt;%\n    ggplot(aes(bikers, .pred)) +\n    geom_point(alpha = 0.1) +\n    geom_abline(slope = 1,\n                linewidth = 1,\n                color = \"grey40\") +\n    labs(title = \"Predicting the number of bikers per hour using Poission Regression\", x = \"Actual\", y = \"Predicted\")\n\n\n\n\n\n\n\n\nShow the codepois_fit_coef_mnths &lt;- \n  tidy(pois_fit) %&gt;% \n  dplyr::filter(grepl(\"^mnth\", term)) %&gt;% \n  mutate(\n    term = stringr::str_replace(term, \"mnth_\", \"\"),\n    term = forcats::fct_inorder(term)\n  ) \n\npois_fit_coef_mnths %&gt;% \n  ggplot(aes(term, estimate)) +\n  geom_line(group = 1,na.rm = TRUE) +\n  geom_point(shape = 21, size = 3, stroke = 1.5, \n             fill = \"black\", color = \"white\",na.rm = TRUE) +\n  labs(title = \"Coefficient value from Poission Regression\",\n       x = \"Month\", y = \"Coefficient\")\n\n\n\n\n\n\n\n\nShow the codepois_acl &lt;- pois_spec %&gt;% \n    fit(NChronic12_W1 ~ SelfEfficacy_W1,data = acl)\n\npois_acl %&gt;% glance()\n#&gt; # A tibble: 1 × 8\n#&gt;   null.deviance df.null logLik    AIC    BIC deviance df.residual  nobs\n#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         5217.    3616 -5161. 10327. 10339.    5114.        3615  3617\n\npois_acl %&gt;% tidy()\n#&gt; # A tibble: 2 × 5\n#&gt;   term            estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)       0.0713    0.0162      4.40 1.06e- 5\n#&gt; 2 SelfEfficacy_W1  -0.150     0.0144    -10.4  3.97e-25\n\nAIC(pois_acl$fit)\n#&gt; [1] 10326.52\nBIC(pois_acl$fit)\n#&gt; [1] 10338.9",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#负二项回归",
    "href": "GLM.html#负二项回归",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.6 负二项回归",
    "text": "15.6 负二项回归\n负二项回归用于处理计数数据且存在过度离散（overdispersion）的问题即当均值不等于方差。\nlog link function，z-statistic\nprobability mass function ：\n\\[\nP(X=x;\\lambda,\\nu)=\\binom{x+\\nu - 1}{ x} \\left ( \\frac{\\lambda}{\\lambda +\\nu} \\right)^x \\left ( \\frac{\\nu}{\\nu + \\lambda} \\right)^{\\nu}\n\\]\n负二项分布的均值是 \\(\\lambda\\) ，\n方差是 \\(\\lambda + \\frac{\\lambda ^2}{\\nu}\\) 。\n\nShow the codelibrary(MASS)\n# 负二项回归模型\nnb_spec &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = MASS::negative.binomial(theta = 1, link = \"log\"))\n\nnb_acl &lt;- nb_spec %&gt;% \n  fit(NChronic12_W1 ~ SelfEfficacy_W1, data = acl)\n\n# 查看模型结果\nnb_acl %&gt;% glance()\n#&gt; # A tibble: 1 × 8\n#&gt;   null.deviance df.null logLik    AIC    BIC deviance df.residual  nobs\n#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         2946.    3616 -5220. 10443. 10456.    2898.        3615  3617\nnb_acl %&gt;% tidy()\n#&gt; # A tibble: 2 × 5\n#&gt;   term            estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)       0.0715    0.0181      3.95 8.10e- 5\n#&gt; 2 SelfEfficacy_W1  -0.148     0.0169     -8.75 3.18e-18\n\n\nAIC(nb_acl$fit)\n#&gt; [1] 10443.43\nBIC(nb_acl$fit)\n#&gt; [1] 10455.82\n\n# MASS::glm.nb()",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#零膨胀模型zero-inflated",
    "href": "GLM.html#零膨胀模型zero-inflated",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.7 零膨胀模型（zero-inflated）",
    "text": "15.7 零膨胀模型（zero-inflated）\n逻辑回归+以上之一",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#正则化广义线性模型",
    "href": "GLM.html#正则化广义线性模型",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.8 正则化广义线性模型",
    "text": "15.8 正则化广义线性模型\nRidge、Lasso\n\nShow the codelibrary(glmnet)\ndata(QuickStartExample)\nfit &lt;- glmnet::glmnet(x = QuickStartExample$x, y = QuickStartExample$y)\nautoplot(fit)\n\n\n\n\n\n\nShow the code\nfit &lt;- glmnet::cv.glmnet(x = QuickStartExample$x, y = QuickStartExample$y)\nautoplot(fit, colour = 'blue')",
    "crumbs": [
      "线性模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "RCT.html",
    "href": "RCT.html",
    "title": "\n21  随机对照试验\n",
    "section": "",
    "text": "21.1 随机化\nhttps://www.equator-network.org/",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#随机化",
    "href": "RCT.html#随机化",
    "title": "\n21  随机对照试验\n",
    "section": "",
    "text": "21.1.1 简单/完全随机化\n独立随机分配，每组数量可能不等。\n\n\nTable 21.1\n\nShow the codelibrary(tidyverse)\n\n# 假设需要 100 个样本,分为 4 个组\nraw_data &lt;- tibble(\n    include_order = 1:100\n)\n\nset.seed(20241011)  \nraw_data |&gt;\n  mutate(简单assigned_group = sample(1:4, size = 100, replace = TRUE),\n         区组BRassigned_group = sample(rep(1:4, each=25))\n         ) -&gt; raw_data\n\ntable(raw_data$简单assigned_group)\n#&gt; \n#&gt;  1  2  3  4 \n#&gt; 24 24 27 25\ntable(raw_data$区组BRassigned_group)\n#&gt; \n#&gt;  1  2  3  4 \n#&gt; 25 25 25 25\nraw_data\n#&gt; # A tibble: 100 × 3\n#&gt;    include_order 简单assigned_group 区组BRassigned_group\n#&gt;            &lt;int&gt;              &lt;int&gt;                &lt;int&gt;\n#&gt;  1             1                  3                    3\n#&gt;  2             2                  2                    1\n#&gt;  3             3                  2                    2\n#&gt;  4             4                  4                    4\n#&gt;  5             5                  1                    4\n#&gt;  6             6                  1                    1\n#&gt;  7             7                  2                    2\n#&gt;  8             8                  3                    1\n#&gt;  9             9                  2                    3\n#&gt; 10            10                  1                    1\n#&gt; # ℹ 90 more rows\n\n\n\n\n完全独立分配无法保证样本量恰好相等。如果是针对受试者的分组，可按照受试者的入组顺序，入组的第1名受试者进入组3，入组的第2名受试者分入组2，以此类推。\n使用sample(rep(1:4, each=25))随机排列固定数量的标签保证各组数量相等，但分配过程不是独立的。实际上是一种区组随机化（当区组大小为100，即一个区组包含所有样本，且按1:1:1:1分配），它保证了每组数量相等，但破坏了受试者之间的独立性（因为每个组的数量固定，分配具有依赖性）。\n\n21.1.2 区组随机化/限制性随机化（restricted randomization）\n在临床试验中，小样本情况下通常推荐使用限制性随机化以保证组间均衡\n区组随机化：通过将受试者分成固定大小的区组，然后在每个区组内随机分配受试者到不同组别，确保在任何时候组间样本量接近相等。例如，使用大小为4的区组（每个区组内包含1,2,3,4各一次，随机排列），则每分配4个受试者，每个组恰好1例。这样，在100例中，仍然保证每组25例。\n\nShow the codeif(!require(blockrand)) install.packages(\"blockrand\")\n\n\n\nShow the codelibrary(blockrand)\n\n# 使用区组随机化，指定区组大小为4  生成25个区组（每个区组4个，共100个）\n\n\nset.seed(20241012)\n# 创建区组随机化方案\nblockrand_data &lt;- blockrand(\n  n = 100,              # 总样本量\n  num.levels = 4,       # 分组数量\n  block.sizes = 1,      # 区组大小\n  id.prefix = \"ID\",     # 受试者ID前缀\n  block.prefix = \"Block\",   # 区组ID前缀\n  stratum = \"Center1\"       # 分层名称（单中心）\n)\ntable(blockrand_data$treatment)\n#&gt; \n#&gt;  A  B  C  D \n#&gt; 25 25 25 25\nblockrand_data \n#&gt;        id stratum block.id block.size treatment\n#&gt; 1   ID001 Center1  Block01          4         B\n#&gt; 2   ID002 Center1  Block01          4         C\n#&gt; 3   ID003 Center1  Block01          4         A\n#&gt; 4   ID004 Center1  Block01          4         D\n#&gt; 5   ID005 Center1  Block02          4         D\n#&gt; 6   ID006 Center1  Block02          4         A\n#&gt; 7   ID007 Center1  Block02          4         C\n#&gt; 8   ID008 Center1  Block02          4         B\n#&gt; 9   ID009 Center1  Block03          4         D\n#&gt; 10  ID010 Center1  Block03          4         C\n#&gt; 11  ID011 Center1  Block03          4         B\n#&gt; 12  ID012 Center1  Block03          4         A\n#&gt; 13  ID013 Center1  Block04          4         B\n#&gt; 14  ID014 Center1  Block04          4         A\n#&gt; 15  ID015 Center1  Block04          4         C\n#&gt; 16  ID016 Center1  Block04          4         D\n#&gt; 17  ID017 Center1  Block05          4         D\n#&gt; 18  ID018 Center1  Block05          4         A\n#&gt; 19  ID019 Center1  Block05          4         C\n#&gt; 20  ID020 Center1  Block05          4         B\n#&gt; 21  ID021 Center1  Block06          4         C\n#&gt; 22  ID022 Center1  Block06          4         A\n#&gt; 23  ID023 Center1  Block06          4         B\n#&gt; 24  ID024 Center1  Block06          4         D\n#&gt; 25  ID025 Center1  Block07          4         A\n#&gt; 26  ID026 Center1  Block07          4         D\n#&gt; 27  ID027 Center1  Block07          4         C\n#&gt; 28  ID028 Center1  Block07          4         B\n#&gt; 29  ID029 Center1  Block08          4         C\n#&gt; 30  ID030 Center1  Block08          4         D\n#&gt; 31  ID031 Center1  Block08          4         A\n#&gt; 32  ID032 Center1  Block08          4         B\n#&gt; 33  ID033 Center1  Block09          4         C\n#&gt; 34  ID034 Center1  Block09          4         D\n#&gt; 35  ID035 Center1  Block09          4         B\n#&gt; 36  ID036 Center1  Block09          4         A\n#&gt; 37  ID037 Center1  Block10          4         C\n#&gt; 38  ID038 Center1  Block10          4         B\n#&gt; 39  ID039 Center1  Block10          4         D\n#&gt; 40  ID040 Center1  Block10          4         A\n#&gt; 41  ID041 Center1  Block11          4         B\n#&gt; 42  ID042 Center1  Block11          4         D\n#&gt; 43  ID043 Center1  Block11          4         A\n#&gt; 44  ID044 Center1  Block11          4         C\n#&gt; 45  ID045 Center1  Block12          4         C\n#&gt; 46  ID046 Center1  Block12          4         B\n#&gt; 47  ID047 Center1  Block12          4         A\n#&gt; 48  ID048 Center1  Block12          4         D\n#&gt; 49  ID049 Center1  Block13          4         A\n#&gt; 50  ID050 Center1  Block13          4         C\n#&gt; 51  ID051 Center1  Block13          4         B\n#&gt; 52  ID052 Center1  Block13          4         D\n#&gt; 53  ID053 Center1  Block14          4         B\n#&gt; 54  ID054 Center1  Block14          4         C\n#&gt; 55  ID055 Center1  Block14          4         A\n#&gt; 56  ID056 Center1  Block14          4         D\n#&gt; 57  ID057 Center1  Block15          4         A\n#&gt; 58  ID058 Center1  Block15          4         B\n#&gt; 59  ID059 Center1  Block15          4         C\n#&gt; 60  ID060 Center1  Block15          4         D\n#&gt; 61  ID061 Center1  Block16          4         D\n#&gt; 62  ID062 Center1  Block16          4         A\n#&gt; 63  ID063 Center1  Block16          4         B\n#&gt; 64  ID064 Center1  Block16          4         C\n#&gt; 65  ID065 Center1  Block17          4         C\n#&gt; 66  ID066 Center1  Block17          4         B\n#&gt; 67  ID067 Center1  Block17          4         D\n#&gt; 68  ID068 Center1  Block17          4         A\n#&gt; 69  ID069 Center1  Block18          4         A\n#&gt; 70  ID070 Center1  Block18          4         D\n#&gt; 71  ID071 Center1  Block18          4         C\n#&gt; 72  ID072 Center1  Block18          4         B\n#&gt; 73  ID073 Center1  Block19          4         C\n#&gt; 74  ID074 Center1  Block19          4         A\n#&gt; 75  ID075 Center1  Block19          4         D\n#&gt; 76  ID076 Center1  Block19          4         B\n#&gt; 77  ID077 Center1  Block20          4         A\n#&gt; 78  ID078 Center1  Block20          4         D\n#&gt; 79  ID079 Center1  Block20          4         B\n#&gt; 80  ID080 Center1  Block20          4         C\n#&gt; 81  ID081 Center1  Block21          4         B\n#&gt; 82  ID082 Center1  Block21          4         C\n#&gt; 83  ID083 Center1  Block21          4         A\n#&gt; 84  ID084 Center1  Block21          4         D\n#&gt; 85  ID085 Center1  Block22          4         B\n#&gt; 86  ID086 Center1  Block22          4         C\n#&gt; 87  ID087 Center1  Block22          4         A\n#&gt; 88  ID088 Center1  Block22          4         D\n#&gt; 89  ID089 Center1  Block23          4         B\n#&gt; 90  ID090 Center1  Block23          4         C\n#&gt; 91  ID091 Center1  Block23          4         A\n#&gt; 92  ID092 Center1  Block23          4         D\n#&gt; 93  ID093 Center1  Block24          4         C\n#&gt; 94  ID094 Center1  Block24          4         A\n#&gt; 95  ID095 Center1  Block24          4         B\n#&gt; 96  ID096 Center1  Block24          4         D\n#&gt; 97  ID097 Center1  Block25          4         A\n#&gt; 98  ID098 Center1  Block25          4         C\n#&gt; 99  ID099 Center1  Block25          4         B\n#&gt; 100 ID100 Center1  Block25          4         D\n\n\n# 检查区组分布\nblockrand_data |&gt; group_by(block.id) |&gt; \n    summarise(\n    groups = paste(sort(unique(treatment)), collapse = \",\"),\n    n = n()\n  )\n#&gt; # A tibble: 25 × 3\n#&gt;    block.id groups      n\n#&gt;    &lt;fct&gt;    &lt;chr&gt;   &lt;int&gt;\n#&gt;  1 Block01  A,B,C,D     4\n#&gt;  2 Block02  A,B,C,D     4\n#&gt;  3 Block03  A,B,C,D     4\n#&gt;  4 Block04  A,B,C,D     4\n#&gt;  5 Block05  A,B,C,D     4\n#&gt;  6 Block06  A,B,C,D     4\n#&gt;  7 Block07  A,B,C,D     4\n#&gt;  8 Block08  A,B,C,D     4\n#&gt;  9 Block09  A,B,C,D     4\n#&gt; 10 Block10  A,B,C,D     4\n#&gt; # ℹ 15 more rows\n\n\n区组随机化的问题\n\n选择偏倚更为常见，因为研究人员可以轻松预测分组的治疗分配。\n\n21.1.3 分层随机化\n根据不同的因素（性别）对受试者进行分组。如果性别是选定因素，则层数是二，对每层应用随机分组。这种形式的随机化可以减少治疗组中的特征不平衡，并提高统计功效。这种方法可以更容易地为不同的预后因素生成区组随机化列表。\n分层随机化的问题\n\n虽然其目的是消除选择偏倚，但这也意味着各分组并不总是具有相同的重要特征。\n\n分层区组随机化分组\n多中心临床试验中普遍采用的方法是以中心分层,然后在各中心内进行区组随机化,即称为分层的区组随机化。\n\n21.1.4 动态随机化（Dynamic Randomization）\n动态随机化是指在临床试验的过程中每例患者分到各组的概率不是固定不变的,而是根据一定的条件进行调整的方法,它能有效地保证各试验组间例数和某些重要的非处理因素接近一致。动态随机化包括瓮(urn)法、偏币(biased coin)法、最小化(minimization)法等。\n最小化\n最小化随机化的核心是通过动态平衡组内特征分配，使得组间的差异最小。\n最小化被用作平衡临床试验预后因素的工具。第一例受试者通过简单随机化分配到一个治疗组，然后根据先前的受试者及其在临床试验中的安置分配其余受试者，以平衡预后因素。目的是克服分层随机化的挑战。\n\nShow the code# 加载randomizeR包\nlibrary(randomizeR)\n\n\n最小化的问题\n\n不符合随机化的所有要求。",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#治疗分配隐匿",
    "href": "RCT.html#治疗分配隐匿",
    "title": "\n21  随机对照试验\n",
    "section": "\n21.2 治疗分配隐匿",
    "text": "21.2 治疗分配隐匿\n在分配前对受试者的治疗组分配保密。这有助于减少选择偏倚，防止研究人员影响受试者分组。\n\n首先要求产生随机分配序列和确定受试对象合格性的研究人员不应该是同一个人\n其次,如果可能,产生和保存随机分配序列的人员最好是不参与试验的人员\n\n按顺序编码、不透光、密封的信封(sequentially numbered,opaque, sealed envelopes )这是最常用的一种方法。每个研究对象所接受的治疗方案由产生的随机分配序列产生,并被放入按顺序、密封、不透光的信封中。合格的受试对象同意进入试验时,信封才能被打开,受试对象才能接受相应的处理措施。但是这种方法有一定的局限性。(1)如果研究者在试验前提前打开信封而将患者分配至预期的治疗组,将会破坏了研究的随机性。(2)如果将信封对着极强的光线,有时信封里面的内容能被看见。因此,为了避免这些问题,目前在临床研究中比较常用的做法是用来无碳复写纸按顺序、密封、不透光的信封。一旦无碳复写纸被开启后,就无法还原。这样,就比较容易发现研究者是否提前知道随机分配序列。信封法适用于单中心小样本的临床研究。\n中心随机( central randomisation)系统为了避免按顺序、密封、不透光的信封所带来的问题,常用的一种方法是“远程”随机。“远程随机”是指当研究人员确定合格的研究对象后,通过电话或者网络将患者的基本信息传递给中心随机系统,然后获得每个患者的治疗分配方案。从今后的发展趋势来看,这种“远程”的中心随机系统将会取代信封系统。中心随机法适用于大型多中心研究。\n随机分配方案隐匿与盲法\n常与盲法相混淆。随机分配方案的隐匿是指通过在随机分配时防止随机序列被事先知道,而避免选择性偏倚;它在临床试验最后一名患者完成分组后即告结束;而盲法是为了避免干预措施实施过程中和结局指标测量时来自受试者和研究者的主观偏性,盲法需要在整个治疗和随访过程中保持盲的状态,直到试验干预和结局测量完成后才结束。盲法并非是在所有的临床试验中都能进行,但是随机分配方案的隐匿却在任何临床试验中都能进行,无论是分配前或者在分配的时点时。例如,比较针灸和药物两种疗法治疗某种疾病的疗效,盲法是难以实施的,而随机分配方案的隐匿却是可行的。",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#盲法",
    "href": "RCT.html#盲法",
    "title": "\n21  随机对照试验\n",
    "section": "\n21.3 盲法",
    "text": "21.3 盲法\n\n\n\n\n\n21.3.1 开放试验\n盲法是RCT的基本原则之一，但并不是所有的研究都必须采用或均能实行。比如比较某种手术与某药物治疗肺癌的效果，就不必要，也没有条件实施盲法。在这种情况下，只能进行开放试验，即研究对象和研究者均知道试验组和对照组的分组情况，试验公开进行。\n在开放试验中，盲法无法实施，但是分组隐匿仍然可以实施。同时可以考虑对结局评价者、数据监察和统计分析人员设盲。其优点是易于设计和实施，研究者了解分组情况，便于对研究对象及时作出处理，其主要缺点是容易产生偏倚。\n\n21.3.2 单盲\n单盲试验（single-blinded）：单盲试验是仅研究者知道每个病人用药的具体内容，而病人不知道，单盲试验虽可以避免来自病人主观因素的偏倚，但仍未能防止来自研究者方面的影响。\n\n21.3.3 双盲\n双盲(double blinded)试验：单盲试验是仅研究者知道每个病人用药的具体内容，而病人不知道，单盲试验虽可以避免来自病人主观因素的偏倚，但仍未能防止来自研究者方面的影响。\n在双盲实施过程中，可能会出现一种情况：假设本研究中006号研究对象在研究过程中出现了严重的不良反应，要分析原因以便采取对策，此时必须揭盲。揭盲后研究实施者就知道了006号研究对象在使用乙药。但是，研究实施者在分组时已经知道006号研究对象为2组，揭盲后便知道了所有2组研究对象均在使用乙药，这会出现一人揭盲人人揭盲的情况。要避免这种情况，严格而规范的双盲试验不是给每个研究对象一个组别，按组别发药；而是给每个研究对象一个编码，按编码发药。盲底则由专人统一保管。\n要避免一人揭盲人人揭盲的情况，双盲的具体做法是:\n\n研究设计者在随机化分组时，对每个研究对象分配一个设盲编码。\n\n\n\nTable 21.2\n\nShow the coderaw_data |&gt; \n    mutate(\n        blind_id = 1001:1100,\n        drug_id = 1001:1100,\n    ) -&gt;raw_data\nraw_data \n#&gt; # A tibble: 100 × 5\n#&gt;    include_order 简单assigned_group 区组BRassigned_group blind_id drug_id\n#&gt;            &lt;int&gt;              &lt;int&gt;                &lt;int&gt;    &lt;int&gt;   &lt;int&gt;\n#&gt;  1             1                  3                    3     1001    1001\n#&gt;  2             2                  2                    1     1002    1002\n#&gt;  3             3                  2                    2     1003    1003\n#&gt;  4             4                  4                    4     1004    1004\n#&gt;  5             5                  1                    4     1005    1005\n#&gt;  6             6                  1                    1     1006    1006\n#&gt;  7             7                  2                    2     1007    1007\n#&gt;  8             8                  3                    1     1008    1008\n#&gt;  9             9                  2                    3     1009    1009\n#&gt; 10            10                  1                    1     1010    1010\n#&gt; # ℹ 90 more rows\n\n# 给研究实施者提供\nraw_data |&gt; select(contains(\"id\"))\n#&gt; # A tibble: 100 × 2\n#&gt;    blind_id drug_id\n#&gt;       &lt;int&gt;   &lt;int&gt;\n#&gt;  1     1001    1001\n#&gt;  2     1002    1002\n#&gt;  3     1003    1003\n#&gt;  4     1004    1004\n#&gt;  5     1005    1005\n#&gt;  6     1006    1006\n#&gt;  7     1007    1007\n#&gt;  8     1008    1008\n#&gt;  9     1009    1009\n#&gt; 10     1010    1010\n#&gt; # ℹ 90 more rows\n\n\n\n\n\n同时，分发的药品包装上也有与设盲编码一一对应的编码。\n在随机化分组完成后，001号研究对象将分入3组，002号将分入2组。研究设计者在编码为1001的药品包装内分装C药，在编码为1002的药品包装内分装乙药。同时仅给研究实施者提供研究对象序号、设盲编码和标有设盲编码的药品 ( Table 21.2)。\n而盲底（ Table 21.1 ）则只有研究设计者知道，并由专人保管。此时，研究实施者按照顺序纳入研究对象后，仅给研究对象标有编码的药品即可。研究实施者和研究对象均不知道分组和用药情况。\n\n这样做的优点是：出现严重不良反应需要揭盲时，只需个别地揭盲，不容易泄密。但需要注意的是，必须建立与健全专项的药品保管、领用和发放制度；领发药品的各个环节都要认真核对编码，防止出错。实际上，如此执行，也做到了分组隐匿。\n需要注意的是，试验结束前盲底泄露或应急信件拆阅超过20%，双盲试验即告失败。\n\n21.3.4 三盲\n在双盲实施的时候，还有可能出现一种偏倚：数据监察和统计分析人员知道研究分组情况，可能会对数据有选择性的取舍，造成不真实的情况。如在双盲实施的过程中，对数据监察和统计分析人员也设盲，此为三盲。\n在研究实施过程中，将所有的临床试验数据输入数据库并经过核查，确证准确无误将数据锁定后，才进行第一次揭盲，即分出A、B两组，但哪一组是试验组、哪一组是对照组并不清楚。之后进行统计分析，待A组和B组分析数据出来后，再第二次揭盲，即明确A、B两组分别代表试验组还是对照组。\n盲法与前述分配隐匿的区别在于：分配隐匿主要控制一种选择偏倚，即控制研究实施者有倾向地选择研究对象进入试验组或对照组；而盲法除此之外，还能控制信息偏倚，即控制研究实施者、资料收集和数据分析者有倾向性的取舍研究结果。",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#对照",
    "href": "RCT.html#对照",
    "title": "\n21  随机对照试验\n",
    "section": "\n21.4 对照",
    "text": "21.4 对照\n空白对照 安慰剂（placebo）对照 阳性对照",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#重复",
    "href": "RCT.html#重复",
    "title": "\n21  随机对照试验\n",
    "section": "\n21.5 重复",
    "text": "21.5 重复\n有一定的重复观察样本, 一项研究不允许有太多的受试者失访, 在选择研究样本时一定要特别注意。",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#评价方法",
    "href": "RCT.html#评价方法",
    "title": "\n21  随机对照试验\n",
    "section": "\n21.6 评价方法",
    "text": "21.6 评价方法\nCochrane 偏倚风险评估工具包括 7 个方面：\n\n随机序列的产生(选择偏倚)；\n盲法分配(选择偏倚)；\n所有研究参与者和人员采用盲法(执行偏倚)；\n结果评估的盲法(观察偏倚)；\n结果数据的完整性(失访偏倚)；\n选择报道(报告偏倚)；\n其他。最后以文字、表格或图示方法显示对所有纳入文献的评价结果\n\nJadad 量表在临床试验的评价工作中简单易行，具有一定的科学性，得到了许多学者的认可， 发表了大量以 Jadad 量表作为评价工具的系统评价， 其中相当一部分文献集中在药物临床试验为主的研究， 在非开放式 RCT 评价中发挥了重要作用，得到了大多数学者的认可。 但是，随着人们对临床试验实施标准的不断修改完善，尤其是开放式非药物临床试验的RCT 研究在临床上广泛开展，Jadad 量表的评价标准有时不能完全客观、透明地反映出开放式 RCT 的研究质量，从而可能将质量较高的 RCT 误认为低质量 RCT。",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html",
    "href": "CoxProportionalHazardsModel.html",
    "title": "\n18  Cox比例风险模型\n",
    "section": "",
    "text": "18.1 风险函数\nCox比例风险模型是一种半参数方法\n\\[\n\\begin{aligned}\nh(t)=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t|T\\ge t)}{\\Delta t}\\\\\n=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{\\Delta t·P(T\\ge t) }\\\\\n=&\\lim_{\\Delta t\\to 0}\\frac{S(t)- S(t+\\Delta t)}{\\Delta t·S(t)}\\\\\n=&-\\frac{d(\\ln S(t))}{dt}\n\\end{aligned}\n\\]\n推导出 \\(S(t)=e^{-\\int_0^t h(u)du}\\)\n\\[\n\\begin{aligned}\nh(t)\\Delta t=&P(t\\le T&lt;t+\\Delta t|T\\ge t)\n=\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{P(T\\ge t) }\\\\\n=&\\frac{P(t\\le T&lt;t+\\Delta t)}{P(T\\ge t) }\\\\\n=&\\frac{f(t)\\Delta t}{S(t)}\n\\end{aligned}\n\\]\n推导出 \\(f(t)=h(t)S(t)\\)",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#风险率",
    "href": "CoxProportionalHazardsModel.html#风险率",
    "title": "\n18  Cox比例风险模型\n",
    "section": "\n18.2 风险率",
    "text": "18.2 风险率\n对于有风险因子\\(x_1,x_2,...,x_k\\) 的个体在时间 t 的风险率\\(h(t|x_1,x_2,...,x_k)\\)\n\\[ h(t|x_1,x_2,...,x_k)=h_0(t)g(x_1,x_2,...,x_k)=h_0(t)exp(\\sum_{j=1}^k\\beta_jx_j) \\]\n其中\n\n\\(h0 (t)\\)是给定所有风险因子（协变量）为零的随时间变化的基线风险函数。\n\\(g(X)\\)是k个独立风险因子的集合函数，代表变量的风险效应。\n\\(β_j\\)是部分回归系数，表示风险比的比例变化。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#风险比hazard-ratio",
    "href": "CoxProportionalHazardsModel.html#风险比hazard-ratio",
    "title": "\n18  Cox比例风险模型\n",
    "section": "\n18.3 风险比（hazard ratio）",
    "text": "18.3 风险比（hazard ratio）\n假设有两个个体，分别具有独立变量，两个个体的风险函数之比称为风险比\n\\[ HR=\\frac{h(t|x_1,x_2,...,x_k)}{h(t|x_1^*,x_2^*,...,x_k^*)}=exp(\\sum_{j=1}^k\\beta_j(x_j-x_j^*)) \\]\n\n18.3.1 比例风险假设（proportional hazards assumption）\nCox 模型假设任意两组之间的 HR 随时间保持不变\n\\[ \\frac{h(t)}{h_0(t)}=exp(\\sum_{j=1}^k\\beta_jx_j) \\]\n\n18.3.2 模型系数的估计\n条件死亡概率和局部似然函数方法\n\\[ \\ln L_p(\\beta)=\\sum_{i=1}^{d}\\left[ \\sum_{j=1}^k\\beta_jx_{ij}-\\ln\\sum_{m\\in R_i}exp( \\sum_{j=1}^k\\beta_jx_{mj})         \\right] \\]\nNewton-Raphson iterative method\n\\[  \\begin{cases}  \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_1}=0\\\\ \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_2}=0\\\\ \\vdots\\\\ \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_k}=0\\\\ \\end{cases} \\]\n\n18.3.3 模型系数的假设检验\n\n\nWald‘s test\n检验是否有独立变量需要被消除，统计量\\(Z=b_j/S_{b_j}\\)\n当样本量足够大时，Z服从标准正态分布，Z2 服从自由度为1 的\\(\\chi^2\\) 分布\n\\[ \\chi^2_W=(b_j/S_{b_j})^2\\sim \\chi^2(1) \\]\n\n\nPartial likelihood Ratio test\n主要用于非显著性变量的消除，新变量的引入和模型的比较。\n\\[ \\chi^2_{LR}=2\\left[ \\ln L_p(\\beta_k)-\\ln L_p(\\beta_{k-1}) \\right]\\sim\\chi^2(1) \\]\n其中分别是包含 k 个和 k-1 个（不包含要检验的第 j 个变量）独立变量的对数局部似然函数",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#示例",
    "href": "CoxProportionalHazardsModel.html#示例",
    "title": "\n18  Cox比例风险模型\n",
    "section": "\n18.4 示例",
    "text": "18.4 示例\n\nShow the codelibrary(survminer)\nlibrary(survival)\ndf &lt;- survival::rotterdam\ndf &lt;- df %&gt;% mutate(dtime_yrs = dtime/365.25,\n                    status = death)\n\n# 拟合Cox比例风险模型 \ncox_model &lt;- coxph(Surv(dtime_yrs, status) ~ hormon + chemo + size + er + pgr + nodes + meno + grade + age, data = df)\n# 查看模型结果 \nsummary(cox_model)  \n#&gt; Call:\n#&gt; coxph(formula = Surv(dtime_yrs, status) ~ hormon + chemo + size + \n#&gt;     er + pgr + nodes + meno + grade + age, data = df)\n#&gt; \n#&gt;   n= 2982, number of events= 1272 \n#&gt; \n#&gt;                 coef  exp(coef)   se(coef)      z Pr(&gt;|z|)    \n#&gt; hormon    -6.553e-02  9.366e-01  8.840e-02 -0.741 0.458535    \n#&gt; chemo      5.032e-02  1.052e+00  8.198e-02  0.614 0.539342    \n#&gt; size20-50  4.425e-01  1.557e+00  6.536e-02  6.771 1.28e-11 ***\n#&gt; size&gt;50    8.222e-01  2.276e+00  9.142e-02  8.993  &lt; 2e-16 ***\n#&gt; er        -5.512e-05  9.999e-01  1.107e-04 -0.498 0.618466    \n#&gt; pgr       -3.676e-04  9.996e-01  1.226e-04 -2.998 0.002720 ** \n#&gt; nodes      7.295e-02  1.076e+00  4.879e-03 14.953  &lt; 2e-16 ***\n#&gt; meno       7.046e-02  1.073e+00  1.006e-01  0.701 0.483583    \n#&gt; grade      3.156e-01  1.371e+00  7.082e-02  4.456 8.33e-06 ***\n#&gt; age        1.406e-02  1.014e+00  3.830e-03  3.671 0.000242 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt;           exp(coef) exp(-coef) lower .95 upper .95\n#&gt; hormon       0.9366     1.0677    0.7876    1.1137\n#&gt; chemo        1.0516     0.9509    0.8955    1.2349\n#&gt; size20-50    1.5567     0.6424    1.3695    1.7694\n#&gt; size&gt;50      2.2755     0.4395    1.9022    2.7221\n#&gt; er           0.9999     1.0001    0.9997    1.0002\n#&gt; pgr          0.9996     1.0004    0.9994    0.9999\n#&gt; nodes        1.0757     0.9296    1.0654    1.0860\n#&gt; meno         1.0730     0.9320    0.8810    1.3068\n#&gt; grade        1.3711     0.7293    1.1934    1.5753\n#&gt; age          1.0142     0.9860    1.0066    1.0218\n#&gt; \n#&gt; Concordance= 0.693  (se = 0.008 )\n#&gt; Likelihood ratio test= 524.4  on 10 df,   p=&lt;2e-16\n#&gt; Wald test            = 609.4  on 10 df,   p=&lt;2e-16\n#&gt; Score (logrank) test = 688.1  on 10 df,   p=&lt;2e-16\n\n\n例如，与未接受激素治疗的患者相比，在任何给定时间接受激素治疗患者的结局（死亡）概率为0.9366。换句话说，他们的生存率提高了6.34%。对于每个组，我们比较了该特征的存在（=1）和不存在（=0）。例如，对于激素治疗，我们有2600名患者没有接受激素治疗，而300名患者接受了激素治疗。因此，系数是指接受治疗与不接受治疗的对数风险率的变化，换句话说，“不接受激素治疗”组是我们的参考。\n在解释 Cox regresison 的结果之前，请验证是否遵循比例风险假设。\nCox 模型假设任意两组之间的 HR 随时间保持不变。我们可以使用 cox.zph() 非常轻松地对其进行测试。\n\nShow the codetest &lt;- survival::cox.zph(cox_model)\ntest\n#&gt;         chisq df       p\n#&gt; hormon  0.684  1 0.40818\n#&gt; chemo   2.100  1 0.14727\n#&gt; size    5.206  2 0.07405\n#&gt; er     59.748  1 1.1e-14\n#&gt; pgr    41.637  1 1.1e-10\n#&gt; nodes   4.073  1 0.04358\n#&gt; meno    4.284  1 0.03846\n#&gt; grade   3.163  1 0.07533\n#&gt; age    13.954  1 0.00019\n#&gt; GLOBAL 93.751 10 9.6e-16\n\n\n基于Schoenfeld residuals 的比例风险假设\n\nShow the code# 绘制每个协变量随时间变化的 Schoenfeld 残差\nsurvminer::ggcoxzph(test, point.size = 0.1)\n\n\n\n\n\n\n\n如果残差随时间显示清晰的模式，则可能表示违反了比例风险假设。\n一些有助于解释的提示：\n\n无模式（常数残差）：如果残差随机分布在零附近，没有明确的趋势或模式，则表明比例风险假设是合理的：）\n线性趋势：残差随时间变化的线性趋势（增加或减少）可能表明违反了比例风险假设。例如，如果残差在一段时间内始终为正或负，则表示存在时间相关效应。\n非线性模式：如果残差表现出非线性模式或特定形状（例如，U 形、V 形），则可能表示偏离比例风险。\n并行度：平行度意味着残差的分布和分布在时间上相对恒定。如果残差随时间变宽或变窄，则可能表明违反了假设。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  }
]